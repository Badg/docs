[{"body":"  Welcome to the LocalStack Documentation!\nExplore and learn about LocalStack.   Get Started Install and run LocalStack on your machine, and discover the benefits of local cloud development.\n   Integrations Use your favorite cloud development framework with LocalStack: CDK, Terraform, Serverless, and more!\n   LocalStack in CI Use LocalStack in your Continuous Integration pipelines.\n   Local AWS Services Browse through the AWS Services that LocalStack emulates.\n   LocalStack Tools Learn how to use LocalStack Cloud Developer Tools to boost your efficiency.\n   Understanding LocalStack Learn how LocalStack works and how you can tweak it for your use case.\n      Featured guides and articles Here are some commonly asked questions and related articles.  How do I get started with LocalStack Pro? What are Local Cloud Pods and how do I use them? How LocalStack improves your Lambda developer experience Which AWS services does LocalStack support? How do I use the Serverless Framework with LocalStack?       Help Where can I get help?  Pro support on Slack Community support on Slack Discussion forum on Discourse Issue reports on GitHub        ","categories":"","description":"","excerpt":"  Welcome to the LocalStack Documentation!\nExplore and learn about ‚Ä¶","ref":"/overview/","tags":"","title":"Overview"},{"body":"Coverage Levels LocalStack provides emulation services for different AWS APIs (e.g., Lambda, SQS, SNS, ‚Ä¶), but the level of support with the real system differs and is categorized using the following system:\n         ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Feature fully supported by LocalStack maintainers; feature is guaranteed to pass all or the majority of tests   ‚≠ê‚≠ê‚≠ê‚≠ê Feature partially supported by LocalStack maintainers   ‚≠ê‚≠ê‚≠ê Feature supports basic functionalities (e.g., CRUD operations)   ‚≠ê‚≠ê Feature should be considered unstable   ‚≠ê Feature is experimental and regressions should be expected   - Feature is not yet implemented    Emulation Levels  CRUD: The service accepts requests and returns proper (potentially static) responses. No additional business logic besides storing entities. Emulated: The service imitates the functionality, including synchronous and asynchronous business logic operating on service entities.  AWS Feature Coverage In the coverage table below, the features are marked with their respective availability across different LocalStack versions:\n Community version (default, if not marked) Pro version (marked with Pro)     Service / Feature Coverage Level Emulation Level Notes     ACM üîç     Certificates ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Account Configuration ‚≠ê‚≠ê CRUD    Amplify (Pro) üîç     Apps ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Backend Environments ‚≠ê‚≠ê‚≠ê CRUD    Branches ‚≠ê‚≠ê‚≠ê CRUD    Deployments -     Domain Associations -     Jobs -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Webhooks ‚≠ê‚≠ê‚≠ê Emulated    API Gateway üîç     API Keys ‚≠ê‚≠ê‚≠ê CRUD    Authorizers (Pro) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Base Path Mappings ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Deployments ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Documentation Parts ‚≠ê‚≠ê‚≠ê CRUD    Documentation Versions ‚≠ê‚≠ê‚≠ê CRUD    Domain Names ‚≠ê‚≠ê‚≠ê CRUD    Gateway / Integration / Method Responses ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Integrations ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Methods ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Models ‚≠ê‚≠ê‚≠ê CRUD    Request Validators ‚≠ê‚≠ê Emulated    Resources ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    REST APIs ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Stages ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Usage Plans ‚≠ê‚≠ê‚≠ê CRUD    Usage Plan Keys ‚≠ê‚≠ê‚≠ê CRUD    VPC Links ‚≠ê‚≠ê‚≠ê CRUD    API Gateway v2 (Pro) üîç     APIs ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    API Mappings ‚≠ê‚≠ê‚≠ê Emulated    Authorizers ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Deployments ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Domain Names ‚≠ê‚≠ê‚≠ê CRUD    Import APIs from OpenAPI specs ‚≠ê‚≠ê‚≠ê Emulated    Integrations ‚≠ê‚≠ê‚≠ê Emulated    Integration Responses ‚≠ê‚≠ê‚≠ê Emulated    Models ‚≠ê‚≠ê‚≠ê CRUD    Routes ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Route Responses ‚≠ê‚≠ê‚≠ê Emulated    Stages ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    VPC Links ‚≠ê‚≠ê‚≠ê CRUD    API Gateway Management API (Pro) üîç     Connections ‚≠ê‚≠ê‚≠ê Emulated    AppConfig (Pro) üîç     Applications ‚≠ê‚≠ê‚≠ê CRUD    Configuration Profiles ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Configurations ‚≠ê‚≠ê‚≠ê CRUD    Deployment Strategies ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Deployments ‚≠ê‚≠ê‚≠ê Emulated    Environments ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Hosted Configuration Versions ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Application Autoscaling (Pro) üîç     Scalable Targets ‚≠ê‚≠ê‚≠ê CRUD    Scaling Activities -     Scaling Policies ‚≠ê‚≠ê‚≠ê CRUD    Scheduled Actions ‚≠ê‚≠ê‚≠ê CRUD    AppSync (Pro) üîç     API Caches ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    API Keys ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Data Sources ‚≠ê‚≠ê‚≠ê Emulated    Functions ‚≠ê‚≠ê‚≠ê Emulated    GraphQL APIs ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Resolvers ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Types ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Athena (Pro) üîç     Data Catalogs ‚≠ê‚≠ê CRUD    Databases ‚≠ê‚≠ê Emulated    Named Queries -     Prepared Statements -     Query Executions ‚≠ê‚≠ê‚≠ê Emulated    Table Metadata -     Tags ‚≠ê‚≠ê‚≠ê CRUD    Work Groups -     Autoscaling (Pro) üîç     Metric Collection ‚≠ê‚≠ê‚≠ê CRUD    Autoscaling Groups ‚≠ê‚≠ê CRUD    Loadbalancer ‚≠ê‚≠ê‚≠ê CRUD    Backup (Pro) üîç     Backup Jobs ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Backup Plans ‚≠ê‚≠ê‚≠ê Emulated    Backup Selections ‚≠ê‚≠ê‚≠ê Emulated    Backup Vaults ‚≠ê‚≠ê‚≠ê Emulated    Backup Vault Access Policies -     Backup Vault Notifications -     Global Settings -     Protected Resources -     Recovery Points ‚≠ê‚≠ê‚≠ê Emulated    Tags -     Batch (Pro) üîç     Compute Environments ‚≠ê‚≠ê‚≠ê CRUD    Job Queues ‚≠ê‚≠ê‚≠ê CRUD    Job Definitions ‚≠ê‚≠ê‚≠ê CRUD    Jobs ‚≠ê‚≠ê‚≠ê Emulated    CE (Cost Explorer API) (Pro) üîç     Anomaly Monitoring ‚≠ê‚≠ê‚≠ê CRUD    Anomaly Subscription ‚≠ê‚≠ê‚≠ê CRUD    Cost Category ‚≠ê‚≠ê CRUD    Cost Usage/Forecast -     Savings Plan -     CloudFormation üîç     Change Sets ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Stacks ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Stack Drifts - -    Stack Events ‚≠ê‚≠ê‚≠ê Emulated    Stack Instances ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Stack Policies ‚≠ê‚≠ê‚≠ê CRUD    Stack Resources ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Stack Sets ‚≠ê‚≠ê‚≠ê CRUD    Publishers - -    Templates ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Type Activations ‚≠ê‚≠ê -    CloudFront (Pro) üîç     Cache Policies -     Distributions ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Field Level Encryption -     Functions ‚≠ê‚≠ê‚≠ê CRUD    Invalidations ‚≠ê‚≠ê‚≠ê CRUD    Key Groups -     Monitoring Subscriptions -     Origin Access Identities ‚≠ê‚≠ê‚≠ê CRUD    Origin Request Policies ‚≠ê‚≠ê‚≠ê CRUD    Public Keys -     Realtime Log Configs -     Streaming Distributions -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    CloudTrail (Pro) üîç     Event Selectors ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Insight Selectors -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Trails ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Start/Stop Logging ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    CloudWatch üîç     Alarms ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Alarm Histories -     Anomaly Detectors -     Dashboards -     Insight Rules -     Metric Data ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Metric Statistics ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Metric Streams -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    CodeCommit (Pro) üîç     Approval Rules -     Blobs / Files / Folders ‚≠ê‚≠ê‚≠ê Emulated    Branches ‚≠ê‚≠ê‚≠ê Emulated    Comments -     Commits ‚≠ê‚≠ê‚≠ê Emulated    Merge Commits / Conflicts -     Pull Requests -     Repositories ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Cognito Identity (Pro) üîç     Developer Identities -     Identities ‚≠ê‚≠ê‚≠ê Emulated    Identity Pool Roles -     Identity Pools ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    OpenID Tokens -     Tags -     Cognito Identity Provider (IdP) (Pro) üîç     Admin APIs ‚≠ê‚≠ê‚≠ê Emulated Triggers can involve Lambda   Devices ‚≠ê‚≠ê CRUD    Auth Flows ‚≠ê‚≠ê‚≠ê Emulated    Groups ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Lambda Triggers ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    MFA Configs ‚≠ê‚≠ê‚≠ê CRUD    Resource Servers -     Risk Configurations -     Identity Providers ‚≠ê‚≠ê‚≠ê CRUD    User Import Jobs -     User Pool Clients ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    User Pool Domains ‚≠ê‚≠ê CRUD    User Pools ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Users ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Config üîç     Config Rules ‚≠ê‚≠ê‚≠ê CRUD    Conformance ‚≠ê‚≠ê CRUD    Remediation -     DocumentDB (Pro) üîç     DB/Cluster Parameter Groups ‚≠ê‚≠ê‚≠ê CRUD    DB/Cluster Snapshots ‚≠ê‚≠ê Emulated    DB Clusters/Instances ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    DB Subnet Groups ‚≠ê‚≠ê‚≠ê Emulated    Event Subscriptions -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    DynamoDB üîç     Backups (Pro) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Batch Operations ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Global Tables ‚≠ê‚≠ê‚≠ê‚≠ê CRUD version 2019.11.21 not supported yet   Items ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Kinesis Streaming Destinations ‚≠ê‚≠ê‚≠ê Emulated    PartiQL Queries ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Query / Scan Operations ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tables ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Table Replica Autoscaling -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    DynamoDB Streams üîç     Records ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Shard Iterators ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Streams ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    EC2 üîç     Classic Links -     Customer Gateways ‚≠ê CRUD    DHCP Options ‚≠ê‚≠ê CRUD    Allocate/Deallocate Elastic IPs ‚≠ê‚≠ê‚≠ê CRUD    Fleets ‚≠ê‚≠ê CRUD    Flow Logs ‚≠ê‚≠ê‚≠ê CRUD    Images ‚≠ê‚≠ê CRUD (Pro) Include Docker images   Internet Gateways ‚≠ê‚≠ê‚≠ê CRUD    Local Gateway Routes ‚≠ê‚≠ê‚≠ê CRUD    Key Pairs ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Launch Templates ‚≠ê‚≠ê‚≠ê CRUD    NAT Gateways ‚≠ê‚≠ê‚≠ê CRUD    Network ACLs ‚≠ê‚≠ê‚≠ê CRUD    Network Interfaces ‚≠ê‚≠ê‚≠ê CRUD    Reserved Instances ‚≠ê‚≠ê‚≠ê CRUD    Route Tables / Routes ‚≠ê‚≠ê‚≠ê CRUD    Scheduled Instances ‚≠ê‚≠ê‚≠ê CRUD    Security Groups / Egress / Ingress ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Snapshots ‚≠ê‚≠ê‚≠ê CRUD    Spot Instances ‚≠ê‚≠ê‚≠ê CRUD    Instances ‚≠ê‚≠ê Emulated (Pro) As Docker containers   Subnets ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Traffic Mirrors -     Transit Gateways ‚≠ê‚≠ê CRUD    Volumes ‚≠ê‚≠ê‚≠ê CRUD    VPC Endpoint Connections ‚≠ê‚≠ê‚≠ê CRUD    VPC Peering Connections ‚≠ê‚≠ê‚≠ê CRUD    VPCs ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    VPN Gateways / Connections ‚≠ê‚≠ê‚≠ê CRUD    ECR (Pro) üîç     Images ‚≠ê‚≠ê‚≠ê Emulated    Image Scans -     Lifecycle Policies ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Registries ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Registry Policies -     Replication Configurations -     Repositories ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Repository Policies ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    ECS (Pro) üîç     Account Settings -     Attributes ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Capacity Providers -     Clusters ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Container Instances ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Services ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Task Definitions ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Task Sets ‚≠ê‚≠ê‚≠ê CRUD    Tasks ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    EFS (Pro) üîç     File System ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Backup Policy -     EKS (Pro) üîç     AddOns -     Clusters ‚≠ê‚≠ê‚≠ê Emulated    Fargate Profiles ‚≠ê‚≠ê CRUD    Identity Provider Configs -     Node Groups -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Updates -     ElastiCache (Pro) üîç     Cache Clusters (Memcached) -     Cache Clusters (Redis) ‚≠ê‚≠ê‚≠ê Emulated    Cache Parameter Groups ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Cache Security Groups ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Cache Subnet Groups ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Global Replication Groups -     Replication Groups ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Snapshots -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Users / User Groups -     Elastic Beanstalk (Pro) üîç     Application Deployment ‚≠ê‚≠ê‚≠ê CRUD    Environment ‚≠ê‚≠ê CRUD    ELB (Elastic Load Balancing) (Pro) üîç     Listeners ‚≠ê‚≠ê‚≠ê CRUD    Load balancers ‚≠ê‚≠ê‚≠ê Emulated Application load balancers with IP address or Lambda targets only   Rules ‚≠ê‚≠ê‚≠ê CRUD    Target groups ‚≠ê‚≠ê‚≠ê CRUD    Listener certificates ‚≠ê‚≠ê‚≠ê CRUD    ELBv2 (Elastic Load Balancing v2) (Pro) üîç     Listeners ‚≠ê‚≠ê‚≠ê CRUD    Load balancers ‚≠ê‚≠ê‚≠ê CRUD    Rules ‚≠ê‚≠ê‚≠ê CRUD    Target groups ‚≠ê‚≠ê‚≠ê CRUD    Listener certificates ‚≠ê‚≠ê‚≠ê CRUD    EMR (Pro) üîç     Clusters ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Instance Fleets ‚≠ê‚≠ê‚≠ê CRUD    Job Flow Steps ‚≠ê‚≠ê‚≠ê Emulated    Managed Scaling Policies -     Notebook Executions -     Run Job Flows (Queries) ‚≠ê‚≠ê‚≠ê Emulated    Security Configurations -     Studios -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    ES (Elasticsearch Service) üîç     Cross-Cluster Search Connections -     Elasticsearch Domains ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Packages -     Reserved Instances -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    EventBridge (Events) üîç     API Destinations ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Archives -     Connections -     Event Buses ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Event Sources ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Partner Event Sources -     Replays -     Rules ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Firehose üîç     Delivery Streams ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Destinations ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Records ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Stream Encryption -     Glacier (Pro) üîç     Archive ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Vault ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Job ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Glue (Pro) üîç     Classifiers ‚≠ê‚≠ê‚≠ê CRUD    Connections ‚≠ê‚≠ê‚≠ê CRUD    Crawlers ‚≠ê‚≠ê‚≠ê Emulated    Databases ‚≠ê‚≠ê‚≠ê Emulated    Dev Endpoints -     Jobs ‚≠ê‚≠ê‚≠ê Emulated    ML Transforms -     Partitions ‚≠ê‚≠ê‚≠ê Emulated    Registries ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Schemas ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Scripts -     Security Configurations ‚≠ê‚≠ê‚≠ê CRUD    Tables ‚≠ê‚≠ê‚≠ê Emulated    Triggers ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê CRUD    User Defined Functions -     Workflows ‚≠ê‚≠ê‚≠ê CRUD    IAM üîç     Access Keys ‚≠ê‚≠ê‚≠ê Emulated    Account Aliases ‚≠ê‚≠ê‚≠ê CRUD    Credential Reports -     Groups ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Instance Profiles ‚≠ê‚≠ê‚≠ê CRUD    Login Profiles ‚≠ê‚≠ê‚≠ê CRUD    OIDC Providers -     Policies ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Roles ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    SAML Providers -     Server Certificates ‚≠ê‚≠ê‚≠ê CRUD    Service Linked Roles ‚≠ê‚≠ê‚≠ê CRUD    Users ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Virtual MFA Devices ‚≠ê‚≠ê CRUD    IoT (Analytics, Data, Wireless) (Pro) üîç     Authorizers -     Billing Groups -     Certificates ‚≠ê‚≠ê CRUD    Channels ‚≠ê‚≠ê CRUD    Custom Metrics -     Datasets ‚≠ê‚≠ê‚≠ê CRUD    Dimensions -     Domain Configurations -     Jobs ‚≠ê‚≠ê‚≠ê CRUD    Jobs Executions ‚≠ê‚≠ê‚≠ê CRUD    Jobs Templates -     Mitigation Actions -     Policies ‚≠ê‚≠ê‚≠ê CRUD    Provisioning Claims / Templates ‚≠ê‚≠ê CRUD    Role Aliases -     Security Profiles - CRUD    Shadows ‚≠ê‚≠ê CRUD    Streams -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Thing Groups ‚≠ê‚≠ê‚≠ê CRUD    Thing Types ‚≠ê‚≠ê‚≠ê CRUD    Things ‚≠ê‚≠ê‚≠ê CRUD    Topic Rules ‚≠ê‚≠ê‚≠ê CRUD    Kafka (MSK - Managed Streaming for Kafka) (Pro) üîç     Brokers ‚≠ê‚≠ê Emulated    Cluster Operations ‚≠ê‚≠ê Emulated    Clusters ‚≠ê‚≠ê‚≠ê‚≠ê Emulated Single node clusters   Configurations ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Kinesis üîç     Records ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Split / Merge Shards ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Stream Consumers ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Stream Encryption -     Streams ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Subscribe to Shard ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Kinesis Analytics (Pro) üîç     Applications ‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Kinesis Analytics v2 (Pro) üîç     Applications ‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    KMS üîç     Aliases ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Custom Key Stores ‚≠ê‚≠ê‚≠ê Emulated    Encrypt / Decrypt / Sign Data ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Grants -     Key Policies -     Keys ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Lake Formation (Pro) üîç     Transactions -     Permissions ‚≠ê‚≠ê CRUD    Resources ‚≠ê‚≠ê CRUD    Lambda üîç     Aliases ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Code Signing Configs ‚≠ê‚≠ê CRUD    Custom Images (Pro) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Event Invoke Configs (Destinations) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Event Source Mappings ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Function Concurrencies ‚≠ê‚≠ê‚≠ê CRUD    Functions ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Invoke Functions ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Layers (Pro) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Permissions ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Logs üîç     Destinations ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Export Tasks ‚≠ê‚≠ê CRUD    Log Events ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Log Groups ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Log Streams ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Metric Filters ‚≠ê‚≠ê‚≠ê CRUD    Queries ‚≠ê‚≠ê CRUD    Resource Policies ‚≠ê‚≠ê‚≠ê CRUD    Retention Policies ‚≠ê‚≠ê‚≠ê CRUD    Subscription Filters ‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    MediaStore (Pro) üîç     Access Logging -     Container Policies -     Containers ‚≠ê‚≠ê‚≠ê CRUD    CORS Policies -     Lifecycle Policies -     Metric Policies -     Tags -     MediaStore Data (Pro) üîç     Objects ‚≠ê‚≠ê‚≠ê CRUD    MWAA (Managed Workflows for Apache Airflow) (Pro) üîç     CLI Tokens -     Environments ‚≠ê‚≠ê‚≠ê Emulated    S3 integration (DAG bucket/paths) ‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Web Login ‚≠ê‚≠ê‚≠ê Emulated    Neptune DB (Pro) üîç     DB Clusters ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    DB Cluster Endpoints ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    DB Cluster Parameter Groups ‚≠ê‚≠ê‚≠ê CRUD    DB Cluster Snapshots ‚≠ê‚≠ê Emulated    Event Subscriptions ‚≠ê‚≠ê CRUD    Events -     Global Clusters -     PendingMaintenanceAction -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    OpenSearch Service üîç     Cross-Cluster Search Connections -     OpenSearch Domains ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Packages -     Reserved Instances -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Organizations (Pro) üîç     Accounts ‚≠ê‚≠ê‚≠ê CRUD    Handshakes -     Organization ‚≠ê‚≠ê CRUD    Organizational Units ‚≠ê‚≠ê CRUD    Policies ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    QLDB (Pro) üîç     Blocks ‚≠ê‚≠ê‚≠ê Emulated    Digests ‚≠ê‚≠ê‚≠ê CRUD    Journal Kinesis Streams ‚≠ê‚≠ê‚≠ê CRUD    Journal S3 Exports ‚≠ê‚≠ê‚≠ê CRUD    Ledgers ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Send Commands / Run Queries ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    QLDB Sessions (Pro) üîç     Send Command ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    RDS / Aurora Serverless (Pro) üîç     DB/Cluster Parameter Groups ‚≠ê‚≠ê‚≠ê CRUD    DB/Cluster Snapshots ‚≠ê‚≠ê‚≠ê Emulated    DB Clusters/Instances ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    DB Proxies ‚≠ê‚≠ê Emulated    DB Security/Subnet Groups ‚≠ê‚≠ê‚≠ê Emulated    Event Subscriptions ‚≠ê‚≠ê CRUD    Option Groups ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Postgres AWS Extension Functions ‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    RDS Data (Pro) üîç     Execute sql/statements ‚≠ê‚≠ê‚≠ê Emulated    Transactions ‚≠ê‚≠ê Emulated    Batch Execution -     Redshift (Pro) üîç     Authorize/Revoke Access -     Cluster Parameter Groups ‚≠ê‚≠ê‚≠ê Emulated    Cluster Snapshots ‚≠ê‚≠ê CRUD    Clusters/Instances ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Event Subscriptions -     HSM Configurations -     Partners -     Security/Subnet Groups ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Usage Limits -     Redshift Data (Pro) üîç     Statements ‚≠ê‚≠ê‚≠ê Emulated    Describe Table ‚≠ê‚≠ê‚≠ê Emulated    Batch Execution -     Resource Groups üîç     Resources ‚≠ê‚≠ê‚≠ê CRUD    Groups ‚≠ê‚≠ê‚≠ê CRUD    Group Configurations ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê CRUD    Resource Groups Tagging API üîç     Reports -     Tags ‚≠ê‚≠ê CRUD    Route53 üîç     DNS Server Integration (Pro) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Geo Locations -     Health Checks ‚≠ê‚≠ê CRUD    Hosted Zones ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Query Logging Configs -     Resource Record Sets ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Reusable Delegation Sets ‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Traffic Policies ‚≠ê‚≠ê‚≠ê CRUD    Route53 Resolver üîç     S3 üîç     Bucket ACLs ‚≠ê‚≠ê‚≠ê Emulated    Bucket CORS ‚≠ê‚≠ê‚≠ê Emulated    Bucket Encryptions ‚≠ê‚≠ê‚≠ê Emulated    Bucket Lifecycles ‚≠ê‚≠ê‚≠ê Emulated    Bucket Loggings ‚≠ê‚≠ê‚≠ê Emulated    Bucket Metrics Configurations ‚≠ê‚≠ê‚≠ê Emulated    Bucket Notifications ‚≠ê‚≠ê‚≠ê Emulated Supported notification targets: SQS, SNS, Lambda; Supported notification events: ObjectCreated, ObjectRemoved, ObjectTagging   Bucket Ownership Controls ‚≠ê‚≠ê‚≠ê Emulated    Bucket Policies ‚≠ê‚≠ê‚≠ê Emulated    Bucket Replications ‚≠ê‚≠ê‚≠ê Emulated    Bucket Request Payments ‚≠ê‚≠ê‚≠ê Emulated    Bucket Versionings ‚≠ê‚≠ê‚≠ê Emulated    Bucket Websites ‚≠ê‚≠ê‚≠ê Emulated    Buckets ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Object Retentions ‚≠ê‚≠ê Emulated    Object Versions ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Objects ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Presigned URLs ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Upload/Download Files ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    S3 Control üîç     Access Point Policies ‚≠ê‚≠ê CRUD    Access Points ‚≠ê‚≠ê CRUD    Jobs -     Lifecycle configurations -     Multi-region Access Points -     Public Access Blocks ‚≠ê‚≠ê CRUD    Storage Lens -     SageMaker (Pro) üîç     Actions -     Algorithms -     App Image Configs -     Apps -     Artifacts -     Associations -     Auto ML Jobs -     Code Repositories -     Compilation Jobs -     Contexts -     Data Quality Job Definitions -     Device Fleets -     Devices -     Domains -     Edge Packaging Jobs -     Endpoints / Endpoint Configs ‚≠ê‚≠ê CRUD    Experiments -     Feature Groups -     Flow Definitions -     Hyper Parameter Tuning Jobs -     Images / Image Versions -     Labelling Jobs -     Model Bias/Explainability Jobs -     Model Packages -     Models ‚≠ê‚≠ê CRUD    Monitoring Executions/Schedules -     Notebook Instances ‚≠ê‚≠ê CRUD    Pipeline Executions -     Pipelines -     Projects -     Tags -     Training Jobs ‚≠ê‚≠ê Emulated    Transform Jobs -     Trials ‚≠ê‚≠ê CRUD    User Profiles -     Workforces / Workteams -     SecretsManager üîç     Resource Policies ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Secret Replications ‚≠ê‚≠ê CRUD    Secret Rotations ‚≠ê‚≠ê CRUD    Secrets ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Serverless Repo (Pro) üîç     Applications ‚≠ê‚≠ê‚≠ê CRUD    Application Policies -     CloudFormation templates ‚≠ê‚≠ê‚≠ê Emulated    Service Discovery (CloudMap) (Pro) üîç     Namespaces ‚≠ê‚≠ê‚≠ê CRUD    SES üîç     Configuration Sets ‚≠ê‚≠ê‚≠ê CRUD    Identities ‚≠ê‚≠ê CRUD    Identity Policies ‚≠ê‚≠ê CRUD    Quotas / Statistics ‚≠ê‚≠ê CRUD    Receipt Filters ‚≠ê‚≠ê‚≠ê CRUD    Receipt Rules ‚≠ê‚≠ê‚≠ê CRUD    Sending Emails via SMTP (Pro) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Templates ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    SESv2 (Pro) üîç     Identities ‚≠ê‚≠ê CRUD    Sending Emails via SMTP ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Templates ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    SNS üîç     Platform Applications ‚≠ê‚≠ê‚≠ê CRUD    Publish/Subscribe to Topics ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    SMS Attributes / Sandbox Accounts ‚≠ê‚≠ê CRUD    Subscriptions ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Topics ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    SQS üîç     FIFO Queues ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Message Deduplication ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Message Visibility ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Messages ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Permission ‚≠ê‚≠ê‚≠ê CRUD    Query API ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Standard Queues ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    SSM üîç     Associations ‚≠ê‚≠ê‚≠ê CRUD    Calendar States ‚≠ê‚≠ê CRUD    Commands / Command Invocations ‚≠ê‚≠ê‚≠ê CRUD    Compliance Items ‚≠ê‚≠ê CRUD    Documents ‚≠ê‚≠ê‚≠ê CRUD    Inventory Entries -     Ops Metadata ‚≠ê‚≠ê CRUD    Parameters ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Resource Compliance Summaries -     Tags ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    StepFunctions üîç     Activities ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Executions / Execution History ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    State Machines ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    STS üîç     Assume Role (Pro) ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Get Access Key Info -     Get Caller Identity ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Session Tokens ‚≠ê‚≠ê‚≠ê‚≠ê CRUD    Support üîç     Cases ‚≠ê‚≠ê‚≠ê CRUD    TrustedAdvisorChecks ‚≠ê‚≠ê CRUD    Attachments -     SWF üîç     Domain ‚≠ê‚≠ê‚≠ê CRUD    Activity ‚≠ê‚≠ê‚≠ê CRUD    Workflows ‚≠ê‚≠ê‚≠ê CRUD    Domains ‚≠ê‚≠ê‚≠ê CRUD    Timestream (query, write) (Pro) üîç     Databases ‚≠ê‚≠ê‚≠ê Emulated    Run Query ‚≠ê‚≠ê‚≠ê Emulated    Tables ‚≠ê‚≠ê‚≠ê Emulated    Tags ‚≠ê‚≠ê‚≠ê CRUD    Write Records ‚≠ê‚≠ê‚≠ê Emulated    Transfer (Pro) üîç     Accesses -     Security Policies -     Servers ‚≠ê‚≠ê‚≠ê Emulated    SSH Public Keys ‚≠ê‚≠ê‚≠ê CRUD    Tags -     Users ‚≠ê‚≠ê‚≠ê Emulated    XRay (Pro) üîç     Encryption Configs -     Groups -     Insights -     Sampling Rules ‚≠ê‚≠ê‚≠ê CRUD    Service Graph -     Tags -     Telemetry Records ‚≠ê‚≠ê‚≠ê‚≠ê Emulated    Trace Graph -     Trace Segments / Summaries ‚≠ê‚≠ê‚≠ê CRUD     ","categories":"","description":"Overview of the implemented AWS APIs and their level of parity with the AWS cloud\n","excerpt":"Overview of the implemented AWS APIs and their level of parity with ‚Ä¶","ref":"/aws/feature-coverage/","tags":"","title":"AWS Service Feature Coverage"},{"body":"Overview The AWS Command Line Interface (CLI) is a unified tool to manage AWS services from the command line. All CLI commands that access services that are implemented in LocalStack can be run against LocalStack.\nThere are two ways to use the CLI:\n Use our awslocal drop-in replacement: $ awslocal kinesis list-streams Configure AWS test environment variables and add the --endpoint-url=\u003clocalstack-url\u003e flag to your aws CLI invocations. For example: $ export AWS_ACCESS_KEY_ID=\"test\" $ export AWS_SECRET_ACCESS_KEY=\"test\" $ export AWS_DEFAULT_REGION=\"us-east-1\" $ aws --endpoint-url=http://localhost:4566 kinesis list-streams  AWS CLI Use the below command to install aws, if not installed already.\n$ pip install awscli Setting up local region and credentials to run LocalStack aws requires the region and the credentials to be set in order to run the aws commands. Create the default configuration and the credentials. Below key will ask for the Access key id, secret Access Key, region \u0026 output format. Config \u0026 credential file will be created under ~/.aws folder\n$ aws configure --profile default Note Please use test as value for AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY to make pre-signed URLs for S3 buckets work. Our pre-signed URL signature verification algorithm validates the pre-signed URL and its expiration. You can configure credentials into the system environment using export command on Linux/Mac systems. You also can add credentials in ~/.aws/credentials file directly.\nexport AWS_ACCESS_KEY_ID=test export AWS_SECRET_ACCESS_KEY=test   LocalStack AWS CLI (awslocal) awslocal is a thin wrapper and a drop-in replacement for the aws command that runs commands directly against LocalStack (no need to specify --endpoint-url anymore). The source code can be found on GitHub: https://github.com/localstack/awscli-local\nInstallation You can install the awslocal command via pip:\n$ pip install awscli-local[ver1] Note that the command above also installs the latest version of the underlying AWS CLI version 1 (awscli) package. Use this command if you prefer to manage your own version of awscli (e.g., v1/v2) and install the wrapper script only: $ pip install awscli-local\nNote: Automatic installation of AWS CLI version 2 is currently not supported yet (at the time of writing there is no official pypi package for v2 available), but the awslocal technically also works with AWS CLI v2 (see this section for more details).  Usage The awslocal command has the same usage as the aws command. For detailed usage, please refer to the man pages of aws help.\nConfigurations You can use the following environment variables for configuration:\n   Variable Description     LOCALSTACK_HOST Set the hostname for the localstack instance. Useful when you have localstack is bound to another interface (i.e. docker-machine).   USE_SSL Whether to use https endpoint URLs (required if LocalStack has been started with USE_SSL=true enabled). Defaults to false.   DEFAULT_REGION Set the default region. Overrides AWS_DEFAULT_REGION environment variable.    Limitations Please note that there is a known limitation for using the cloudformation package ... command with the AWS CLI v2. The problem is that the AWS CLI v2 is not available as a package on pypi.org, but is instead shipped as a binary package that cannot be easily patched from awslocal. To work around this issue, you have 2 options:\n Downgrade to the v1 AWS CLI (this is the recommended approach) There is an inofficial way to install AWS CLI v2 from sources. We do not recommend this, but it is technically possible. Also, you should install these libraries in a Python virtualenv, to avoid version clashes with other libraries on your system:  $ virtualenv .venv $ . .venv/bin/activate $ pip install https://github.com/boto/botocore/archive/v2.zip https://github.com/aws/aws-cli/archive/v2.zip AWS CLI v2 Automatic installation of AWS CLI version 2 is currently not supported (at the time of writing there is no official pypi package for v2 available), but the awslocal technically also works with AWS CLI v2 (see this section for more details).\nAWS CLI v2 with Docker and LocalStack By default, the container running amazon/aws-cli is isolated from 0.0.0.0:4566 on the host machine, that means that aws-cli cannot reach localstack through your shell.\nTo ensure that the two docker containers can communicate create a network on the docker engine:\n$ docker network create localstack 0c9cb3d37b0ea1bfeb6b77ade0ce5525e33c7929d69f49c3e5ed0af457bdf123 Then modify the docker-compose.yml specifying the network to use:\nnetworks:default:external:name:\"localstack\"Run AWS Cli v2 docker container using this network (example):\n$ docker run --network localstack --rm -it amazon/aws-cli --endpoint-url=http://localstack:4566 lambda list-functions { \"Functions\": [] } If you use AWS CLI v2 from a docker container often, create an alias:\n$ alias laws='docker run --network localstack --rm -it amazon/aws-cli --endpoint-url=http://localstack:4566' So you can type:\n$ laws lambda list-functions { \"Functions\": [] } ","categories":"","description":"How to use the AWS Command Line Interface (CLI) with LocalStack.\n","excerpt":"How to use the AWS Command Line Interface (CLI) with LocalStack.\n","ref":"/integrations/aws-cli/","tags":"","title":"AWS Command Line Interface"},{"body":"LocalStack is a cloud service emulator that runs in a single container on your laptop or in your CI environment. With LocalStack, you can run your AWS applications or Lambdas entirely on your local machine without connecting to a remote cloud provider! Whether you are testing complex CDK applications or Terraform configurations, or just beginning to learn about AWS services, LocalStack helps speed up and simplify your testing and development workflow.\nLocalStack supports a growing number of AWS services, like AWS Lambda, S3, DynamoDB, Kinesis, SQS, SNS, and many more! The Pro version of LocalStack supports additional APIs and advanced features. You can find a comprehensive list of supported APIs on our ‚≠ê Feature Coverage page.\nLocalStack also provides additional features to make your life as a cloud developer easier! Check out LocalStack‚Äôs Cloud Developer Tools.\nGet LocalStack Up and Running The first thing when getting started with LocalStack is to choose your preferred way of starting and managing your LocalStack instance.\nLocalStack currently provides the following options:\n  LocalStack CLI\nThe easiest way to start and manage LocalStack - either on your machine, in a Docker container on your machine, or even on a remote Docker host.\n  LocalStack Cockpit\nGet a desktop experience and work with your local LocalStack instance via the UI.\n  Docker\nUse the docker CLI to manually start the LocalStack Docker container.\n  Docker-Compose\nUse docker-compose to configure and start your LocalStack Docker container.\n  Helm\nUse helm to create a LocalStack deployment in a Kubernetes cluster.\n  LocalStack CLI The LocalStack CLI aims to simplify starting and managing LocalStack. It provides convenience features to start LocalStack on your local machine, as a Docker container on your machine, or even on a remote Docker host. In addition you can easily check the status or open a shell in your LocalStack instance if you want to take a deep-dive.\nPrerequisites Please make sure to install the following tools on your machine before moving on:\n python (Python 3.7 up to 3.10 is supported) pip (Python package manager) docker  Installation The easiest way to install the LocalStack CLI is via pip:\n$ python3 -m pip install localstack Note: Please do not use sudo or the root user - LocalStack should be installed and started entirely under a local non-root user. If you have problems with permissions in MacOS X Sierra, install with python3 -m pip install --user localstack.  Afterwards you should be able to use the LocalStack CLI in your terminal:\n$ localstack --help Usage: localstack [OPTIONS] COMMAND [ARGS]... The LocalStack Command Line Interface (CLI) Options: ... Updates The LocalStack CLI also allows you to easily update the different components of LocalStack. You can decide to update the CLI itself, the LocalStack Docker images, or all at once: $ # Print the available commands $ localstack update $ # Update all components $ localstack update all $ # Only update the LocalStack docker images $ localstack update docker-images $ # Only update the LocalStack CLI $ localstack update localstack-cli\nTroubleshooting The installation is successful, but I cannot execute localstack on my terminal. If you can successfully install LocalStack using pip but you cannot use it in your terminal, you most likely haven‚Äôt set up your operating system‚Äôs / terminal‚Äôs PATH variable (in order to tell them where to find programs installed via pip).\n If you are using Windows, you can enable the PATH configuration when installing Python, as described in the official docs of Python. If you are using a MacOS or Linux operating system, please make sure that the PATH is correctly set up - either system wide, or in your terminal.  As a workaround you can call the LocalStack CLI python module directly: $ python3 -m localstack.cli.main\nStarting LocalStack with the LocalStack CLI By default, LocalStack is started inside a Docker container by running:\n$ localstack start Notes   This command loads all services provided by LocalStack, they will however be started on the first request reaching this service.\n  By default, LocalStack uses the image tagged latest that is cached on your machine, and will not pull the latest image automatically from Docker Hub (i.e., the image needs to be pulled manually if needed).\n  From 2020-07-11 onwards, the default image localstack/localstack in Docker Hub refers to the ‚Äúlight version‚Äù, which has some large dependency files like Elasticsearch removed (and lazily downloads them, if required). (Note that the localstack/localstack-light image alias may get removed in the future). In case you need the full set of dependencies, the localstack/localstack-full image can be used instead. Please also refer to the USE_LIGHT_IMAGE environment variable.\n  Although we strongly recommend to use Docker, the infrastructure can also be spun up directly on the host machine using the --host startup flag. Note that this will require additional dependencies, and is not supported on some operating systems, including Windows.\n   LocalStack Cockpit See LocalStack Cockpit.\nDocker If you do not want to use the LocalStack CLI, you can also decide to manually start the LocalStack Docker container.\nPrerequisites Please make sure that you have a working docker environment on your machine before moving on. You can check if docker is correctly configured on your machine by executing docker info in your terminal. If it does not report an error (but shows information on your Docker system), you‚Äôre good to go.\nStarting LocalStack with Docker You can start the Docker container simply by executing the following docker run command: $ docker run --rm -it -p 4566:4566 -p 4510-4559:4510-4559 localstack/localstack\nNotes   This command pulls the current nightly build from the master branch (if you don‚Äôt have the image locally) and not the latest supported version. If you want to use a specific version, use the appropriate tag (for example localstack/localstack:1.0.0).\n  This command reuses the image if it‚Äôs already on your machine, i.e. it will not pull the latest image automatically from Docker Hub.\n  This command does not bind all ports which are potentially used by LocalStack, nor does it mount any volumes. When using Docker to manually start LocalStack, you will have to configure the container on your own. This could be seen as the ‚Äúexpert mode‚Äù of starting LocalStack. If you are looking for a simpler method of starting LocalStack, please use the LocalStack CLI.\n  To facilitate interoperability, configuration variables can be prefixed with LOCALSTACK_ in docker. For instance, setting LOCALSTACK_PERSISTENCE=1 is equivalent to PERSISTENCE=1.\n   Docker-Compose If you want to manually manage your Docker container, it‚Äôs usually a good idea to use docker-compose in order to simplify your container configuration.\nPrerequisites  docker docker-compose (version 1.9.0+)  Starting LocalStack with Docker-Compose You can use the docker-compose.yml file from the official LocalStack repository and use this command (currently requires docker-compose version 1.9.0+):\n$ docker-compose up Notes   This command pulls the current nightly build from the master branch (if you don‚Äôt have the image locally) and not the latest supported version. If you want to use a specific version, use the appropriate tag (for example localstack/localstack:1.0.0).\n  This command reuses the image if it‚Äôs already on your machine, i.e. it will not pull the latest image automatically from Docker Hub.\n  To facilitate interoperability, configuration variables can be prefixed with LOCALSTACK_ in docker. For instance, setting LOCALSTACK_PERSISTENCE=1 is equivalent to PERSISTENCE=1.\n  Before 0.13: If you do not connect your LocalStack container to the default bridge network with network_mode: bridge as in the example, you need to set LAMBDA_DOCKER_NETWORK=\u003cdocker-compose-network\u003e.\n  If using using the Docker default bridge network using network_mode: bridge, container name resolution will not work inside your containers. Please consider removing it, if this functionality is needed.\n   Please note that there‚Äôs a few pitfalls when configuring your stack manually via docker-compose (e.g., required container name, Docker network, volume mounts, environment variables, etc.). We recommend using the LocalStack CLI to validate your configuration, which will print warning messages in case it detects any (potential) misconfigurations:\n$ localstack config validate ... Helm If you want to deploy LocalStack in your Kubernetes cluster, you can use Helm.\nPrerequisites  Kubernetes Helm  Deploy LocalStack using Helm You can deploy LocalStack in a Kubernetes cluster by running these commands: $ helm repo add localstack-repo https://helm.localstack.cloud $ helm upgrade --install localstack localstack-repo/localstack\nThe Helm charts are not maintained in the main repository, but in a separate one.\nRan into trouble? We strive to make it as easy as possible for you to use LocalStack, and we are very grateful for any feedback. If you run into any issues or problems with this guide, please submit an issue.\nWhat‚Äôs next? Now that you have LocalStack up and running, the following resources might be useful for your next steps:\n Use the LocalStack integrations to interact with LocalStack and other integrated tools, for example:  Use awslocal to use the AWS CLI against your local cloud! Use the Serverless Framework with LocalStack! And many more!   Find out how to configure LocalStack such that it perfectly fits your need. Use LocalStack in your CI environment to increase your code quality. Checkout LocalStack‚Äôs Cloud Developer Tools to further increase your development efficiency with LocalStack. Find out about the ways you can configure LocalStack.  ","categories":"","description":"How to get up to speed with LocalStack.\n","excerpt":"How to get up to speed with LocalStack.\n","ref":"/get-started/","tags":"","title":"Get Started"},{"body":" Note: We have recently added a couple of refactorings and enhancements in the core framework and application architecture, hence this page is no longer fully up to date. We‚Äôre planning to publish an updated version soon.  General Application Architecture The coarse-grained system architecture is illustrated in the figure below. The LocalStack components are either installed on the local machine, or the entire application runs in a Docker container. The application exposes a set of external network ports (see defaults in constants.py). Client applications can use the standard AWS SDKs to connect to LocalStack; most SDKs have a configuration option to configure the endpoint URLs of the target services (e.g., configure http://localhost:4572 as endpoint URL to connect to local DynamoDB).\nTo handle incoming requests on the external network ports, LocalStack uses proxy threads which inspect the incoming request message, forward the requests to corresponding backend service processes, and perform any additional processing. The additional processing is required because some of the backend services only provide the basic ‚ÄúCRUD‚Äù functionality for maintaining API state, and LocalStack provides integrations on top of these services. This makes the backend services easily replaceable with best-of-breed implementations.\nProxy Interceptors For the basic ‚ÄúCRUD‚Äù functionality of most services we‚Äôre using a mock implementation (e.g., based on moto) in the background, and LocalStack adds a bunch of integrations on top of these services. We start up an HTTP proxy which intercepts all invocations and forwards requests to the backend. This allows us to add extended functionality without having to change the backend service.\nThe figure below illustrates the proxy mechanism and ports for the API Gateway service. (The default ports can be found in https://github.com/localstack/localstack/blob/master/localstack/constants.py )\n -------- ------------- ------------- | Client | -\u003e | Proxy | -\u003e | Backend | | | | (port 4567) | | (port 4566) | -------- ------------- ------------- The proxy follows a simple protocol by implementing 2 methods: forward_request which is called before a request is forwarded to the backend, and return_response which is called after a response has been received from the backend: https://github.com/localstack/localstack/blob/master/localstack/services/generic_proxy.py\nThe proxy implementation for API Gateway can be found here: https://github.com/localstack/localstack/blob/master/localstack/services/apigateway/apigateway_listener.py#L81\n","categories":"","description":"This document contains a few essential instructions for developing new features and bug fixes for *LocalStack*.\n","excerpt":"This document contains a few essential instructions for developing new ‚Ä¶","ref":"/developer-guide/basics/","tags":"","title":"Basics"},{"body":"This guide describes how to start and use LocalStack in your CircleCI pipelines.\nThe LocalStack Circle CI Orb LocalStack is an official partner of Circle CI and can easily be integrated into your pipeline by using the official CircleCI Orb.\nThe Orb‚Äôs documentation features examples, as well as a description of the available commands.\nWhen using the official CircleCI Orb, using LocalStack in your pipeline is as easy as adding the Orb to your pipeline and executing the startup command.\nThe following example CircleCI config (.circleci/config.yml) starts LocalStack, creates a new S3 bucket, and prints a nice message in the end:\nversion:2.1orbs:localstack:localstack/platform@1.0jobs:run-integration-tests:executor:localstack/defaultsteps:- localstack/startup- run:command:awslocal s3 mb s3://test-bucket- run:command:echo \"Execute your tests here :)\"workflows:integration-test:jobs:- run-integration-testsActivate LocalStack Pro You can easily enable LocalStack Pro by adding your API key to the project‚Äôs environment variables. The LocalStack Orb will automatically pick it up and activate the Pro features.\nJust go to the project settings in CircleCI, click on Environment Variables in the sidebar and add your API key:\nRan into trouble? If you run into any issues or problems while integrating LocalStack with CircleCI, please submit an issue.\n","categories":"","description":"Use LocalStack in [Circle CI](https://circleci.com/)\n","excerpt":"Use LocalStack in [Circle CI](https://circleci.com/)\n","ref":"/ci/circle-ci/","tags":["continuous-integration","ci","continuous-delivery","testing"],"title":"CircleCI"},{"body":"Overview This guide explains how to integrate LocalStack with the Serverless Framework. Although it probably requires a few code changes, integrating LocalStack with the Serverless Framework is fairly straightforward.\nIn particular, the setup consists of the following two steps.\n Installing and configuring the Serverless-LocalStack plugin. Adjusting AWS endpoints in Lambda functions.  Prerequisites This guide assumes that you have the following tools installed.\n LocalStack (Install) Serverless (Install)  It also assumes that you already have a Serverless app set up consisting of a couple of Lambda functions and a serverless.yml file similar to the following. An example Serverless app integrated with LocalStack can be found here:  Simple REST API using the Serverless Framework and LocalStack\nservice:my-serviceframeworkVersion:\"\u003e=1.1.0 \u003c=2.50.0\"provider:name:awsruntime:python3.8environment:DYNAMODB_TABLE:${self:service}-${opt:stage, self:provider.stage}iamRoleStatements:- Effect:AllowAction:- dynamodb:Query- ...Resource:\"arn:aws:dynamodb:${opt:region, self:provider.region}:*:table/${self:provider.environment.DYNAMODB_TABLE}\"functions:create:handler:todos/create.createevents:- http:path:todosmethod:postcors:true...resources:Resources:TodosDynamoDbTable:Type:'AWS::DynamoDB::Table'DeletionPolicy:RetainProperties:...TableName:${self:provider.environment.DYNAMODB_TABLE}Install and configure Serverless-LocalStack Plugin To install the plugin, execute the following command in the root of your project. $ npm install -D serverless-localstack\nNext, set up the plugin by adding the following properties to serverless.yml.\n...plugins:- serverless-localstackcustom:localstack:stages:- localThis sets up Serverless to use the LocalStack plugin but only for the stage ‚Äúlocal‚Äù. Next, you need make minor adjustments to your function code in order to make your application work no matter if it is deployed on AWS or LocalStack.\nAdjust AWS endpoints in Lambda functions You are likely using an AWS SDK (such as Boto3 for Python) in your Lambda functions to interact with other AWS services such as DynamoDB.\nFor example, in Python, your code to set up a connection to DynamoDB may look like this:\n... dynamodb = boto3.resource('dynamodb') ... By default, this call attempts to create a connection via the usual AWS endpoints. However, when running services in LocalStack, we need to make sure, our applications creates a connection via the LocalStack endpoint instead.\nUsually, all of LocalStack‚Äôs services are available via a specific port on localhost (e.g. localhost:4566). However, this endpoint only works when accessing LocalStack from outside its Docker runtime.\nSince the Lambda functions execute within the LocalStack Docker container, Lambda functions cannot access other services via the usual localhost endpoint.\nInstead, LocalStack provides a special environment variable LOCALSTACK_HOSTNAME which contains the internal endpoint of the LocalStack services from within its runtime environment.\nHence, you need to configure the Lambda functions to use the LOCALSTACK_HOSTNAME endpoint when accessing other AWS services in LocalStack.\nIn Python, this may look something like. The code detects if it is running in LocalStack by checking if the LOCALSTACK_HOSTNAME variable exists and then configures the endpoint URL accordingly.\n... if 'LOCALSTACK_HOSTNAME' in os.environ: dynamodb_endpoint = 'http://%s:4566' % os.environ['LOCALSTACK_HOSTNAME'] dynamodb = boto3.resource('dynamodb', endpoint_url=dynamodb_endpoint) else: dynamodb = boto3.resource('dynamodb') ...  Ideally, we want to make LocalStack‚Äôs Lambda execution environment ‚ÄúLocalStack-agnostic‚Äù, so that you are not required to adjust endpoints in your function code anymore. You want to help us with that? Drop us a line in Slack!.\n Deploying to LocalStack You can now deploy your Serverless service to LocalStack.\nFirst, start LocalStack by running $ localstack start\nThen deploy the endpoint by running $ serverless deploy --stage local\nThe expected result should be similar to:\nServerless: Packaging service... Serverless: Excluding development dependencies... Serverless: Creating Stack... Serverless: Checking Stack create progress... ........ Serverless: Stack create finished... Serverless: Uploading CloudFormation file to S3... Serverless: Uploading artifacts... Serverless: Uploading service my-service.zip file to S3 (38.3 KB)... Serverless: Validating template... Serverless: Skipping template validation: Unsupported in Localstack Serverless: Updating Stack... Serverless: Checking Stack update progress... ..................................... Serverless: Stack update finished... Service Information service: my-service stage: local region: us-east-1 stack: my-service-local resources: 35 api keys: None endpoints: http://localhost:4566/restapis/XXXXXXXXXX/local/_user_request_ functions: ... layers: None Use the displayed endpoint http://localhost:4566/restapis/XXXXXXXXXX/local/_user_request_/my/custom/endpoint to make requests to the deployed service.\nAdvanced topics Local code mounting for lambda functions serverless-localstack supports a feature for lambda functions that allows local code mounting:\n# serverless.ymlcustom:localstack:# ...lambda:mountCode:TrueWhen this flag is set, the lambda code will be mounted into the container running the function directly from your local directory instead of packaging and uploading it.\nIf you want to use this feature together with the local lambda executor (LAMBDA_EXECUTOR=local), you need to make sure the container running localstack itself can find the code. To do that, you need to manually mount the code into the localstack container, here is a snippet using a docker-compose.yml with the essentials. Where /absolute/path/to/todos is the path on your local machine that points to the todos/ directory containing the lambda code from our previous example.\n# docker-compose.yml to start localstackservices:localstack:# ...environment:- LAMBDA_EXECUTOR=local- LAMBDA_REMOTE_DOCKER=0# ...volumes:# ...- \"/absolute/path/to/todos:/absolute/path/to/todos\"Ran into trouble? If you run into any issues or problems while integrating LocalStack with your Serverless app, please submit an issue.\n","categories":"","description":"Use the Serverless Framework with LocalStack\n","excerpt":"Use the Serverless Framework with LocalStack\n","ref":"/integrations/serverless-framework/","tags":["serverless-framework"],"title":"Serverless Framework"},{"body":" Note: We have recently added a couple of refactorings and enhancements in the core framework and application architecture, hence this page is no longer fully up to date. We‚Äôre planning to publish an updated version soon.  Development requirements You will need the following tools for local development of LocalStack.\n Python 3.10+ Sasl Pip Virtualenv OpenJDK Node \u0026 npm Maven Gradle Terraform Docker Docker-Compose  Installation instructions Below are some basic installation instructions for the dependencies you will need (assuming you‚Äôre on Debian/Ubuntu Linux). In the case of Fedora/CentOS, most of the packages have pretty much the same name, with a few exceptions.\n  Python 3.10+\nupdate-alternatives --install /usr/bin/python python /usr/bin/python3.10 2   Sasl\nFor Debian\napt install libsasl2-dev For Fedora\ndnf install cyrus-sasl-devel   Pip\napt-get install python3-pip update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 2   Virtualenv\npip install virtualenv   OpenJDK\nFor Debian\napt-get install openjdk-11-jdk For Fedora\nsudo dnf install java-11-openjdk   Node\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - apt-get install -y nodejs   Maven\nwget https://mirrors.estointernet.in/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.zip -O /opt/apache-maven-3.6.3-bin.zip unzip /opt/apache-maven-3.6.3-bin.zip -d /opt/   Gradle\nwget https://services.gradle.org/distributions/gradle-6.7-bin.zip -O /opt/gradle-6.7-bin.zip unzip /opt/gradle-6.7-bin.zip -d /opt/   Terraform\ncurl -L -o /opt/terraform/terraform.zip https://releases.hashicorp.com/terraform/0.13.4/terraform_0.13.4_linux_amd64.zip (cd /opt/terraform \u0026\u0026 unzip -q /opt/terraform/terraform.zip \u0026\u0026 rm /opt/terraform/terraform.zip)   Adding Environment variable\necho \"PATH=$PATH:/opt/apache-maven-3.6.3/bin:/opt/gradle-6.7/bin:/opt/terraform\" \u003e\u003e ~/.bashrc \u0026\u0026 source ~/.bashrc   Docker\ncurl -sSLk https://get.docker.com | bash -   Docker-Compose\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose   Development Environment If you pull the repo in order to extend/modify LocalStack, run this command to install all the dependencies:\nmake install This will install the required pip dependencies in a local Python virtualenv directory .venv (your global python packages will remain untouched), as well as some node modules in ./localstack/node_modules/. Depending on your system, some pip/npm modules may require additional native libs installed.\nThe Makefile contains a start command to conveniently start:\nmake start Building the Docker image for Development Please note that there are a few commands we need to run on the host to prepare the local environment for the Docker build - specifically, downloading some dependencies like the StepFunctions local binary. Therefore, simply running docker build . in a fresh clone of the repo may not work.\nWe generally recommend using this command to build the Docker image locally (works on Linux/MacOS):\nmake docker-build Tips  If virtualenv chooses system python installations before your pyenv installations, manually initialize virtualenv before running make install like this: virtualenv -p ~/.pyenv/shims/python3.10 .venv . Terraform needs version \u003c0.14 to work currently. Use tfenv (https://github.com/tfutils/tfenv) to manage terraform versions comfortable. Quick start: tfenv install 0.13.7 \u0026\u0026 tfenv use 0.13.7 Set env variable LS_LOG=‚Äòtrace‚Äô to print every http request sent to localstack and their responses. Useful for debugging certain issues. As per dev guide, it requires libsasl2-dev. Arch based Distro equivalent: libsasl  ","categories":"","description":"Set up your development environment for developing LocalStack.\n","excerpt":"Set up your development environment for developing LocalStack.\n","ref":"/developer-guide/setup/","tags":"","title":"Setup and requirements"},{"body":"Overview In this guide, you will learn how to use LocalStack to test your serverless applications powered by Spring Cloud Function framework.\n   Complexity ‚òÖ‚òÖ‚òÖ‚òÜ‚òÜ     Time to read 30 minutes   Edition community [pro]   Platform x64_86 (-aarch64)    aarch64 warning Some features and services described in this document may not work properly on aarch64, including Apple‚Äôs M1 silicon  Covered Topics We will create a new Rest API application that will route requests to a Cloud Function using functionRouter and routing expressions.\nThe primary language for the application is Kotlin powered by Gradle build tool, but the described concepts would work for any other JVM setup.\n Limitations Setting up an Application  Starting a new Project Project Settings Configure Log4J2 for AWS Lambda Configure Spring Cloud Function for Rest API Define an Application class Configure Jackson Define Logging Utility Add Request/Response utilities Creating a sample Model / DTO Creating Rest API endpoints Cold Start and Warmup (PRO) Creating other lambda Handlers   Setting up Deployment Testing, Debugging and Code hot-swapping Useful links  Limitations This document demonstrates the usage of the Spring Cloud Function framework together with LocalStack. It does not cover some of the application-specific topics, like 404 error handling, or parametrized routing, that you need to consider when building production-ready applications.\nSetting up an Application We recommend using jenv to manage multiple Java runtimes.\nStarting a new Project Please follow the instructions from the official website to install the Gradle build tool on your machine.\nThen run the following command to initialize a new Gradle project\n$ gradle init Running the command below will run the gradle wrapper task\n$ gradle wrapper After running the wrapper task, you will find the Gradle wrapper script gradlew. From now on, we will use the wrapper instead of the globally installed Gradle binary:\n$ ./gradlew \u003ccommand\u003e Project Settings Let‚Äôs give our project a name: open settings.gradle, and adjust the autogenerated name to something meaningful.\nrootProject.name = 'localstack-sampleproject' Now we need to define our dependencies. Here‚Äôs a list of what we will be using in our project.\nGradle plugins:\n java kotlin jvm kotlin spring plugin spring boot plugin spring dependency management plugin shadow plugin  Dependencies:\n kotlin stdlib spring cloud starter function web spring cloud function adapter for aws lambda log4j2 lambda events jackson core jackson databind jackson annotations jackson module kotlin  In order to deploy our application to AWS, we need to build so-called ‚Äúfat jar‚Äù which contains all application dependencies. To that end, we use the ‚ÄúShadow Jar‚Äù plugin.\nHere‚Äôs our final build.gradle:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76  plugins { id \"java\" id \"org.jetbrains.kotlin.jvm\" version '1.5.31' id \"org.jetbrains.kotlin.plugin.spring\" version '1.5.31' id 'org.springframework.boot' version '2.5.5' id \"io.spring.dependency-management\" version '1.0.11.RELEASE' id \"com.github.johnrengelman.shadow\" version '7.0.0' } group = 'org.localstack.sampleproject' sourceCompatibility = 11 tasks.withType(JavaCompile) { options.encoding = 'UTF-8' } repositories { mavenCentral() maven { url \"https://plugins.gradle.org/m2/\" } } ext { springCloudVersion = \"3.1.4\" awsLambdaLog4jVersion = \"1.2.0\" awsLambdaJavaEventsVersion = \"3.10.0\" jacksonVersion = \"2.12.5\" } dependencies { implementation \"org.jetbrains.kotlin:kotlin-stdlib\" implementation \"org.springframework.cloud:spring-cloud-starter-function-web:$springCloudVersion\" implementation \"org.springframework.cloud:spring-cloud-function-adapter-aws:$springCloudVersion\" implementation \"com.amazonaws:aws-lambda-java-log4j2:$awsLambdaLog4jVersion\" implementation \"com.amazonaws:aws-lambda-java-events:$awsLambdaJavaEventsVersion\" implementation \"com.fasterxml.jackson.core:jackson-core:$jacksonVersion\" implementation \"com.fasterxml.jackson.core:jackson-databind:$jacksonVersion\" implementation \"com.fasterxml.jackson.core:jackson-annotations:$jacksonVersion\" implementation \"com.fasterxml.jackson.module:jackson-module-kotlin:$jacksonVersion\" } import com.github.jengelman.gradle.plugins.shadow.transformers.* // Configure the main class jar { manifest { attributes 'Start-Class': 'org.localstack.sampleproject.Application' } } // Build a fatjar (with dependencies) for aws lambda shadowJar { transform(Log4j2PluginsCacheFileTransformer) dependencies { exclude( dependency(\"org.springframework.cloud:spring-cloud-function-web:${springCloudVersion}\") ) } // Required for Spring  mergeServiceFiles() append 'META-INF/spring.handlers' append 'META-INF/spring.schemas' append 'META-INF/spring.tooling' transform(PropertiesFileTransformer) { paths = ['META-INF/spring.factories'] mergeStrategy = \"append\" } } assemble.dependsOn shadowJar   Please note that we will be using org.localstack.sampleproject as a working namespace, and org.localstack.sampleproject.Application as an entry class for our application. You can adjust it for your needs, but don‚Äôt forget to change your package names accordingly.\nConfigure Log4J2 for AWS Lambda Spring framework comes with Log4J logger, so all we need to do is to configure it for AWS Lambda. In this project, we are following official documentation to setup up src/main/resources/log4j2.xml content.\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cConfiguration packages=\"com.amazonaws.services.lambda.runtime.log4j2.LambdaAppender\"\u003e \u003cAppenders\u003e \u003cLambda name=\"Lambda\"\u003e \u003cPatternLayout\u003e \u003cpattern\u003e%d{yyyy-MM-dd HH:mm:ss} %X{AWSRequestId} %-5p %c{1}:%L - %m%n\u003c/pattern\u003e \u003c/PatternLayout\u003e \u003c/Lambda\u003e \u003c/Appenders\u003e \u003cLoggers\u003e \u003cRoot level=\"debug\"\u003e \u003cAppenderRef ref=\"Lambda\" /\u003e \u003c/Root\u003e \u003c/Loggers\u003e \u003c/Configuration\u003e Configure Spring Cloud Function for Rest API Spring Function comes with functionRouter that can route requests to different Beans based on predefined routing expressions. Let‚Äôs configure it to lookup our function Beans by HTTP method and path, create a new application.properties file under src/main/resources/application.properties with the following content:\nspring.main.banner-mode=off spring.cloud.function.definition=functionRouter spring.cloud.function.routing-expression=headers['httpMethod'].concat(' ').concat(headers['path']) spring.cloud.function.scan.packages=org.localstack.sampleproject.api Once configured, you can use FunctionInvoker as a handler for your Rest API lambda function. It will automatically pick up the configuration we have just set.\norg.springframework.cloud.function.adapter.aws.FunctionInvoker::handleRequest Define an Application class Now our application needs an entry-class, the one we referenced earlier. Let‚Äôs add it under src/main/kotlin/org/localstack/sampleproject/Application.kt.\n1 2 3 4 5 6 7 8 9 10  package org.localstack.sampleproject import org.springframework.boot.autoconfigure.SpringBootApplication @SpringBootApplication class Application fun main(args: Array\u003cString\u003e) { // Do nothing unless you use a custom runtime }   Configure Jackson In our sample project we are using a JSON format for reqeusts and responses. The easiest way to get started with JSON is to use the Jackson library. Let‚Äôs configure it by creating a new configuration class JacksonConfiguration.kt under src/main/kotlin/org/localstack/sampleproject/config:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  package org.localstack.sampleproject.config import com.fasterxml.jackson.annotation.JsonInclude import com.fasterxml.jackson.databind.* import org.springframework.context.annotation.Bean import org.springframework.context.annotation.Configuration import org.springframework.context.annotation.Primary import org.springframework.http.converter.json.Jackson2ObjectMapperBuilder import java.text.DateFormat @Configuration class JacksonConfiguration { @Bean fun jacksonBuilder() = Jackson2ObjectMapperBuilder() .dateFormat(DateFormat.getDateInstance(DateFormat.FULL)) @Bean @Primary fun objectMapper(): ObjectMapper = ObjectMapper().apply { configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false) configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false) configure(SerializationFeature.WRITE_ENUMS_USING_TO_STRING, true) configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false) configure(SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS, true) configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true) setSerializationInclusion(JsonInclude.Include.NON_NULL) findAndRegisterModules() } }   In applications where you need support for multiple formats or a format different from JSON (for example, SOAP/XML applications) simply use multiple beans with corresponding ObjectMapper implementations.\nDefine Logging Utility Let‚Äôs create a small logging utility to simplify interactions with the logger\n1 2 3 4 5 6 7 8  package org.localstack.sampleproject.util import org.apache.logging.log4j.LogManager import org.apache.logging.log4j.Logger open class Logger { val LOGGER: Logger = LogManager.getLogger(javaClass.enclosingClass) }   Add Request/Response utilities To reduce the amount of boilerplate code, we are going to introduce three utility functions for our Rest API communications:\n to build regular json response to build error json response to parse request payload using ObjectMapper. Note that ObjectMapper does not necessarily need to be a JSON only. It could also be XML or any other Mapper extended from standard ObjectMapper. Your application may even support multiple protocols with different request/response formats at once.  Let‚Äôs define utility functions to to build API gateway responses:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  package org.localstack.sampleproject.util import org.springframework.messaging.Message import org.springframework.messaging.support.MessageBuilder data class ResponseError( val message: String, ) fun \u003cT\u003ebuildJsonResponse(data: T, code: Int = 200): Message\u003cT\u003e { return MessageBuilder .withPayload(data) .setHeader(\"Content-Type\", \"application/json\") .setHeader(\"Access-Control-Allow-Origin\", \"*\") .setHeader(\"Access-Control-Allow-Methods\", \"OPTIONS,POST,GET\") .setHeader(\"statusCode\", code) .build() } fun buildJsonErrorResponse(message: String, code: Int = 500) = buildJsonResponse(ResponseError(message), code)   And now a utility function to process API Gateway requests:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  package org.localstack.sampleproject.util import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent import com.fasterxml.jackson.databind.ObjectMapper import org.springframework.messaging.Message import java.util.function.Function fun \u003cT\u003eapiGatewayFunction( objectMapper: ObjectMapper, callable: (message: Message\u003cT\u003e, context: APIGatewayProxyRequestEvent) -\u003e Message\u003c*\u003e ): Function\u003cMessage\u003cT\u003e, Message\u003c*\u003e\u003e = Function { input -\u003e try { val context = objectMapper.readValue( objectMapper.writeValueAsString(input.headers), APIGatewayProxyRequestEvent::class.java ) return@Function callable(input, context) } catch (e: Throwable) { val message = e.message?.replace(\"\\n\", \"\")?.replace(\"\\\"\", \"'\") return@Function buildJsonErrorResponse(message ?: \"\", 500) } }   Creating a sample Model / DTO To transfer data from requests into something more meaningful than JSON strings (and back) you will be using a lot of Models and Data Transfer Objects (DTOs). It‚Äôs time to define our first one.\n1 2 3 4 5 6 7 8 9 10 11  package org.localstack.sampleproject.model import com.fasterxml.jackson.annotation.JsonIgnore data class SampleModel( val id: Int, val name: String, @JsonIgnore val jsonIgnoredProperty: String? = null, )   Creating Rest API endpoints Let‚Äôs add our first endpoints to simulate CRUD operations on previously defined SampleModel:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  package org.localstack.sampleproject.api import com.fasterxml.jackson.databind.ObjectMapper import org.localstack.sampleproject.model.SampleModel import org.localstack.sampleproject.util.Logger import org.localstack.sampleproject.util.apiGatewayFunction import org.localstack.sampleproject.util.buildJsonResponse import org.springframework.context.annotation.Bean import org.springframework.stereotype.Component private val SAMPLE_RESPONSE = mutableListOf( SampleModel(id = 1, name = \"Sample #1\"), SampleModel(id = 2, name = \"Sample #2\"), ) @Component class SampleApi(private val objectMapper: ObjectMapper) { companion object : Logger() @Bean(\"POST /v1/entities\") fun createSampleEntity() = apiGatewayFunction\u003cSampleModel\u003e(objectMapper) { input, context -\u003e LOGGER.info(\"calling POST /v1/entities\") SAMPLE_RESPONSE.add(input.payload) buildJsonResponse(input.payload, code = 201) } @Bean(\"GET /v1/entities\") fun listSampleEntities() = apiGatewayFunction\u003cByteArray\u003e(objectMapper) { input, context -\u003e LOGGER.info(\"calling GET /v1/entities\") buildJsonResponse(\"hello world\") } @Bean(\"GET /v1/entities/get\") fun getSampleEntity() = apiGatewayFunction\u003cByteArray\u003e(objectMapper) { input, context -\u003e LOGGER.info(\"calling GET /v1/entities/get\") val desiredId = context.queryStringParameters[\"id\"]!!.toInt() buildJsonResponse(SAMPLE_RESPONSE.find { it.id == desiredId }) } }   Note how we used Spring‚Äôs dependency injection to inject ObjectMapper Bean we configured earlier.\nCold Start and Warmup (PRO) Pro Features Please note that EVENTS is a LocalStack PRO feature and is not supported in Community version  We know Java‚Äôs cold start is always a pain. To minimize this pain, we will try to define a pre-warming endpoint within the Rest API. By invoking this function every 5-10 mins we can make sure Rest API lambda is always kept in a pre-warmed state.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  package org.localstack.sampleproject.api import com.fasterxml.jackson.databind.ObjectMapper import org.localstack.sampleproject.util.apiGatewayFunction import org.localstack.sampleproject.util.buildJsonResponse import org.springframework.context.annotation.Bean import org.springframework.stereotype.Component @Component class ScheduleApi(private val objectMapper: ObjectMapper) { @Bean(\"SCHEDULE warmup\") fun warmup() = apiGatewayFunction\u003cByteArray\u003e(objectMapper) { input, context -\u003e // execute scheduled events  buildJsonResponse(\"OK\") } }   Now you can add a scheduled event to the Rest API lambda function with the following synthetic payload (to simulate API gateway request). This way, you can define any other scheduled events, but we recommend using pure lambda functions.\n{ \"httpMethod\": \"SCHEDULE\", \"path\": \"warmup\" } As you may have guessed, this input will get mapped to the SCHEDULE warmup Bean.\n For more information, please read the ‚ÄúSetting up Deployment‚Äù section.\n Creating other lambda Handlers HTTP requests are not the only thing our Spring Function-powered lambdas can do. We can still define pure lambda functions, DynamoDB stream handlers, and so on.\nBelow you can find a little example of few lambda functions grouped in LambdaApi class.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  package org.localstack.sampleproject.api import com.amazonaws.services.lambda.runtime.events.DynamodbEvent import org.localstack.sampleproject.model.SampleModel import org.localstack.sampleproject.util.Logger import org.springframework.cloud.function.adapter.aws.SpringBootStreamHandler import org.springframework.context.annotation.Bean import org.springframework.stereotype.Component import java.util.function.Function @Component class LambdaApi : SpringBootStreamHandler() { companion object : Logger() @Bean fun functionOne(): Function\u003cAny, String\u003e { return Function { LOGGER.info(\"calling function one\") return@Function \"ONE\"; } } @Bean fun functionTwo(): Function\u003cSampleModel, SampleModel\u003e { return Function { LOGGER.info(\"calling function two\") return@Function it; } } @Bean fun dynamoDbStreamHandlerExample(): Function\u003cDynamodbEvent, Unit\u003e { return Function { LOGGER.info(\"handling DynamoDB stream event\") } } }   As you can see from the example above, we are using SpringBootStreamHandler class as a base that takes care of the application bootstrapping process and AWS requests transformation.\nNow org.localstack.sampleproject.api.LambdaApi can be used as a handler for your lambda function along with FUNCTION_NAME environmental variable with the function bean name.\nYou may have noticed we used DynamodbEvent in the last example. The Lambda-Events package comes with a set of predefined wrappers that you can use to handle different lifecycle events from AWS.\nSetting up Deployment Check our sample project for usage examples.\nServerless  AWS CDK  Terraform   service:localstack-sampleproject-serverlessprovider:name:awsruntime:java11stage:${opt:stage}region:us-west-1lambdaHashingVersion:20201221deploymentBucket:name:deployment-bucketpackage:artifact:build/libs/localstack-sampleproject-all.jarplugins:- serverless-localstack- serverless-deployment-bucketcustom:localstack:stages:- localfunctions:http_proxy:timeout:30handler:org.springframework.cloud.function.adapter.aws.FunctionInvoker::handleRequestevents:- http:path:/{proxy+}method:ANYcors:true# Please, note that events are a LocalStack PRO feature- schedule:rate:rate(10 minutes)enabled:trueinput:httpMethod:SCHEDULEpath:warmuplambda_helloOne:timeout:30handler:org.localstack.sampleproject.api.LambdaApienvironment:FUNCTION_NAME:functionOnelambda_helloTwo:timeout:30handler:org.localstack.sampleproject.api.LambdaApienvironment:FUNCTION_NAME:functionTwo package org.localstack.cdkstack import java.util.UUID import software.amazon.awscdk.core.Construct import software.amazon.awscdk.core.Duration import software.amazon.awscdk.core.Stack import software.amazon.awscdk.services.apigateway.CorsOptions import software.amazon.awscdk.services.apigateway.LambdaRestApi import software.amazon.awscdk.services.apigateway.StageOptions import software.amazon.awscdk.services.events.Rule import software.amazon.awscdk.services.events.RuleTargetInput import software.amazon.awscdk.services.events.Schedule import software.amazon.awscdk.services.events.targets.LambdaFunction import software.amazon.awscdk.services.lambda.* import software.amazon.awscdk.services.lambda.Function import software.amazon.awscdk.services.s3.Bucket private val STAGE = System.getenv(\"STAGE\") ?: \"local\" private const val JAR_PATH = \"../../build/libs/localstack-sampleproject-all.jar\" class ApplicationStack(parent: Construct, name: String) : Stack(parent, name) { init { val restApiLambda = Function.Builder.create(this, \"RestApiFunction\") .code(Code.fromAsset(JAR_PATH)) .handler(\"org.springframework.cloud.function.adapter.aws.FunctionInvoker\") .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .tracing(Tracing.ACTIVE) .build() val corsOptions = CorsOptions.builder().allowOrigins(listOf(\"*\")).allowMethods(listOf(\"*\")).build() LambdaRestApi.Builder.create(this, \"ExampleRestApi\") .proxy(true) .restApiName(\"ExampleRestApi\") .defaultCorsPreflightOptions(corsOptions) .deployOptions(StageOptions.Builder().stageName(STAGE).build()) .handler(restApiLambda) .build() val warmupRule = Rule.Builder.create(this, \"WarmupRule\") .schedule(Schedule.rate(Duration.minutes(10))) .build() val warmupTarget = LambdaFunction.Builder.create(restApiLambda) .event(RuleTargetInput.fromObject(mapOf(\"httpMethod\" to \"SCHEDULE\", \"path\" to \"warmup\"))) .build() // Please note that events is a LocalStack PRO feature  warmupRule.addTarget(warmupTarget) SingletonFunction.Builder.create(this, \"ExampleFunctionOne\") .code(Code.fromAsset(JAR_PATH)) .handler(\"org.localstack.sampleproject.api.LambdaApi\") .environment(mapOf(\"FUNCTION_NAME\" to \"functionOne\")) .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .uuid(UUID.randomUUID().toString()) .build() SingletonFunction.Builder.create(this, \"ExampleFunctionTwo\") .code(Code.fromAsset(JAR_PATH)) .handler(\"org.localstack.sampleproject.api.LambdaApi\") .environment(mapOf(\"FUNCTION_NAME\" to \"functionTwo\")) .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .uuid(UUID.randomUUID().toString()) .build() } } variable \"STAGE\" { type = string default = \"local\" } variable \"AWS_REGION\" { type = string default = \"us-east-1\" } variable \"JAR_PATH\" { type = string default = \"build/libs/localstack-sampleproject-all.jar\" } provider \"aws\" { access_key = \"test_access_key\" secret_key = \"test_secret_key\" region = var.AWS_REGION s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { apigateway = var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudformation = var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatch = var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatchevents = var.STAGE == \"local\" ? \"http://localhost:4566\" : null iam = var.STAGE == \"local\" ? \"http://localhost:4566\" : null lambda = var.STAGE == \"local\" ? \"http://localhost:4566\" : null s3 = var.STAGE == \"local\" ? \"http://localhost:4566\" : null } } resource \"aws_iam_role\" \"lambda-execution-role\" { name = \"lambda-execution-role\" assume_role_policy = \u003c\u003cEOF{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"sts:AssumeRole\", \"Principal\": { \"Service\": \"lambda.amazonaws.com\" }, \"Effect\": \"Allow\", \"Sid\": \"\" } ] } EOF } resource \"aws_lambda_function\" \"restApiLambdaFunction\" { filename = var.JAR_PATH function_name = \"RestApiFunction\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.springframework.cloud.function.adapter.aws.FunctionInvoker\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) } resource \"aws_api_gateway_rest_api\" \"rest-api\" { name = \"ExampleRestApi\" } resource \"aws_api_gateway_resource\" \"proxy\" { rest_api_id = aws_api_gateway_rest_api.rest-api.id parent_id = aws_api_gateway_rest_api.rest-api.root_resource_id path_part = \"{proxy+}\" } resource \"aws_api_gateway_method\" \"proxy\" { rest_api_id = aws_api_gateway_rest_api.rest-api.id resource_id = aws_api_gateway_resource.proxy.id http_method = \"ANY\" authorization = \"NONE\" } resource \"aws_api_gateway_integration\" \"proxy\" { rest_api_id = aws_api_gateway_rest_api.rest-api.id resource_id = aws_api_gateway_method.proxy.resource_id http_method = aws_api_gateway_method.proxy.http_method integration_http_method = \"POST\" type = \"AWS_PROXY\" uri = aws_lambda_function.restApiLambdaFunction.invoke_arn } resource \"aws_api_gateway_deployment\" \"rest-api-deployment\" { depends_on = [aws_api_gateway_integration.proxy] rest_api_id = aws_api_gateway_rest_api.rest-api.id stage_name = var.STAGE } resource \"aws_cloudwatch_event_rule\" \"warmup\" { name = \"warmup-event-rule\" schedule_expression = \"rate(10 minutes)\" } resource \"aws_cloudwatch_event_target\" \"warmup\" { target_id = \"warmup\" rule = aws_cloudwatch_event_rule.warmup.name arn = aws_lambda_function.restApiLambdaFunction.arn input = \"{\\\"httpMethod\\\": \\\"SCHEDULE\\\", \\\"path\\\": \\\"warmup\\\"}\" } resource \"aws_lambda_permission\" \"warmup-permission\" { statement_id = \"AllowExecutionFromCloudWatch\" action = \"lambda:InvokeFunction\" function_name = aws_lambda_function.restApiLambdaFunction.function_name principal = \"events.amazonaws.com\" source_arn = aws_cloudwatch_event_rule.warmup.arn } resource \"aws_lambda_function\" \"exampleFunctionOne\" { filename = var.JAR_PATH function_name = \"ExampleFunctionOne\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.localstack.sampleproject.api.LambdaApi\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) environment { variables = { FUNCTION_NAME = \"functionOne\" } } } resource \"aws_lambda_function\" \"exampleFunctionTwo\" { filename = var.JAR_PATH function_name = \"ExampleFunctionTwo\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.localstack.sampleproject.api.LambdaApi\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) environment { variables = { FUNCTION_NAME = \"functionTwo\" } } }  Testing, Debugging and Code hot-swapping Please read our Lambda Tools documentation to learn more about testing, debugging and code hot-swapping for JVM Lambda functions.\nUseful Links  Spring Cloud Function on LocalStack (Kotlin JVM)  ","categories":["LocalStack Community","LocalStack Pro"],"description":"Use Spring Cloud Function framework with LocalStack\n","excerpt":"Use Spring Cloud Function framework with LocalStack\n","ref":"/integrations/spring-cloud-function/","tags":["serverless-framework","spring","spring-cloud","spring-cloud-function","jvm","kotlin"],"title":"Spring Cloud Function"},{"body":"   Complexity ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ     Time to read 5 minutes   Edition community/pro   Platform any    Quickly iterating over Lambda function code can be quite cumbersome, as you need to deploy your function on every change. With LocalStack you can avoid this hurdle by mounting your code directly from the source folder. This way, any saved change inside your source file directly affects the already deployed Lambda function ‚Äì without any redeployment!\nCovered Topics Application Configuration Examples:\n Code hot-swapping for JVM Lambdas Code hot-swapping for Python Lambdas Debugging Nodejs lambdas (under development)  Deployment Configuration Examples:\n Serverless Framework Configuration AWS Cloud Development Kit (CDK) Configuration Terraform Configuration  Useful Links\nApplication Configuration Examples Code hot-swapping for JVM Lambdas Since lambda containers lifetime is usually limited, regular hot code swapping techniques are not applicable here.\nIn our implementation, we will be watching for fs changes under the project folder, then build a FatJar, unzip it, and mount it into the Lambda Docker Container.\nWe assume you already have:\n watchman configured JVM project capable of building FatJars using your preferred build tool  First, create a watchman wrapper by using one of our examples\nDon‚Äôt forget to adjust permissions: $ chmod +x bin/watchman.sh\nNow configure your build tool to unzip the FatJar to some folder, which will be then mounted to LocalStack. We are using Gradle build tool to unpack the FatJar into the build/hot folder:\n// We assume you are using something like `Shadow` plugin that comes with `shadowJar` task task buildHot(type: Copy) { from zipTree(\"${project.buildDir}/libs/${project.name}-all.jar\") into \"${project.buildDir}/hot\" } buildHot.dependsOn shadowJar Now run the following command to start watching your project in a hot-swapping mode:\n$ bin/watchman.sh src \"./gradlew buildHot\" Please note that you still need to configure your deployment tool to use local code mounting. Read the ‚ÄúDeployment Configuration Examples‚Äù for more information.\nCode hot-swapping for Python Lambdas We will show you how you can do this with a simple example function, taken directly from the AWS Lambda developer guide.\nYou can check out that code, or use your own lambda functions to follow along. To use the example just do:\n$ cd /tmp $ git clone git@github.com:awsdocs/aws-doc-sdk-examples.git Starting up LocalStack First, we need to make sure we start LocalStack with the right configuration. This is as simple as setting LAMBDA_REMOTE_DOCKER(see the Configuration Documentation for more information):\n$ LAMBDA_REMOTE_DOCKER=0 localstack start Accordingly, if you are launching LocalStack via Docker or Docker Compose:\n#docker-compose.ymlservices:localstack:...environment:...- LAMBDA_REMOTE_DOCKER=falseCreating the Lambda Function To create the Lambda function, you just need to take care of two things:\n Deploy via an S3 Bucket. You need to use the magic variable __local__ as the bucket. Set the S3 key to the path of the directory your lambda function resides in. The handler is then referenced by the filename of your lambda code and the function in that code that needs to be invoked.  So, using the AWS example, this would be:\n$ awslocal lambda create-function --function-name my-cool-local-function \\ --code S3Bucket=\"__local__\",S3Key=\"/tmp/aws-doc-sdk-examples/python/example_code/lambda/boto_client_examples\" \\ --handler lambda_handler_basic.lambda_handler \\ --runtime python3.8 \\ --role cool-stacklifter You can also check out some of our ‚ÄúDeployment Configuration Examples‚Äù.\nWe can also quickly make sure that it works by invoking it with a simple payload:\n$ awslocal lambda invoke --function-name my-cool-local-function --payload '{\"action\": \"square\", \"number\": 3}' output.txt The invocation returns itself returns:\n{ \"StatusCode\": 200, \"LogResult\": \"\", \"ExecutedVersion\": \"$LATEST\" } and output.txt contains:\n{\"result\":9} Changing things up Now, that we got everything up and running, the fun begins. Because the function is now mounted as a file in the executing container, any change that we save on the file will be there in an instant.\nFor example, we can now make a minor change to the API and replace the response in line 41 with the following:\nresponse = {'math_result': result} Without redeploying or updating the function, the result of the previous request will look like this:\n{\"math_result\":9} Cool!\nUsage with Virtualenv For virtualenv-driven projects, all dependencies should be made available to the Python interpreter at runtime. There are different ways to achieve that, including:\n expanding the Python module search path in your Lambda handler creating a watchman script to copy the libraries  Expanding the module search path in your Lambda handler The easiest approach is to expand the module search path (sys.path) and add the site-packages folder inside the virtualenv. We can add the following two lines of code at the top of the Lambda handler script:\nimport sys, glob sys.path.insert(0, glob.glob(\".venv/lib/python*/site-packages\")[0]) ... import some_lib_from_virtualenv # import your own modules here This way you can easily import modules from your virtualenv, without having to change the file system layout.\nNote: As an alternative to modifying sys.path, you could also set the PYTHONPATH environment variable when creating your Lambda function, to add the additional path.\nUsing a watchman script to copy libraries Another alternative is to implement a watchman script that will be preparing a special folder for hot code swapping.\nIn our example, we are using build/hot folder as a mounting point for our Lambdas.\nFirst, create a watchman wrapper by using one of our examples\nAfter that, you can use the following Makefile snippet, or implement another shell script to prepare the codebase for hot swapping:\nBUILD_FOLDER ?= build PROJECT_MODULE_NAME = my_project_module build-hot: rm -rf $(BUILD_FOLDER)/hot \u0026\u0026 mkdir -p $(BUILD_FOLDER)/hot cp -r $(VENV_DIR)/lib/python$(shell python --version | grep -oE '[0-9]\\.[0-9]')/site-packages/* $(BUILD_FOLDER)/hot/ cp -r $(PROJECT_MODULE_NAME) $(BUILD_FOLDER)/hot/$(PROJECT_MODULE_NAME) cp *.toml $(BUILD_FOLDER)/hot watch: bin/watchman.sh $(PROJECT_MODULE_NAME) \"make build-hot\" .PHONY: build-hot watch To run the example above, run make watch. The script is copying the project module PROJECT_MODULE_NAME along with all dependencies into the build/hot folder, which is then mounted into LocalStack‚Äôs Lambda container.\nDeployment Configuration Examples Serverless Framework Configuration Enable local code mounting\ncustom:localstack:...lambda:mountCode:true# or if you need to enable code mounting only for specific stagescustom:stages:local:mountCode:truetesting:mountCode:falselocalstack:stages:- local- testinglambda:mountCode:${self:custom.stages.${opt:stage}.mountCode}Pass LAMBDA_MOUNT_CWD env var with path to the built code directory (in our case to the folder with unzipped FatJar):\n$ LAMBDA_MOUNT_CWD=$(pwd)/build/hot serverless deploy --stage local AWS Cloud Development Kit (CDK) Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  package org.localstack.cdkstack import java.util.UUID import software.amazon.awscdk.core.Construct import software.amazon.awscdk.core.Duration import software.amazon.awscdk.core.Stack import software.amazon.awscdk.services.lambda.* import software.amazon.awscdk.services.s3.Bucket private val STAGE = System.getenv(\"STAGE\") ?: \"local\" private val LAMBDA_MOUNT_CWD = System.getenv(\"LAMBDA_MOUNT_CWD\") ?: \"\" private const val JAR_PATH = \"build/libs/localstack-sampleproject-all.jar\" class ApplicationStack(parent: Construct, name: String) : Stack(parent, name) { init { val lambdaCodeSource = this.buildCodeSource() SingletonFunction.Builder.create(this, \"ExampleFunctionOne\") .code(lambdaCodeSource) .handler(\"org.localstack.sampleproject.api.LambdaApi\") .environment(mapOf(\"FUNCTION_NAME\" to \"functionOne\")) .timeout(Duration.seconds(30)) .runtime(Runtime.JAVA_11) .uuid(UUID.randomUUID().toString()) .build() } /** * Mount code for hot-reloading when STAGE=local */ private fun buildCodeSource(): Code { if (STAGE == \"local\") { val bucket = Bucket.fromBucketName(this, \"HotReloadingBucket\", \"__local__\") return Code.fromBucket(bucket, LAMBDA_MOUNT_CWD) } return Code.fromAsset(JAR_PATH) } }   Then to bootstrap and deploy the stack run the following shell script\n$ STAGE=local \u0026\u0026 LAMBDA_MOUNT_CWD=$(pwd)/build/hot \u0026\u0026 cdklocal bootstrap aws://000000000000/$(AWS_REGION) \u0026\u0026 \\ cdklocal deploy Terraform Configuration variable \"STAGE\" { type = string default = \"local\" } variable \"AWS_REGION\" { type = string default = \"us-east-1\" } variable \"JAR_PATH\" { type = string default = \"build/libs/localstack-sampleproject-all.jar\" } variable \"LAMBDA_MOUNT_CWD\" { type = string } provider \"aws\" { access_key = \"test_access_key\" secret_key = \"test_secret_key\" region = var.AWS_REGION s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { apigateway =var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudformation =var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatch =var.STAGE == \"local\" ? \"http://localhost:4566\" : null cloudwatchevents =var.STAGE == \"local\" ? \"http://localhost:4566\" : null iam =var.STAGE == \"local\" ? \"http://localhost:4566\" : null lambda =var.STAGE == \"local\" ? \"http://localhost:4566\" : null s3 =var.STAGE == \"local\" ? \"http://localhost:4566\" : null } } resource \"aws_iam_role\" \"lambda-execution-role\" { name = \"lambda-execution-role\" assume_role_policy = \u003c\u003cEOF { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": \"sts:AssumeRole\", \"Principal\": { \"Service\": \"lambda.amazonaws.com\" }, \"Effect\": \"Allow\", \"Sid\": \"\" } ] } EOF } resource \"aws_lambda_function\" \"exampleFunctionOne\" { s3_bucket =var.STAGE == \"local\" ? \"__local__\" : null s3_key =var.STAGE == \"local\" ? var.LAMBDA_MOUNT_CWD : null filename =var.STAGE == \"local\" ? null : var.JAR_PATH function_name = \"ExampleFunctionOne\" role = aws_iam_role.lambda-execution-role.arn handler = \"org.localstack.sampleproject.api.LambdaApi\" runtime = \"java11\" timeout = 30 source_code_hash = filebase64sha256(var.JAR_PATH) environment { variables = { FUNCTION_NAME = \"functionOne\" } } }  $ terraform init \u0026\u0026 \\ terraform apply -var \"STAGE=local\" -var \"LAMBDA_MOUNT_CWD=$(pwd)/build/hot\" Useful Links  Lambda Code Mounting and Debugging (Python) Spring Cloud Function on LocalStack (Kotlin JVM)  ","categories":["LocalStack Community","LocalStack Pro"],"description":"Hot code swapping for Lambda functions using LocalStack's code mounting\n","excerpt":"Hot code swapping for Lambda functions using LocalStack's code ‚Ä¶","ref":"/tools/lambda-tools/hot-swapping/","tags":"","title":"Hot Swapping"},{"body":"LocalStack Event Analytics LocalStack allows for transparent collection of execution events, in order to provide usage analytics and insights into the testing process overall.\nSimply configure your system with the LOCALSTACK_API_KEY environment variable, and the system will start making your events accessible on the LocalStack dashboard at https://app.localstack.cloud/dashboard.\nData Privacy Please note that data privacy is one of our key concerns; data is only collected in an anonymized way, and never exposes any sensitive information about your application.  The following screenshot shows an the Analytics Dashboard in action:\nThe top row shows a summary of your LocalStack usage. A test process or Process ID refers to a single run of LocalStack. The table shows the detailed list of events sorted by date.\nConfiguration You can disable event reporting on your LocalStack client by setting the environment variable DISABLE_EVENTS=1.\nAdditional Info Brave blocks localhost requests due to security by default via shields, some sites need access to localhost/127.0.0.1 to work correctly. Easy option to allow a user to enable this is manually enabling via the site brave://settings/content/insecureContent.  ","categories":["LocalStack Pro"],"description":"An Introduction to the LocalStack Pro Analytics Dashboard\n","excerpt":"An Introduction to the LocalStack Pro Analytics Dashboard\n","ref":"/tools/analytics-dashboard/","tags":"","title":"Analytics Dashboard"},{"body":"Overview Architect enables you to quickly build large serverless apps without worrying about the underlying infrastructure. On this page we discuss how Architect and LocalStack can be used together. If you are adapting an existing configuration, you might be able to skip certain steps at your own discretion.\nExample Setup To use Architect in conjunction with LocalStack, simply install the arclocal command (sources can be found here). $ npm install -g architect-local @architect/architect aws-sdk\nThe arclocal command has the same usage as the arc command, so you can start right away.\nCreate a test directory\n$ mkdir architect_quickstart \u0026\u0026 cd architect_quickstart then create an architect project\n$ arclocal init Deployment Now you need to start LocalStack. After LocalStack has started you can deploy your Architect setup via: $ arclocal deploy\nFurther reading For more architect examples, you can take a look at the official architect docs.\n","categories":"","description":"Use the Architect Infrastructure as Code framework with LocalStack\n","excerpt":"Use the Architect Infrastructure as Code framework with LocalStack\n","ref":"/integrations/architect/","tags":["architect","infrastructure-as-code"],"title":"Architect"},{"body":"Overview The AWS Copilot CLI is a command line tool for developer, to release and operate containerized applications using the AWS services ECS, Fargate and App runner. Copilot CLI makes it very simple to deploy your application, without the need for manual configuration of the mentioned services.\nCopilot Local copilotlocal is a fork of AWS Copilot CLI, where the endpoints for all services are redirected to http://localhost:4566. Using copilotlocal instead of copilot in your command line therefore ensures the deployment of your service on LocalStack instead of AWS.\nDownload / Installation Linux AMD64  Linux ARM64  Mac OS  Windows Powershell   curl -Lo copilotlocal https://github.com/localstack/copilot-cli/raw/localstack-builds/build/linux-amd64/copilotlocal \u0026\u0026 chmod +x copilotlocal # if you want to have copilotlocal in your $PATH, move the executable e.g. to /usr/local/bin/ sudo mv copilotlocal /usr/local/bin/ curl -Lo copilotlocal https://github.com/localstack/copilot-cli/raw/localstack-builds/build/linux-arm64/copilotlocal \u0026\u0026 chmod +x copilotlocal # if you want to have copilotlocal in your $PATH, move the executable e.g. to /usr/local/bin/ sudo mv copilotlocal /usr/local/bin/ curl -Lo copilotlocal https://github.com/localstack/copilot-cli/raw/localstack-builds/build/macos-darwin/copilotlocal \u0026\u0026 chmod +x copilotlocal # if you want to have copilotlocal in your $PATH, move the executable e.g. to /usr/local/bin/ sudo mv copilotlocal /usr/local/bin/ Invoke-WebRequest -Uri https://github.com/localstack/copilot-cli/raw/localstack-builds/build/windows/copilotlocal.exe -OutFile copilotlocal.exe   Configuration  LOCALSTACK_HOSTNAME: Target hostname under which LocalStack endpoints are available (default: localhost.localstack.cloud) EDGE_PORT: Target port under which LocalStack endpoints are available (default: 4566) LOCALSTACK_DISABLE: Optional flag to disable the local endpoints and use the default behavior of copilot (set to 1 or true to enable)  Usage copilotlocal can be used as a drop-in replacement for copilot. You can execute any copilot command as copilotlocal to run your intended action against LocalStack instead of AWS.\nTo deploy your init your copilot environment, execute the following command in your project folder:\ncopilotlocal init For more information about how to use the AWS Copilot CLI, checkout the copilot documentation. Just remember to replace copilot with copilotlocal.\n","categories":"","description":"Build, Release and Operate Containerized Applications on AWS with AWS Copilot CLI\n","excerpt":"Build, Release and Operate Containerized Applications on AWS with AWS ‚Ä¶","ref":"/integrations/copilot/","tags":["continuous-delivery"],"title":"AWS Copilot CLI"},{"body":"Syntax Use the following syntax to run localstack pod commands from your terminal window:\nlocalstack pod [command] [options] where command specifies the operation you want to perform with your Cloud Pods, e.g., pull or push, and options specifies the optional flag. For example, you can attach a specific message to a snapshot using the -m option while doing a commit operation.\nConfiguration The CRUD commands exposed with the Cloud Pods CLI expect a --name \u003cpod_name\u003e option to specify the pod‚Äôs name. Users can avoid specifying a pod name at every command by setting a global config with the config command.\nFor instance, the following command\nlocalstack config --name my_pod will implicitly pass a pod name to all subsequent CLI commands. Such a configuration will be saved locally on the host machine in a JSON file (e.g., in ~/.localstack/cloudpods/pods-config.json).\nCommands commit The commit command creates a snapshot of your LocalStack running instance and locally saves it on the host machine.\nSynopsis\nCommit a snapshot of the LocalStack running instance. Options: -m, --message TEXT Add a comment describing the snapshot. -n, --name TEXT Name of the Cloud Pod. -s, --services TEXT Comma-delimited list of services to push in the pods (all, by default). config The config command saves some configuration values that apply to all the subsequent CLI commands. For instance with localstack pod config --name \u003cmy_name\u003e users can avoid specifying a pod name for other commands like pull or push. Users can specify a list of services with the following command:\nlocalstack pod config --services sqs,sns The following CRUD operation will only take into account the selected service and not the entire LocalStack application state.\nSynopsis\nConfigure a set of parameters for all Cloud Pods commands. Options: -n, --name TEXT Name of the Cloud Pod. -s, --services TEXT Comma-delimited list of services or `all` to enable all (default). delete The delete command let users delete their remote or local Cloud Pods.\nSynopsis\nDelete a Cloud Pod. Options: -n, --name TEXT Name of the Cloud Pod. -l, --local Delete only the local Cloud Pod, leaving the remote copy intact inject The inject command let users inject a specific application state, previously saved, into the application runtime. Please note that this is a local-only operation, i.e., the injecting state must be located on the host machine (usually under ~/.localstack/cloudpods/\u003cpod_name\u003e).\nBy default, the injecting state will replace the application runtime. The --merge option, instead, will first merge the injecting state with the current runtime and then inject the result.\nSynopsis\nInject the state from a locally available Cloud Pod version into the application runtime. Options: --merge Merge the injecting state with the current application runtime. -v, --version INTEGER Version to inject (most recent one by default). -n, --name TEXT Name of the cloud pod. inspect The inspect command simply lets the user inspect the content of a Cloud Pod.\nSynopsis\nInspect the contents of a Cloud Pod. Options: -n, --name TEXT Name of the Cloud Pod. -f, --format TEXT Format (curses, rich, json). list The list command displays all the available Cloud Pods. By default, it only shows the pods that have been uploaded to the platform. The -l option will also show the locally available pods.\nSynopsis\nList all available Cloud Pods.\nOptions: -l, --local List also locally available Cloud Pods pull The pull command retrieves the content of a Cloud Pod previously created and uploaded to the LocalStack platform and injects it into the application runtime. By default, the fetched pod will always be injected. The --fetch option will instead only trigger the download of the desired Cloud Pods to the host machine, without performing any additional operation. Users could then, for instance, use the --inject command to inject the retrieved pods. Similar to the --inject command, users can specify the --merge flag (off by default) if they wish to merge the current application state with the injecting one.\nSynopsis\nIncorporate the state of a Cloud Pod into the application runtime. Options: -n, --name TEXT Name of the cloud pod --merge Merge the injecting state with the current application runtime. --fetch Only fetch the Cloud Pod from the remote platform. push The push command is used to create a new version of a Cloud Pods and upload it to the LocalStack platform. A new version is created from the latest snapshot, e.g., taken with a previous commit. A snapshot will be created at the moment of the push if no previous snapshot has been taken. By default, a push operation will always retrieve the application state, create a Cloud Pod, and upload a version to the platform. Users can use the --local flag if they wish to avoid the last step and keep the newly created pod on the host machine. Users can also select a subset of AWS services they wish to incorporate in a new Cloud Pod version with the --services option. Pushing an already existing pod results in creating a new version of it and, eventually, uploading it to the platform.\nSynopsis\nCreate a new version of a Cloud Pod from the latest snapshot. A snapshot is created if it does not exists yet. Options: -l, --local Create the Cloud Pod version only locally, without pushing to remote -m, --message TEXT Add a comment describing the version. -n, --name TEXT Name of the Cloud Pod. -s, --services TEXT Comma-delimited list of services to push in the pods (all by default). --overwrite BOOLEAN Overwrite a version with the content from the latest snapshot of the selected version. -v, --version INTEGER Version to overwrite. Works with `--overwrite` versions The versions command simply lists all the available versions of a Cloud Pod.\nSynopsis\nList all available versions for a Cloud Pod. Options: -n, --name TEXT Name of the Cloud Pod. ","categories":["LocalStack Pro","Tools","Persistence","CLI"],"description":"LocalStack provides a command line tool to manage the state of your instance via Cloud Pods.\n","excerpt":"LocalStack provides a command line tool to manage the state of your ‚Ä¶","ref":"/tools/cloud-pods/pods-cli/","tags":"","title":"Cloud Pods CLI"},{"body":"LocalStack allows for many different configuration options. You can pass these via environment variables, e.g., like the following:\n$ DEBUG=1 localstack start Core    Variable Example Values Description     EDGE_BIND_HOST 127.0.0.1 (default), 0.0.0.0 (docker) Address the edge service binds to.   EDGE_PORT 4566 (default) Port number for the edge service, the main entry point for all API invocations.   HOSTNAME localhost (default) Name of the host to expose the services internally. For framework-internal communication, e.g., services are started in different containers using docker-compose.   HOSTNAME_EXTERNAL localhost (default) Name of the host to expose the services externally. This host is used, e.g., when returning queue URLs from the SQS service to the client.   DEBUG 0|1 Flag to increase log level and print more verbose logs (useful for troubleshooting issues)   IMAGE_NAME localstack/localstack (default), localstack/localstack:0.11.0 Specific name and tag of LocalStack Docker image to use.   USE_LIGHT_IMAGE 1 (default) Whether to use the light-weight Docker image. Overwritten by IMAGE_NAME.   LEGACY_DIRECTORIES 0 (default) Use legacy method of managing internal filesystem layout. See filesystem layout.   MULTI_ACCOUNTS 0 (default) Enable multi-accounts (preview)   PERSISTENCE 0 (default) Enable persistence. See persistence mechanism and filesystem layout.   PERSIST_ALL true (default) Whether to persist all resources (including user code like Lambda functions), or only ‚Äúlight-weight‚Äù resources (e.g., SQS queues, or Cognito users). Can be set to false to reduce storage size of DATA_DIR folders or Cloud Pods.   MAIN_CONTAINER_NAME localstack_main (default) Specify the main docker container name   INIT_SCRIPTS_PATH /some/path Specify the path to the initializing files with extensions .sh that are found default in /docker-entrypoint-initaws.d.   LS_LOG trace, trace-internal, debug, info, warn, error, warning Specify the log level. Currently overrides the DEBUG configuration. trace for detailed request/response, trace-internal for internal calls, too.   EXTERNAL_SERVICE_PORTS_START 4510 (default) Start of the external service port range (included).   EXTERNAL_SERVICE_PORTS_END 4560 (default) End of the external service port range (excluded).   EAGER_SERVICE_LOADING 0 (default) Boolean that toggles lazy loading of services. If eager loading is enabled, services are started at LocalStack startup rather than their first use. Eager loading significantly increases LocalStack startup time.    CLI These variables are only relevant when using the CLI to start LocalStack.\n   Variable Example Values Description     LOCALSTACK_VOLUME_DIR ~/.cache/localstack/volume (on Linux) The location on the host of the LocalStack volume directory mount. See filesystem layout   CONFIG_PROFILE  The configuration profile to load. See Profiles   CONFIG_DIR ~/.localstack The path where LocalStack can find configuration profiles and other CLI-specific configuration    Docker Docker is used extensively by LocalStack, and there are several configuration parameters for how LocalStack interacts with Docker.\n   Variable Example Values Description     DOCKER_FLAGS  Allows to pass custom flags (e.g., volume mounts) to ‚Äúdocker run‚Äù when running LocalStack in Docker.   DOCKER_SOCK /var/run/docker.sock Path to local Docker UNIX domain socket   DOCKER_BRIDGE_IP 172.17.0.1 IP of the docker bridge used to enable access between containers   LEGACY_DOCKER_CLIENT 0|1 Whether LocalStack should use the command-line Docker client and subprocess execution to run Docker commands, rather than the Docker SDK.   DOCKER_CMD docker (default), sudo docker Shell command used to run Docker containers (only used in combination with LEGACY_DOCKER_CLIENT)   FORCE_NONINTERACTIVE  When running with Docker, disables the --interactive and --tty flags. Useful when running headless.    Local AWS Services This section covers configuration values that are specific to certain AWS services.\n AppSync Batch DynamoDB Elastic Kubernetes Service (EKS) Elasticsearch Kinesis Lambda Stepfunctions  AppSync    Variable Example Values Description     GRAPHQL_ENDPOINT_STRATEGY legacy|domain|path Governs how AppSync endpoints are created to access a GraphQL API (see AppSync Endpoints)    Batch    Variable Example Values Description     BATCH_DOCKER_FLAGS -e TEST_ENV=1337 Additional flags provided to the batch container. Only flags for volumes, ports, environment variables and add-hosts are allowed.    Bigdata (EMR, Athena, Glue,‚Ä¶)    Variable Example Values Description     BIGDATA_DOCKER_NETWORK  Network the bigdata should be connected to. The LocalStack container has to be connected to that network as well. Per default, the bigdata container will be connected to a network LocalStack is also connected to.   BIGDATA_DOCKER_FLAGS  Additional flags for the bigdata container. Same restrictions as LAMBDA_DOCKER_FLAGS.    DynamoDB    Variable Example Values Description     DYNAMODB_ERROR_PROBABILITY Decimal value between 0.0(default) and 1.0 Randomly inject ProvisionedThroughputExceededException errors into DynamoDB API responses.   DYNAMODB_HEAP_SIZE 256m (default), 1G Sets the JAVA EE maximum memory size for DynamoDB; full table scans require more memory   DYNAMODB_SHARE_DB 0|1 When activated, DynamodDB will use a single database instead of separate databases for each credential and region.   DYNAMODB_OPTIMIZE_DB_BEFORE_STARTUP 0|1 Optimize the database tables in the store before starting   DYNAMODB_DELAY_TRANSIENT_STATUSES 0|1 When activated, DynamoDB will introduce artificial delays in resource creation to simulate the actual cloud service more closely. Currently works only for CREATING and DELETING online index statuses.   DYNAMODB_CORS * Enable CORS support for specific allow-list list the domains separated by , use * for public access (default is *)    EKS    Variable Example Values Description     EKS_LOADBALANCER_PORT 8081 (default) Local port on which the Kubernetes load balancer is exposed on the host.    Elasticsearch Deprecated While the ElasticSearch API is actively maintained, the configuration variables for ElasticSearch have been deprecated. Please use the OpenSearch configuration variables instead. The OpenSearch configuration variables are used to manage both, OpenSearch and ElasticSearch clusters.     Variable Example Values Description     ES_CUSTOM_BACKEND http://elasticsearch:9200 Deprecated. Use OPENSEARCH_CUSTOM_BACKEND instead. URL to a custom elasticsearch backend cluster. If this is set to a valid URL, then localstack will not create elasticsearch cluster instances, but instead forward all domains to the given backend (see Custom Elasticsearch Backends).   ES_MULTI_CLUSTER 0|1 Deprecated. Use OPENSEARCH_MULTI_CLUSTER instead. When activated, LocalStack will spawn one Elasticsearch cluster per domain. Otherwise all domains will share a single cluster instance. This is ignored if ES_CUSTOM_BACKEND is set.   ES_ENDPOINT_STRATEGY path|domain|port (formerly off) Deprecated. Use OPENSEARCH_ENDPOINT_STRATEGY instead. Governs how domain endpoints are created to access a cluster (see Elasticsearch Endpoints)    IAM    Variable Example Values Description     ENFORCE_IAM 0 (default)|1 Enable IAM policy evaluation and enforcement. If this is disabled (the default), IAM policies will have no effect to your requests.   LEGACY_IAM_PROVIDER 0 (default)|1 (deprecated) Enable the pre-1.0 legacy IAM provider   IAM_SOFT_MODE 0 (default)|1 Enable IAM soft mode. This leads to policy evaluation without actually denying access. Needs ENFORCE_IAM enabled as well. For more information, see Identity and Access Management.    Kinesis    Variable Example Values Description     KINESIS_ERROR_PROBABILITY Decimal value between 0.0(default) and 1.0 Randomly inject ProvisionedThroughputExceededException errors into Kinesis API responses.   KINESIS_SHARD_LIMIT 100 (default), Infinity (to disable) Integer value , causing the Kinesis API to start throwing exceptions to mimick the default shard limit.   KINESIS_LATENCY 500 (default), 0 (to disable) Integer value of milliseconds, causing the Kinesis API to delay returning a response in order to mimick latency from a live AWS call.   KINESIS_INITIALIZE_STREAMS \"my-first-stream:1,my-other-stream:2:us-west-2,my-last-stream:1\" A comma-delimited string of stream names, its corresponding shard count and an optional region to initialize during startup. If the region is not provided, the default region is used. Only works with the kinesis-mock KINESIS_PROVIDER.    Lambda    Variable Example Values Description     LAMBDA_EXECUTOR  Method to use for executing Lambda functions. For docker and docker-reuse, if LocalStack itself is started inside Docker, then the docker command needs to be available inside the container (usually requires to run the container in privileged mode). More information in Lambda Executor Modes.    docker (default) Run each function invocation in a separate Docker container.    local (fallback) Run Lambda functions in a temporary directory on the local machine.    docker-reuse Create one Docker container per function and reuse it across invocations.   LAMBDA_STAY_OPEN_MODE 1 (default) Usage of the stay-open mode of Lambda containers. Only applicable if LAMBDA_EXECUTOR=docker-reuse. Set to 0 if you want to use Hot Swapping.   LAMBDA_REMOTE_DOCKER  determines whether Lambda code is copied or mounted into containers    true (default) your Lambda function definitions will be passed to the container by copying the zip file (potentially slower). It allows for remote execution, where the host and the client are not on the same machine.    false your Lambda function definitions will be passed to the container by mounting a volume (potentially faster). This requires to have the Docker client and the Docker host on the same machine.   LAMBDA_TRUNCATE_STDOUT 2000 Allows increasing the default char value for truncation of lambda logs.   BUCKET_MARKER_LOCAL  Optional bucket name for running lambdas locally.   LAMBDA_CODE_EXTRACT_TIME 25 Time in seconds to wait at max while extracting Lambda code. By default it is 25 seconds for limiting the execution time to avoid client/network timeout issues.   LAMBDA_DOCKER_NETWORK  Optional Docker network for the container running your lambda function. This configuration value also applies to ECS containers. Needs to be set to the network the LocalStack container is connected to if not default bridge network.   LAMBDA_DOCKER_DNS  Optional DNS server for the container running your lambda function.   LAMBDA_DOCKER_FLAGS -e KEY=VALUE, -v host:container, -p host:container, --add-host domain:ip Additional flags passed to Lambda Docker run|create commands (e.g., useful for specifying custom volume mounts). Does only support environment, volume, port and add-host flags   LAMBDA_CONTAINER_REGISTRY lambci/lambda (default) An alternative docker registry from where to pull lambda execution containers.   LAMBDA_REMOVE_CONTAINERS 1 (default) Whether to remove containers after Lambdas being inactive for 10 minutes. Only applicable when using docker-reuse executor.   LAMBDA_FALLBACK_URL  Fallback URL to use when a non-existing Lambda is invoked. Either records invocations in DynamoDB (value dynamodb://\u003ctable_name\u003e) or forwards invocations as a POST request (value http(s)://...).   LAMBDA_FORWARD_URL  URL used to forward all Lambda invocations (useful to run Lambdas via an external service).   LAMBDA_JAVA_OPTS -Xmx512M Allow passing custom JVM options to Java Lambdas executed in Docker. Use _debug_port_ placeholder to configure the debug port, e.g., -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=_debug_port_.   HOSTNAME_FROM_LAMBDA localstack Endpoint host under which APIs are accessible from Lambda containers (optional). This can be useful in docker-compose stacks to use the local container hostname if neither IP address nor container name of the main container are available (e.g., in CI). Often used in combination with LAMBDA_DOCKER_NETWORK.   LAMBDA_XRAY_INIT 1 / 0 (default) Whether to fully initialize XRay daemon for Lambda containers (may increase Lambda startup times)    OpenSearch    Variable Example Values Description     OPENSEARCH_CUSTOM_BACKEND http://opensearch:9200 URL to a custom OpenSearch backend cluster. If this is set to a valid URL, then LocalStack will not create OpenSearch cluster instances, but instead forward all domains to the given backend (see Custom Opensearch Backends).   OPENSEARCH_MULTI_CLUSTER 0|1 When activated, LocalStack will spawn one OpenSearch cluster per domain. Otherwise all domains will share a single cluster instance. This is ignored if OPENSEARCH_CUSTOM_BACKEND is set.   OPENSEARCH_ENDPOINT_STRATEGY path|domain|port Governs how domain endpoints are created to access a cluster (see Opensearch Endpoints).    RDS    Variable Example Values Description     RDS_PG_CUSTOM_VERSIONS 1 / 0 (default) Whether to install and use custom Postgres versions for RDS (or alternatively, use default version 11).    StepFunctions    Variable Example Values Description     STEPFUNCTIONS_LAMBDA_ENDPOINT default URL to use as the Lambda service endpoint in Step Functions. By default this is the LocalStack Lambda endpoint. Use default to select the original AWS Lambda endpoint.    SQS    Variable Example Values Description     SQS_DELAY_RECENTLY_DELETED 0 (default) Used to toggle QueueDeletedRecently errors when re-creating a queue within 60 seconds of deleting it.   SQS_ENDPOINT_STRATEGY domain|path|off Configures the format of Queue URLs (see SQS Queue URLs)    Security Please be aware that the following configurations may have severe security implications!\n   Variable Example Values Description     DISABLE_CORS_HEADERS 0 (default) Whether to disable the returning of default CORS headers in API responses (disables access from https://app.localstack.cloud).   DISABLE_CORS_CHECKS 0 (default) Whether to disable all CSRF (server-side) mitigations.   DISABLE_CUSTOM_CORS_S3 0 (default) Whether to disable CORS override by S3.   DISABLE_CUSTOM_CORS_APIGATEWAY 0 (default) Whether to disable CORS override by apigateway.   EXTRA_CORS_ALLOWED_ORIGINS  Comma-separated list of origins that are allowed to communicate with localstack.   EXTRA_CORS_ALLOWED_HEADERS  Comma-separated list of header names to be be added to Access-Control-Allow-Headers CORS header.   EXTRA_CORS_EXPOSE_HEADERS  Comma-separated list of header names to be be added to Access-Control-Expose-Headers CORS header.   ENABLE_CONFIG_UPDATES 0 (default) Whether to enable dynamic configuration updates at runtime.    Emails Please check with your SMTP email service provider for the following settings.\n   Variable Example Values Description     SMTP_HOST localhost Hostname of the SMTP server. The port defaults to 25.   SMTP_USER  Login username for the SMTP server if required.   SMTP_PASS  Login password for the SMTP server if required.   SMTP_EMAIL sender@example.com Origin email address. Required for Cognito only.    Provider Some of the services can be configured to switch to a particular provider:\n   Variable Valid options Notes     KINESIS_PROVIDER kinesis-mock (default) and kinesalite    KMS_PROVIDER moto (default) and local-kms     Profiles LocalStack supports configuration profiles which are stored in the ~/.localstack config directory. A configuration profile is a set of environment variables stored in an .env file in the LocalStack config directory. Here is an example of what configuration profiles might look like:\n% tree ~/.localstack /home/username/.localstack ‚îú‚îÄ‚îÄ default.env ‚îú‚îÄ‚îÄ dev.env ‚îî‚îÄ‚îÄ pro.env Here is an example of what a specific environment profile looks like\n% cat ~/.localstack/pro-debug.env LOCALSTACK_API_KEY=XXXXX DEBUG=1 DEVELOP=1 You can load a profile by either setting the env variable CONFIG_PROFILE=\u003cprofile\u003e or the --profile=\u003cprofile\u003e CLI flag when using the CLI. Let‚Äôs take an example to load the dev.env profile file if it exists:\npython -m localstack.cli.main --profile=dev start --host If no profile is specified, the default.env profile will be loaded. While explicitly specified, the environment variables will always overwrite the profile.\nTo display the config environment variables, you can use the following command:\npython -m localstack.cli.main --profile=dev config show Miscellaneous    Variable Example Values Description     SKIP_INFRA_DOWNLOADS  Whether to skip downloading additional infrastructure components (e.g., specific Elasticsearch versions)   SKIP_SSL_CERT_DOWNLOAD  Whether to skip downloading the SSL certificate for localhost.localstack.cloud   IGNORE_ES_DOWNLOAD_ERRORS  Whether to ignore errors (e.g., network/SSL) when downloading Elasticsearch plugins   OVERRIDE_IN_DOCKER  Overrides the check whether LocalStack is executed within a docker container. If set to true, LocalStack assumes it runs in a docker container. Should not be set unless necessary.   EDGE_FORWARD_URL  Optional target URL to forward all edge requests to (e.g., for distributed deployments)   MOCK_UNIMPLEMENTED  Whether to return mocked success responses (instead of 501 errors) for currently unimplemented API methods   DISABLE_EVENTS 1 Whether to disable publishing LocalStack events   OUTBOUND_HTTP_PROXY http://10.10.1.3 HTTP Proxy used for downloads of runtime dependencies and connections outside LocalStack itself   OUTBOUND_HTTPS_PROXY https://10.10.1.3 HTTPS Proxy used for downloads of runtime dependencies and connections outside LocalStack itself   REQUESTS_CA_BUNDLE /var/lib/localstack/lib/ca_bundle.pem CA Bundle to be used to verify HTTPS requests made by LocalStack   DISABLE_TERM_HANDLER  Whether to disable signal passing to LocalStack when running in docker. Enabling this will prevent an orderly shutdown when running inside LS in docker.    Debugging    Variable Example Values Description     DEVELOP  Starts a debugpy server before starting LocalStack services   DEVELOP_PORT  Port number for debugpy server   WAIT_FOR_DEBUGGER  Forces LocalStack to wait for a debugger to start the services    Additionally, the following read-only environment variables are available:\n LOCALSTACK_HOSTNAME: Name of the host where LocalStack services are available. Use this hostname as endpoint (e.g., http://${LOCALSTACK_HOSTNAME}:4566) in order to access the services from within your Lambda functions (e.g., to store an item to DynamoDB or S3 from a Lambda).  DNS More information here.\n   Variable Example Values Description     DNS_ADDRESS 0.0.0.0 (default) Address the LocalStack should bind the DNS server on (port 53 tcp/udp). Value 0 to disable.   DNS_SERVER 8.8.8.8 (default) Fallback DNS server for non-modified queries.   DNS_LOCAL_NAME_PATTERNS  Names which should be resolved to the LocalStack IP, as python-compatible regex.    LocalStack Pro More information here.\n   Variable Example Values Description     LOCALSTACK_API_KEY  API key to activate LocalStack Pro.   LOG_LICENSE_ISSUES 1 (default) Whether to log issues with the license activation to the console.   REQUIRE_PRO 0 (default) Whether to require license activation to succeed to start LocalStack. If set to 0 (default) LocalStack will start as community version if the license cannot be activated.    Read-only    Variable Usage Example Description     LOCALSTACK_HOSTNAME http://${LOCALSTACK_HOSTNAME}:4566 Name of the host where LocalStack services are available. Use this hostname as endpoint in order to access the services from within your Lambda functions (e.g., to store an item to DynamoDB or S3 from a Lambda).    Deprecated    Variable Example Values Description     USE_SSL false (default) Whether to use https://‚Ä¶ URLs with SSL encryption. Deprecated as of version 0.11.3. Each service endpoint now supports multiplexing HTTP/HTTPS traffic over the same port.   DEFAULT_REGION  AWS region to use when talking to the API (needs to be activated via USE_SINGLE_REGION=1). Deprecated and inactive as of version 0.12.17. LocalStack now has full multi-region support.   USE_SINGLE_REGION  Whether to use the legacy single-region mode, defined via DEFAULT_REGION.   PERSISTENCE_SINGLE_FILE true (default) Specify if persistence files should be combined (only relevant for legacy persistence in Community version, not relevant for advanced persistence in Pro version).   DATA_DIR blank (disabled/default), /tmp/localstack/data Local directory for saving persistent data. This option is deprecated since LocalStack v1 and will be ignored. Please use PERSISTENCE. Using this option will set PERSISTENCE=1 as a deprecation path. The state will be stored in your LocalStack volume in the state/ directory   HOST_TMP_FOLDER /some/path Temporary folder on the host that gets mounted as $TMPDIR/localstack into the LocalStack container. Required only for Lambda volume mounts when using LAMBDA_REMOTE_DOCKER=false.   TMPDIR /tmp (default) Temporary folder on the host running the CLI and inside the LocalStack container .   SERVICES kinesis,lambda,sqs,serverless Only works with EAGER_SERVICE_LOADING=1. Comma-separated list of AWS CLI service names or shorthands to start. Per default, all services are loaded and started on the first request for that service.   \u003cSERVICE\u003e_BACKEND  Custom endpoint URL to use for a specific service, where  is the uppercase service name.   \u003cSERVICE\u003e_PORT_EXTERNAL 4567 Port number to expose a specific service externally . SQS_PORT_EXTERNAL, e.g. , is used when returning queue URLs from the SQS service to the client.    ","categories":"","description":"Environment variables which affect LocalStack.\n","excerpt":"Environment variables which affect LocalStack.\n","ref":"/localstack/configuration/","tags":"","title":"Configuration"},{"body":"This guide shows you how to start LocalStack in a Drone CI pipeline.\nDrone CI Pipelines There are a few restrictions in Drone CI Pipelines that make it hard to customize the behavior of Docker. For example, mounting the host machine Docker socket is considered insecure, and hence alleviated privileges are required to run commands like localstack wait. Learn more about configuring Docker for Drone CI pipelines over their official documentation.\nA possible alternative to mounting the Docker socket (/var/run/docker.sock) into the container to communicate with the Docker daemon on the host is to expose port 2375 and make it reachable in the main LocalStack container. However, it requires changes to the typical Docker-Compose setup.\nExample We can integrate the following example into your Drone CI workflow. As an example, it will pull the LocalStack Docker image and check if the LocalStack service is up and running:\nkind:pipelinetype:dockername:localstacktrigger:branch:- mainservices:- name:localstackimage:localstack/localstacksteps:- name:localstack waitimage:alpine/curl:3.14commands:- until curl -s http://localstack:4566/health; do echo -n . \u0026\u0026 sleep 1; doneUsing LocalStack Pro You can easily enable LocalStack Pro by adding your API key to Drone Repository secrets. You can manage them from your repository settings screen. Navigate to your Repository secrets on your Drone repository and add the LocalStack API key as localstack_api_key. Here is an example:\nservices:- name:localstackimage:localstack/localstackenvironment:LOCALSTACK_API_KEY:from_secret:localstack_api_key","categories":"","description":"Use LocalStack in [Drone CI](https://drone.io/)\n","excerpt":"Use LocalStack in [Drone CI](https://drone.io/)\n","ref":"/ci/drone-ci/","tags":["continuous-integration","ci","continuous-delivery","testing"],"title":"Drone CI"},{"body":"Services like OpenSearch or Elasticsearch use external software which binds to separate ports.\nDepending on the configuration of the individual LocalStack service, these services can either be accessed by using the proxy functionality of LocalStack which assigns local domains to these external services. For example, if OpenSearch is configured to use the OPENSEARCH_ENDPOINT_STRATEGY=domain, a cluster can be reached by using the domain name \u003cdomain-name\u003e.\u003cregion\u003e.\u003cengine-type\u003e.localhost.localstack.cloud. Messages coming to those domains are then relayed to the servers running on ports which do not have to be accessible from outside the Docker container.\nAnother option is using the external service port range, which - e.g. in OpenSearch - is enabled by using the OPENSEARCH_ENDPOINT_STRATEGY=port).\nThe external service port range is a set of pre-defined ports (by default 4510-4559). LocalStack will chose a free port withing this range when starting an external service. These ports need to be accessible from outside the Docker container and in turn allows to directly access an external service (as opposed to using LocalStack as a proxy).\nThe port range is configurable by using the environment variables EXTERNAL_SERVICE_PORTS_START and EXTERNAL_SERVICE_PORTS_END. This results in the external service port range (EXTERNAL_SERVICE_PORTS_START, EXTERNAL_SERVICE_PORTS_END] (i.e. the EXTERNAL_SERVICE_PORTS_END is not included in the range).\n","categories":"","description":"The range of ports used by services not directly provided by LocalStack\n","excerpt":"The range of ports used by services not directly provided by ‚Ä¶","ref":"/localstack/external-ports/","tags":"","title":"External Service Port Range"},{"body":"This page describes the filesystem directory layout used internally by LocalStack.\nFilesystem layout Information This filesystem layout was introduced in LocalStack v1 and can be disabled by setting LEGACY_DIRECTORIES to 1.  LocalStack uses following directories when running within a container.\n /var/lib/localstack: the LocalStack volume directory root /var/lib/localstack/lib: variable packages (like extensions or lazy-loaded third-party dependencies) /var/lib/localstack/logs: logs for recent LocalStack runs /var/lib/localstack/state: contains the state of services if persistence is enabled (such as OpenSearch cluster data) /var/lib/localstack/tmp: temporary data that is not expected to survive LocalStack runs (may be cleared when LocalStack starts or stops) /var/lib/localstack/cache: temporary data that is expected to survive LocalStack runs (is not cleared when LocalStack starts or stops) /usr/lib/localstack: static third-party packages installed into the container images  Warning Previously, directories were individually configurable, e.g., via DATA_DIR or HOST_TMP_DIR. These have been deprecated since LocalStack v1, since we now follow a directory convention.\nDATA_DIR implicitly points to /var/lib/localstack/state if persistence is enabled. Use PERSISTENCE=1 to enable persistence. If DATA_DIR is set, its value is ignored, a warning is logged and PERSISTENCE is set to 1.\nHOST_TMP_FOLDER is determined by inspecting the volume mounts and using the source of the bind mount to /var/lib/localstack.\n LocalStack volume For LocalStack to function correctly, the LocalStack volume must be mounted from the host into the container at /var/lib/localstack.\nUsing docker-compose When using Docker Compose, this can be achieved using following:\nvolumes:- \"${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack\"${LOCALSTACK_VOLUME_DIR} could be an arbitrary location on the host, e.g., ./volume. In this case, the effective layout would be something like:\n$ tree -L 4 ./volume . ‚îî‚îÄ‚îÄ localstack ‚îú‚îÄ‚îÄ cache ‚îÇ ‚îú‚îÄ‚îÄ machine.json ‚îÇ ‚îú‚îÄ‚îÄ server.test.pem ‚îÇ ‚îú‚îÄ‚îÄ server.test.pem.crt ‚îÇ ‚îî‚îÄ‚îÄ server.test.pem.key ‚îú‚îÄ‚îÄ lib ‚îÇ ‚îî‚îÄ‚îÄ opensearch ‚îÇ ‚îî‚îÄ‚îÄ 1.1.0 ‚îú‚îÄ‚îÄ logs ‚îÇ ‚îú‚îÄ‚îÄ localstack_infra.err ‚îÇ ‚îî‚îÄ‚îÄ localstack_infra.log ‚îú‚îÄ‚îÄ state ‚îÇ ‚îî‚îÄ‚îÄ startup_info.json ‚îî‚îÄ‚îÄ tmp ‚îî‚îÄ‚îÄ zipfile.4986fb95 Using the CLI When using the CLI to start LocalStack, the volume directory can be configured via the LOCALSTACK_VOLUME_DIR. It should point to a directory on the host which is then automatically mounted into /var/lib/localstack. The defaults are:\n Mac: ~/Library/Caches/localstack/volume Linux: ~/.cache/localstack/volume Windows: %LOCALAPPDATA%/localstack/cache/volume  Host mode When LocalStack is running in host mode, the system directories /usr/lib/localstack or /var/lib/localstack are not used. Instead, the root directory is changed to FILESYSTEM_ROOT which defaults to ./.filesystem, i.e. the LocalStack project root.\n","categories":"","description":"Overview of runtime directory structure\n","excerpt":"Overview of runtime directory structure\n","ref":"/localstack/filesystem/","tags":"","title":"Filesystem Layout"},{"body":"This guide shows you how to start LocalStack in a Github Actions job.\nSetting up your Github Actions job In order to start LocalStack, we recommend to start it in a separate build step, to separate its log output / status from the rest of your job.\nWe recommend taking the following steps:\n Install the LocalStack CLI (and maybe also awslocal). Make sure your LocalStack docker image is up-to-date by pulling the latest version. Use the LocalStack CLI to start LocalStack. Make sure to use the -d flag to start the LocalStack docker container in detached mode. Wait for the container to report that it is up and running.  An official GitHub action for this also planned, to make the configuration easier and less verbose.\nThe following example can be integrated into your GitHub workflow. As an example, it will use awslocal to create bucket and list it afterwards.\nname:localstack-action-exampleon:pushjobs:example-job:runs-on:ubuntu-lateststeps:- name:Start LocalStackenv:LOCALSTACK_API_KEY:${{ secrets.LOCALSTACK_API_KEY }}run:|# install LocalStack cli and awslocal pip install localstack awscli-local[ver1] # Make sure to pull the latest version of the image docker pull localstack/localstack # Start LocalStack in the background localstack start -d # Wait 30 seconds for the LocalStack container to become ready before timing out echo \"Waiting for LocalStack startup...\" localstack wait -t 30 echo \"Startup complete\"- name:Run some Tests against LocalStackrun:|awslocal s3 mb s3://test awslocal s3 ls echo \"Test Execution complete!\"If you want to add further configuration for LocalStack, you can use the env section of your build step to set the configuration variables as described here.\nActivating LocalStack Pro If you want to use LocalStack Pro in your GitHub Actions job, you should use a Github Encrypted Secret to store your API key securely. In the above example, you can see us setting the LOCALSTACK_API_KEY environment variable to the value of the secret LOCALSTACK_API_KEY.\nYou can set your secret at an environment, repository or organization level, for more information see here. In the simplest case, you just set it at the repository level. For this, you go, in your repository, to Settings =\u003e Secrets and press ‚ÄúNew Repository Secret‚Äù.\nThere, you create the secret for your API key like in the following image, replacing foobar with your API key.\n","categories":"","description":"Use LocalStack in [GitHub Actions](https://github.com/features/actions)\n","excerpt":"Use LocalStack in [GitHub ‚Ä¶","ref":"/ci/github-actions/","tags":["continuous-integration","ci","continuous-delivery","testing"],"title":"GitHub Actions"},{"body":"LocalStack has an extensive set of integration tests. This document describes how to run and write integration tests.\nRunning the test suite To run the tests you can use the make target and set the TEST_PATH variable.\nTEST_PATH=\"tests/integration\" make test or run it manually within the virtual environment:\npython -m pytest --log-cli-level=INFO tests/integration Running individual tests You can further specify the file and test class you want to run in the test path:\nTEST_PATH=\"tests/integration/docker/test_docker.py::TestDockerClient\" make test Test against a running LocalStack instance When you run the integration tests, LocalStack is automatically started (via the pytest conftest mechanism in tests/integration/conftest.py). You can disable this behavior by setting the environment variable TEST_SKIP_LOCALSTACK_START=1.\nTest against real AWS It can be useful to run an integration test against the real AWS cloud using your credentials. You can do this by setting the environment variable TEST_TARGET=\"AWS_CLOUD\".\nWriting a test We use pytest for our testing framework. Older tests were written using the unittest framework, but its use is discouraged.\nIf your test matches the pattern tests/integration/**/test_*.py it will be picked up by the integration test suite.\nFunctional-style tests You can write functional style tests by defining a function with the prefix test_ with basic asserts:\ndef test_something(): assert True is not False Class-style tests Or you can write class-style tests by grouping tests that logically belong together in a class:\nclass TestMyThing: def test_something(self): assert True is not False Fixtures We use the pytest fixture concept, and provide several fixtures you can use when writing AWS tests. For example, to inject a Boto client for SQS, you can specify the sqs_client in your test method:\nclass TestMyThing: def test_something(self, sqs_client): assert len(sqs_client.list_queues()[\"QueueUrls\"]) == 0 We also provide fixtures for certain disposable resources, like buckets:\ndef test_something_on_a_bucket(s3_bucket): s3_bucket # s3_bucket is a boto s3 bucket object that is created before # the test runs, and removed after it returns. Another pattern we use is the factory as fixture pattern.\ndef test_something_on_multiple_buckets(s3_create_bucket): bucket1 = s3_create_bucket() bucket2 = s3_create_bucket() # both buckets will be deleted after the test returns You can find the list of available fixtures in the fixtures.py.\n","categories":"","description":"How to run and write integration tests.\n","excerpt":"How to run and write integration tests.\n","ref":"/developer-guide/integration-tests/","tags":"","title":"Integration tests"},{"body":"Overview LocalStack currently supports three different modes for lambda execution. They differ in when and where your lambda code is executed, and in term of feature set and execution speed.\nExecution modes The active lambda executor can be set using the LAMBDA_EXECUTOR environment variable, which has the 3 possible options local, docker and docker-reuse.\nThe default option is docker, unless LocalStack has no access to a docker daemon itself when it will be set to local.\nRunning docker containers inside the LocalStack docker images requires to bind mount the /var/run/docker.sock. See the example below: $ docker run --rm -it -v \"/var/run/docker.sock:/var/run/docker.sock\" -e DEBUG=1 -e LAMBDA_EXECUTOR=\u003cmode\u003e -p 4566:4566 localstack/localstack\nLocal execution Configuration: LAMBDA_EXECUTOR=local\nIn this execution mode, the lambda code is executed directly in the context of LocalStack itself. Therefore, if LocalStack is executed within docker, all the Lambda executions take place within that same container, and if it is executed in host mode, it will be executed directly on your machine. If lambda container images are used, and the local executor is set, the execution of these images will automatically take place using the docker executor (regular lambdas will continue to use the local executor).\nLocal executor mode currently supports the following Lambda Platforms:\n Python Nodejs Java Go  Lambdas on other platforms like .Net currently need to be executed in one of the docker modes.\nDocker Configuration: LAMBDA_EXECUTOR=docker\nThe docker execution mode will execute lambdas in a docker container. For this, every lambda invocation creates and runs a new docker container and returns its result when it‚Äôs finished. The advantage of this mode is the fresh lambda environment from each start, so possible leftovers during previous invocations will be purged. Due to the nature of this mode, mainly recreating the container for each invocation, this mode is rather slow. A typical invocation of a dummy python lambda can take around 3 seconds from start to finish (awscli invoke - start to finish). All supported lambda types can be used with this executor.\nDocker reuse Configuration: LAMBDA_EXECUTOR=docker-reuse\nStay-open mode LocalStack allows to use the stay-open mode of its lambda containers. The containers stay open and wait for further invocations, without executing the initialization code of the lambda multiple times. This results in way faster execution times, especially if the lambda has long-running initialization code.\nThe stay-open mode is the new default method when using docker-reuse as lambda executor, however, it has some restrictions:\n Only works if LocalStack runs in a Docker container Large Payloads (multiple MBs) do not work Problems with error handling in some runtimes  A list of failing tests with this mode can be found in this GitHub issue.\nDocker-exec execution mode This mode is the default if LocalStack is started in host mode. If you experience failures using the stay-open mode (either due to the mentioned restrictions or networking problems), you can force this mode by setting LAMBDA_STAY_OPEN_MODE=0. Also if you want to use Hot Swapping you should set LAMBDA_STAY_OPEN_MODE=0.\nThis execution mode provides a balance between the speed of a local execution and the feature set and isolation of the docker executor. While the initial call, which creates the container, will take roughly the same time of docker executor, the subsequent invocations will only take around 1 second (start to finish, invoked using the awscli), which is roughly the time an actual aws invocation using this method takes. The container is kept running 10 minutes after the last invocation for this lambda, then it will be destroyed (and recreated if necessary for the next invocation). The complete lambda process is called using docker-exec each time of the invocation. While the invocation is still faster than docker execution mode, it is not as fast as with the stay-open mode (since the lambda has to be loaded and initialized every time).\n","categories":"","description":"Overview of the different Lambda execution modes\n","excerpt":"Overview of the different Lambda execution modes\n","ref":"/localstack/lambda-executors/","tags":"","title":"Lambda Executor Modes"},{"body":"This guide shows how to use your shiny new LocalStack licenses, and go over some best-practices regarding usage, activation, and safety of your LocalStack API key.\nRequirements First, you need an API key for LocalStack Pro or Enterprise. You can get your key by signing up on our website.\nDon‚Äôt worry, you can sign-up without any payment details and try LocalStack Pro within your free trial for 14 days.\nGetting your API key You can find your API key in the LocalStack Web Interface in the Account ‚Üí Subscriptions section.\nAPI Key Security   Do not share your API key with anyone. Especially make sure that you do not commit it to any source code management systems (like Git repositories). If you push an API key to a repository, it has potentially been exposed to the public and it might remain in the history (even if you try to rewrite the history).\n  If you accidentally publish your API key, please contact us to get your API key rotated!\n  If you want to use your API key in your CI environment, please check out our CI documentation to see the proper way to handle secrets in your CI environment.\n   Using your API key LocalStack Pro or Enterprise expects your API key to be present in the environment variable LOCALSTACK_API_KEY. Before starting LocalStack, please define the environment variable in your terminal like this:\n$ export LOCALSTACK_API_KEY=\u003cyour-api-key\u003e Starting LocalStack Pro or Enterprise using the CLI When starting LocalStack using the LocalStack CLI, you dot not have to perform any further steps (after exporting the environment variable). $ localstack start\nLocalStack will detect the API key and properly pass it to the LocalStack container.\nStarting LocalStack Pro or Enterprise using Docker When starting LocalStack using a docker run command, you have to specify the API key using the -e flag for environment variables like this:\n$ docker run \\ --rm -it \\ -p 4566:4566 \\ -p 4510-4559:4510-4559 \\ -e LOCALSTACK_API_KEY=${LOCALSTACK_API_KEY:- } \\  localstack/localstack For more information about starting LocalStack, take a look at our general Getting Started guide.\nStarting LocalStack Pro or Enterprise using Docker-Compose When starting LocalStack using docker-compose, you have to make sure your API key is passed properly to the LocalStack container. For this, you have to make sure to include the LOCALSTACK_API_KEY environment variable in your docker-compose.yml like this:\nenvironment:- LOCALSTACK_API_KEY=${LOCALSTACK_API_KEY- }This statement sets the API key we defined before (by using the export command) into your LocalStack container, such that the key activation can take place.\nLicensing-related configuration If you want to make sure that LocalStack is only started if LocalStack Pro or Enterprise can be activated, or if you want to suppress licensing-related error messages, take a look at our configuration guide regarding LocalStack Pro.\nChecking license activation The easiest way to check if LocalStack Pro or Enterprise is activated is to check the health endpoint of LocalStack for a list of the running services:\n$ curl localhost:4566/health | jq If a Pro-only service ‚Äì like XRay ‚Äì is running, LocalStack Pro or Enterprise has started successfully.\nOtherwise, please check our collected most common activation issues.\nCommon activation issues Invalid API key If your API key is invalid, you will see an error message like this in the logs of LocalStack:\nActivation key \"abc...\"(10) is invalid or expired! Reason: ... If this error occurs, something is wrong with your API key or license. Please make sure your API key is set correctly (check for typos!) and your license is valid. If the API key still does not work, please contact us.\nNo connection to the LocalStack API If your log output contains lines like:\nWARNING:localstack_ext.bootstrap.licensing: Error activating API key \"abc...\"(10): ... ConnectionRefusedError: [Errno 111] Connection refused LocalStack cannot contact our API to perform the license activation. Please confirm with your network administrator that no policies block the connection to our backend.\nCannot resolve api.localstack.cloud Log output like the following indicates that your machine cannot resolve the domain of the LocalStack API.\nWARNING:localstack_ext.bootstrap.licensing: Error activating API key \"abc...\"(10): ... socket.gaierror: [Errno -3] Temporary failure in name resolution Please confirm this by using a tool like dig:\n$ dig api.localstack.cloud If the result has some other status than status: NOERROR, your machine cannot resolve this domain.\nSome corporate DNS servers might filter requests to certain domains. Please contact your network administrator in order to whitelist localstack.cloud domains.\nYour issue isn‚Äôt listed here? If you have any problems concerning your API key activation not mentioned here, or if these steps do not help, please do not hesitate to contact us.\n","categories":["LocalStack Pro \u0026 Enterprise"],"description":"Use your API key to start LocalStack Pro or Enterprise.\n","excerpt":"Use your API key to start LocalStack Pro or Enterprise.\n","ref":"/get-started/pro/","tags":"","title":"LocalStack Pro and Enterprise"},{"body":"Covered Topics  JVM Testing Utils  JVM Testing Utils LocalStack provides Java Utils library that integrates with JUnit and provides LocalStack-targeted AWS Clients.\nInstallation Maven  Gradle   \u003cdependency\u003e \u003cgroupId\u003ecloud.localstack\u003c/groupId\u003e \u003cartifactId\u003elocalstack-utils\u003c/artifactId\u003e \u003cversion\u003e0.2.15\u003c/version\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e testImplementation group: 'cloud.localstack', name: 'localstack-utils', version: '0.2.15'  Usage Java  Kotlin   ... import cloud.localstack.LocalstackTestRunner; import cloud.localstack.ServiceName; import cloud.localstack.TestUtils; import cloud.localstack.docker.annotation.LocalstackDockerProperties; @RunWith(LocalstackTestRunner.class) @LocalstackDockerProperties(services = { ServiceName.S3, \"sqs\", \"kinesis\" }) public class MyCloudAppTest { @Test public void testLocalS3API() { AmazonS3 s3 = TestUtils.getClientS3() List\u003cBucket\u003e buckets = s3.listBuckets(); ... } } ... import cloud.localstack.LocalstackTestRunner import cloud.localstack.ServiceName import cloud.localstack.TestUtils import cloud.localstack.docker.annotation.LocalstackDockerProperties @RunWith(LocalstackTestRunner::class) @LocalstackDockerProperties(services = [ServiceName.S3, \"sqs\", \"kinesis\"]) public class MyCloudAppTest { @Test fun testLocalS3API() { val s3 = TestUtils.getClientS3() val buckets = s3.listBuckets(); ... } }  Powermock You can use the PowerMock Library to call the builders default method and still get LocalStack version of the AWS clients.\n... @RunWith(PowerMockRunner.class) @PowerMockRunnerDelegate(LocalstackTestRunner.class) @LocalstackDockerProperties(services = { \"ses\" }) @PrepareForTest({ AmazonSimpleEmailServiceClientBuilder.class, AmazonSimpleEmailServiceAsyncClientBuilder.class }) @PowerMockIgnore({\"javax.crypto.*\", \"org.hamcrest.*\", \"javax.net.ssl.*\", \"com.sun.org.apache.xerces.*\", \"javax.xml.*\", \"org.xml.*\", \"javax.management.*\", \"javax.security.*\", \"org.w3c.*\"}) public class SESMessagingTest { .... @Before public void mockSES() { AmazonSimpleEmailService mockSes = TestUtils.getClientSES(); PowerMockito.mockStatic(AmazonSimpleEmailServiceClientBuilder.class); when(AmazonSimpleEmailServiceClientBuilder.defaultClient()).thenReturn(mockSes); } @Test public void testSendEmail() throws Exception { AmazonSimpleEmailService client = amazonSimpleEmailServiceClientBuilder.defaultClient(); .... PowerMockLocalStack Utility This utility makes easier to use PowerMock with LocalStack.\n... public class PowerMockLocalStackExampleTest extends PowerMockLocalStack{ private static final String TOPIC = \"topic\"; @Before public void mock() { PowerMockLocalStack.mockSNS(); } @Test public void testSendMessage() throws JMSException { final AmazonSNS clientSNS = AmazonSNSClientBuilder.defaultClient(); ... } } ","categories":["LocalStack Community","LocalStack Pro"],"description":"Tools to simplify application testing\n","excerpt":"Tools to simplify application testing\n","ref":"/tools/testing-tools/","tags":"","title":"LocalStack Testing Tools"},{"body":" Warning Multi-account is a preview feature and is not compatible with cloud pods and persistence. To enable multi-accounts, refer to configuration.  LocalStack Community only supports a single AWS Account ID, 000000000000 by default. By contrast, LocalStack Pro ships with multi-account support which adds namespacing based on AWS Account ID\nNamespaced AWS resources can be accessed by using the AWS_ACCESS_KEY_ID variable when making requests. No additional server-side configuration is required.\nNote Multi-account is not supported for the us-east-1 region. See limitation note.  $ export AWS_DEFAULT_REGION=eu-central-1 $ AWS_ACCESS_KEY_ID=000000000001 awslocal ec2 create-key-pair --key-name green-hospital $ AWS_ACCESS_KEY_ID=000000000002 awslocal ec2 create-key-pair --key-name red-medicine $ AWS_ACCESS_KEY_ID=000000000001 awslocal ec2 describe-key-pairs { \"KeyPairs\": [ { \"KeyFingerprint\": \"6b:e3:a3:41:4b:60:f3:6d:7b:84:3e:17:e3:ad:d0:15\", \"KeyName\": \"green-hospital\" } ] } $ AWS_ACCESS_KEY_ID=000000000002 awslocal ec2 describe-key-pairs { \"KeyPairs\": [ { \"KeyFingerprint\": \"16:4c:64:13:36:41:7c:75:d0:51:f0:db:ed:d7:c8:95\", \"KeyName\": \"red-medicine\" } ] } In absence of an explicit value for Account ID, LocalStack reverts to the default value of 000000000000. In the current example, not setting an explicit Account ID will return no resources.\n$ awslocal ec2 describe-key-pairs { \"KeyPairs\": [] } Note LocalStack uses the AWS_ACCESS_KEY_ID client-side variable for Account ID. In future LocalStack may support proper access key IDs issued by the local IAM service, which will then internally be translated to corresponding account IDs.  Limitations Multi-accounts is a preview feature and is not compatible with cloud pods and persistence.\nIn order to use multi-accounts, the region must be configured to something other than us-east-1. Note that us-east-1 is the default region and must be explicitly overridden. For the AWS CLI, this can be done using the AWS_DEFAULT_REGION or the --region argument. More information can be found on AWS CLI documentation.\n","categories":["LocalStack Pro"],"description":"Using LocalStack in multi-tenant setups\n","excerpt":"Using LocalStack in multi-tenant setups\n","ref":"/tools/multi-account-setups/","tags":["multi-tenant","multi-account","account-id","namespaces"],"title":"Multi-Account Setups"},{"body":"The persistence mechanism is essentially a ‚Äúpause and resume‚Äù feature for your LocalStack application state. For instance, you may want to run consecutive integration tests where each test loads in a different context but depends on the state produced by a previous test. Commonly, you may simply have a local development server that relies on a non-ephemeral application state.\nWhile the persistence mechanism covers most services, not all of them are supported yet. Please make sure to check the feature coverage page to see whether your desired services are covered.\nIn the past we supported a version of persistence ‚Äì available in the Community version ‚Äì based on a record-and-replay approach (basically, storing API calls and re-running them on restart), we discontinued this feature with 0.13.1. Therefore, please note that persistence in LocalStack, as currently intended, is a Pro only feature (more on that in the Technical Details section).\nPlease note that the coverage is only guaranteed for the Pro version, while the Community version attempts to restore the state on a best-effort basis using a record-and-replay approach (more on that in the Technical Details section).\nTo enable the persistence mechanism simply set the PERSISTENCE environment variable to 1.\n...environment:- LOCALSTACK_API_KEY=...- PERSISTENCE=1volumes:- \"${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack\"Once the application has been set and configured properly, the /health endpoint of LocalStack will indicate whether the persistence mechanism has been initialized successfully.\n\"features\": { \"persistence\": \"initialized\" } Otherwise, the endpoint will inform you that the mechanism is disabled.\n\"features\": { \"persistence\": \"disabled\" } Technical Details The persistence mechanism in LocalStack Pro is a sophisticated approach based on serialized state. Starting the Pro version of LocalStack will traverse the state directory root folder recursively and directly deserialize the file into the application state.\nTypically, each service has one state file for each region.\nEach serialization mechanism has its root folder. As of now, all supported services are serialized as pickle files. Particular services, in addition to their pickled files, can serialize additional artifacts. For instance, Kinesis persists some data in form of JSON while DynamoDB serializes a SQLite database. This is illustrated in the diagram below.\nRestoring the state ‚Äì even for large projects ‚Äì usually only takes a few milliseconds. Moreover, since the files store accurate snapshots of the application state, they can restore a state that is identical to the one before restarting the instance.\n","categories":"","description":"How the LocalStack persistence mechanism works and how you can configure it.\n","excerpt":"How the LocalStack persistence mechanism works and how you can ‚Ä¶","ref":"/localstack/persistence-mechanism/","tags":"","title":"Persistence Mechanism"},{"body":"Overview This guide covers the remote debugging of Lambda functions with Visual Studio Code or IntelliJ IDEA as an IDE. For a simple working example of this feature, check out our samples repository.\n   Complexity ‚òÖ‚òÜ‚òÜ‚òÜ‚òÜ     Time to read 5 minutes   Edition community/pro   Platform any    More examples and tooling support for local Lambda debugging (including support for other IDEs like PyCharm) is coming soon - stay tuned!\nCovered Topics  Debugging Python lambdas Debugging JVM lambdas Useful Links  Debugging Python lambdas Lambda functions debugging used to be a difficult task. LocalStack changes that with the same local code mounting functionality that also helps you to iterate quickly over your function code.\nFor a simple working example of this feature, you can refer to our samples. There, the necessary code fragments for enabling debugging are already present.\nConfigure LocalStack for remote Python debugging First, make sure that LocalStack is started with the following configuration (see the Configuration docs for more information): $ LAMBDA_REMOTE_DOCKER=0 \\ LAMBDA_DOCKER_FLAGS='-p 19891:19891' \\ DEBUG=1 localstack start\nPreparing your code For providing the debug server, we use debugpy inside the Lambda function code. In general, all you need is the following code fragment placed inside your handler code:\nimport debugpy debugpy.listen(19891) debugpy.wait_for_client() # blocks execution until client is attached For extra convenience, you can use the wait_for_debug_client function from our example. It implements the above-mentioned start of the debug server and also adds an automatic cancellation of the wait task if the debug client (i.e. VSCode) doesn‚Äôt connect.\ndef wait_for_debug_client(timeout=15): \"\"\"Utility function to enable debugging with Visual Studio Code\"\"\" import time, threading import sys, glob sys.path.append(glob.glob(\".venv/lib/python*/site-packages\")[0]) import debugpy debugpy.listen((\"0.0.0.0\", 19891)) class T(threading.Thread): daemon = True def run(self): time.sleep(timeout) print(\"Canceling debug wait task ...\") debugpy.wait_for_client.cancel() T().start() print(\"Waiting for client to attach debugger ...\") debugpy.wait_for_client() Creating the Lambda function To create the Lambda function, you just need to take care of two things:\n Deploy the function via an S3 Bucket. You need to use the magic variable __local__ as the bucket name. Set the S3 key to the path of the directory your lambda function resides in. The handler is then referenced by the filename of your lambda code and the function in that code that should be invoked.  So, in our example, this would be:\n$ awslocal lambda create-function --function-name my-cool-local-function \\ --code S3Bucket=\"__local__\",S3Key=\"$(pwd)/\" \\ --handler handler.handler \\ --runtime python3.8 \\ --role cool-stacklifter We can quickly verify that it works by invoking it with a simple payload:\n$ awslocal lambda invoke --function-name my-cool-local-function --payload '{\"message\": \"Hello from LocalStack!\"}' output.txt Configuring Visual Studio Code for remote Python debugging For attaching the debug server from Visual Studio Code, you need to add a run configuration.\n{ \"version\": \"0.2.0\", \"configurations\": [ { \"name\": \"Python: Remote Attach\", \"type\": \"python\", \"request\": \"attach\", \"connect\": { \"host\": \"localhost\", \"port\": 19891 }, \"pathMappings\": [ { \"localRoot\": \"${workspaceFolder}\", \"remoteRoot\": \".\" } ] } ] } With our function from above you have about 15 seconds (the timeout is configurable) to switch to Visual Studio Code and run the preconfigured remote debugger. Make sure to set a breakpoint in the Lambda handler code first, which can then later be inspected.\nThe screenshot below shows the triggered breakpoint with our 'Hello from LocalStack!' in the variable inspection view:\nLimitations Due to the ports used by the debugger, you can currently only debug one Lambda at a time. Multiple concurrent invocations will not work.\nDebugging JVM lambdas Configure LocalStack for remote JVM debugging Set LAMBDA_JAVA_OPTS with jdwp settings and expose the debug port (you can use any other port of your choice):\n#docker-compose.ymlservices:localstack:...environment:...- LAMBDA_JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=*:5050- LAMBDA_DOCKER_FLAGS=-p 127.0.0.1:5050:5050Note the suspend=y option here, it will delay code execution until debugger is attached to debgger server. If you want to change that simply switch to suspend=n.\nConfiguring IntelliJ IDEA for remote JVM debugging Open the Run/Debug Configurations window and create a new Shell Script with the following content:\nwhile [[ -z $(docker ps | grep :5050) ]]; do sleep 1; done This shell script should simplify the process a bit since the debugger server is not immediately available (only once lambda container is up).\nThen create a new Remote JVM Debug configuration and use the script from above as a Before launch target:\nNow to debug your lambda function, simply click on the Debug icon with Remote JVM on LS Debug configuration selected, and then invoke your lambda function.\nConfiguring Visual Studio Code for remote JVM debugging Make sure you installed the following extensions:\n Language Support for Java(TM) by Red Hat Debugger for Java  Add a new task by creating/modifying the .vscode/tasks.json file:\n{ \"version\": \"2.0.0\", \"tasks\": [ { \"label\": \"Wait Remote Debugger Server\", \"type\": \"shell\", \"command\": \"while [[ -z $(docker ps | grep :5050) ]]; do sleep 1; done; sleep 1;\" } ] } Create a new launch.json file or edit an existing one from the Run and Debug tab, then add the following configuration:\n{ \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"java\", \"name\": \"Remote JVM on LS Debug\", \"projectRoot\": \"${workspaceFolder}\", \"request\": \"attach\", \"hostName\": \"localhost\", \"preLaunchTask\": \"Wait Remote Debugger Server\", \"port\": 5050 } ] } Now to debug your lambda function, click on the Debug icon with Remote JVM on LS Debug configuration selected, and then invoke your lambda function.\nResources  Lambda Code Mounting and Debugging (Python) Spring Cloud Function on LocalStack (Kotlin JVM)  ","categories":["LocalStack Community","LocalStack Pro"],"description":"Attach a debugger to your Lambda functions from your IDE.\n","excerpt":"Attach a debugger to your Lambda functions from your IDE.\n","ref":"/tools/lambda-tools/debugging/","tags":"","title":"Remote Debugging"},{"body":"Overview Terraform allows you to automate the management of AWS resources such as containers, lambda functions and so on by declaring them in the HashiCorp Configuration Language (HCL). On this page we discuss how Terraform and LocalStack can be used together. If you are adapting an existing configuration, you might be able to skip certain steps at your own discretion.\nExample If you have not done so yet, install Terraform.\nUsing Terraform with LocalStack requires little extra configuration. Apart from some information Terraform expects there are basically only two things to take care of in the configuration.\nBefore we start changing the configuration, create and change into a new directory for this sample\n$ mkdir terraform_quickstart \u0026\u0026 cd terraform_quickstart Inside this directory, create a file called main.tf. The following changes go into this file.\nNow we are adding a minimal S3 bucket configuration to the main.tf file:\nresource \"aws_s3_bucket\" \"test-bucket\" { bucket = \"my-bucket\" } Using the tflocal script We provide tflocal, a thin wrapper script around the terraform command line client. tflocal takes care of automatically configuring the local service endpoints, which allows you to easily deploy your unmodified Terraform scripts against LocalStack.\nYou can install the tflocal command via pip (requires a local Python installation): $ pip install terraform-local\nOnce installed, the tflocal command should be available, with the same interface as the terraform command line: $ tflocal --help Usage: terraform [global options] \u003csubcommand\u003e [args] ...\nNote: Alternatively, you can also manually configure the local endpoints in the provider section of your Terraform script - see further below.  Deployment After starting LocalStack you can now deploy the S3 bucket via tflocal and interact with the (still empty) S3 bucket via awslocal!\nAll you need to do is to initialize Terraform:\n$ tflocal init ‚Ä¶ and then provision s3 bucket specified in the configuration: $ tflocal apply\nManual Configuration As an alternative to using the tflocal script, you may also manually configure the local service endpoints and credentials. We‚Äôll walk through the detailed steps in the following sections.\nGeneral Configuration First, we have to specify mock credentials for the AWS provider:\nprovider \"aws\" { access_key = \"test\" secret_key = \"test\" region = \"us-east-1\" } Request Management Second, we need to avoid issues with routing and authentication (as we do not need it). Therefore we need to supply some general parameters:\nprovider \"aws\" { access_key = \"test\" secret_key = \"test\" region = \"us-east-1\"# only required for non virtual hosted-style endpoint use case. # https://registry.terraform.io/providers/hashicorp/aws/latest/docs#s3_force_path_style s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true } Services Additionally, we have to point the individual services to LocalStack. In case of S3, this looks like the following snippet, in this case we opted to use the virtual hosted-style endpoint.\nendpoints { s3 = \"http://s3.localhost.localstack.cloud:4566\" }  Note: In case of issues resolving this DNS record, we can fallback to http://localhost:4566 in combination with the provider setting s3_force_path_style = true. The S3 service endpoint is slightly different from the other service endpoints, because AWS is deprecating path-style based access for hosting buckets.  Final Configuration The final (minimal) configuration to deploy an S3 bucket thus looks like this\nprovider \"aws\" { access_key = \"mock_access_key\" secret_key = \"mock_secret_key\" region = \"us-east-1\" s3_force_path_style = true skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { s3 = \"http://s3.localhost.localstack.cloud:4566\" } } resource \"aws_s3_bucket\" \"test-bucket\" { bucket = \"my-bucket\" } Endpoint Configuration Below is a configuration example with additional service endpoints. Again, these provider configurations should no longer be required if you use the tflocal script (see above).\nprovider \"aws\" { access_key = \"test\" secret_key = \"test\" region = \"us-east-1\" s3_force_path_style = false skip_credentials_validation = true skip_metadata_api_check = true skip_requesting_account_id = true endpoints { apigateway = \"http://localhost:4566\" apigatewayv2 = \"http://localhost:4566\" cloudformation = \"http://localhost:4566\" cloudwatch = \"http://localhost:4566\" dynamodb = \"http://localhost:4566\" ec2 = \"http://localhost:4566\" es = \"http://localhost:4566\" elasticache = \"http://localhost:4566\" firehose = \"http://localhost:4566\" iam = \"http://localhost:4566\" kinesis = \"http://localhost:4566\" lambda = \"http://localhost:4566\" rds = \"http://localhost:4566\" redshift = \"http://localhost:4566\" route53 = \"http://localhost:4566\" s3 = \"http://s3.localhost.localstack.cloud:4566\" secretsmanager = \"http://localhost:4566\" ses = \"http://localhost:4566\" sns = \"http://localhost:4566\" sqs = \"http://localhost:4566\" ssm = \"http://localhost:4566\" stepfunctions = \"http://localhost:4566\" sts = \"http://localhost:4566\" } } Further Reading For more examples, you can take a look at our Terraform sample or the Terraform LocalStack section.\nCommunity Resources  LocalStack with Terraform and Docker for running AWS locally. 2021-07-04  ","categories":"","description":"Use the Terraform Infrastructure as Code framework with LocalStack\n","excerpt":"Use the Terraform Infrastructure as Code framework with LocalStack\n","ref":"/integrations/terraform/","tags":["terraform","infrastructure-as-code"],"title":"Terraform"},{"body":"Overview LocalStack Pro supports transparent execution mode, which means that your application code automatically accesses the LocalStack APIs as opposed to the real APIs on AWS.\nWhen the system starts up, the log output contains the IP address of the local DNS server. Typically, this address by default is either 0.0.0.0 (see example below) or 127.0.0.1 if LocalStack cannot bind to 0.0.0.0 due to a conflicting service.\nStarting DNS servers (tcp/udp port 53 on 0.0.0.0)... Configuration The DNS server can be configured to match your usecase.\n  The DNS server can be configured using the DNS_ADDRESS environment variable. To bind the server to 127.0.0.1, you can set:\nDNS_ADDRESS=127.0.0.1   You can disable the DNS server (which will prevent LocalStack from binding port 53) using:\nDNS_ADDRESS=0   You can also specify which exact URLs should be redirected to LocalStack by defining a hostname regex like:\nDNS_LOCAL_NAME_PATTERNS='.*(ecr|lambda).*.amazonaws.com' Using this configuration, the LocalStack DNS server only redirects ECR and Lambda domains to LocalStack, and the rest will be resolved via $DNS_SERVER. This can be used for hybrid setups, where certain API calls (e.g., ECR, Lambda) target LocalStack, whereas other services will target real AWS.\nNote: We generally do not recommend connecting to real AWS from within LocalStack, in fact you should avoid using real AWS credentials anywhere in your LocalStack apps. Use this configuration with caution.\n  There is the possibility to manually set the DNS server all not-redirected queries will be forwarded to:\nDNS_SERVER=1.1.1.1 Per default, LocalStack uses the Google DNS resolver at 8.8.8.8.\n  Limitations When you configure transparent execution mode using DNS, you may still have to configure your application‚Äôs AWS SDK to accept self-signed certificates. This is a technical limitation caused by the SSL certificate validation mechanism, due to the fact that we are repointing AWS domain names (e.g., *.amazonaws.com) to localhost. For example, the following command will fail with an SSL error: $ aws kinesis list-streams SSL validation failed for https://kinesis.us-east-1.amazonaws.com/ [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1076) ‚Ä¶ whereas the following command works: $ PYTHONWARNINGS=ignore aws --no-verify-ssl kinesis list-streams { \"StreamNames\": [] }\nDisabling SSL validation depends on the programming language and version of the AWS SDK used. For example, the boto3 AWS SDK for Python provides a parameter verify=False to disable SSL verification. Similar parameters are available for most other AWS SDKs.\nFor Node.js, you can set this environment variable in your application, to allow the AWS SDK to talk to the local APIs via SSL:\nprocess.env.NODE_TLS_REJECT_UNAUTHORIZED = \"0\"  Note: Disabling SSL validation may have undesired side effects and security implications. Make sure to use this only for local testing, and never in production.  System DNS configuration In order to use transparent execution mode, the system needs to be configured to use the predefined DNS server. This is necessary if you want to test code running directly on your system against LocalStack, instead of AWS. The configuration depends on the operating system.\nNote: Please be careful when changing the network configuration on your system, as this may have undesired side effects.\nMac OS In Mac OS it can be configured in the Network System Settings, under Linux this is usually achieved by configuring /etc/resolv.conf as follows:\nnameserver 0.0.0.0 The example above needs to be adjusted to the actual IP address of the DNS server. You can also configure a custom IP address by setting the DNS_ADDRESS environment variable (e.g., DNS_ADDRESS=127.0.0.1).\nLinux In Linux, the configuration depends on your network manager / DNS configuration.\nsystemd-resolved On many modern systemd-based distributions, like Ubuntu, systemd-resolved is used for name resolution. LocalStack provides a CLI command for exactly this scenario. To use systemd-resolved and the LocalStack domain resolution, try the following steps.\n  Start LocalStack Pro with DNS_ADDRESS=127.0.0.1 as environment variable. This makes LocalStack bind port 53 on 127.0.0.1, whereas systemd-resolved binds its stub resolver to 127.0.0.53:53, which prevents a conflict. Once LocalStack is started, you can test the DNS server using dig @127.0.0.1 s3.amazonaws.com versus dig @127.0.0.53 s3.amazonaws.com, the former should return an A record 127.0.0.1, the latter the real AWS DNS result.\n  Run: $ localstack dns systemd-resolved\nTo revert, please run: $ localstack dns systemd-resolved --revert\nNote: You need sudo privileges to execute this command.\nThis command sets the DNS server of the bridge interface of the docker network LocalStack currently runs in to the LocalStack container‚Äôs IP address. (The command does not work with host networking or without LocalStack running for this reason.) Also, it configures the DNS route to exclusively (and only) route the following DNS names (and its subdomains) to the LocalStack DNS:\n~amazonaws.com ~aws.amazon.com ~cloudfront.net ~localhost.localstack.cloud   If you want to perform this action manually, please do the following steps:\n  Find out the bridge interface and container IP of your LocalStack container. Use docker inspect localstack_main to get the IP address and network, then docker inspect network to get the interface name. If the interface name is not mentioned, it is usually the first 12 characters of the network ID prefixed with br-, like br-0ae393d3345e. If you use the default bridge network, it is usually docker0.\n  Configure the DNS resolver for the bridge network: # resolvectl dns \u003cnetwork_name\u003e \u003ccontainer_ip\u003e\n  Set the DNS route to route only the above mentioned domain names (and subdomains) to LocalStack: # resolvectl domain \u003cnetwork_name\u003e ~amazonaws.com ~aws.amazon.com ~cloudfront.net ~localhost.localstack.cloud\n  In both cases, you can use resolvectl query s3.amazonaws.com or resolvectl query example.com to check which interface your DNS request is routed through, to confirm only the above mentioned domains (and its subdomains) are routed to LocalStack.\nWhen correctly configured, either using the LocalStack CLI command or manually, only the requests for the mentioned domain names are routed to LocalStack, all other queries will resolve as usual.\nOther resolution settings Depending on your Linux distribution, the settings to set a DNS server can be quite different. In some systems, directly editing /etc/resolv.conf is possible, like described in Mac OS. If your /etc/resolv.conf is overwritten by some service, it might be possible to install and enable/start resolvconf and specify the nameserver in /etc/resolvconf/resolv.conf.d/head with nameserver 127.0.0.1. This will prepend this line in the resolv.conf file even after changes.\nNote: Using this options, every DNS request is forwarded to LocalStack, which will forward queries it does not need to modify (in essence all but certain aws domains). LocalStack will not store or share any forwarded DNS requests, except maybe in the local logs on exceptions / in debug mode.\nCustomizing internal endpoint resolution The DNS name localhost.localstack.cloud (and any subdomains like mybucket.s3.localhost.localstack.cloud) is used internally in LocalStack to route requests, e.g., between a Lambda container and the LocalStack APIs.\nPlease refer to the steps in the Route53 docs for more details on how the internal DNS name can be customized.\n","categories":["LocalStack Pro","Tools","DNS"],"description":"Use LocalStack as DNS server to redirect AWS queries to LocalStack\n","excerpt":"Use LocalStack as DNS server to redirect AWS queries to LocalStack\n","ref":"/tools/local-endpoint-injection/dns-server/","tags":"","title":"DNS Server"},{"body":"Overview The Lambda runtime in LocalStack uses patched AWS SDKs, which are configured to target the local APIs instead of the real AWS. This behavior is enabled by default for most Lambda runtimes when using LocalStack Pro.\nAssuming you had a Python Lambda handler that attempts to list all S3 buckets. In the past, you had to manually configure the endpoint_url parameter on the boto3 client (and potentially use environment switches for dev/prod in your test code):\nimport boto3 def handler(event, context): client = boto3.client(\"s3\", endpoint_url=\"http://localhost:4566\") print(client.list_buckets()) With the patched AWS SDKs, it now becomes possible to deploy your unmodified production code to LocalStack, simply creating a boto3 client with default settings. The invocations of the boto3 client will be automatically forwarded to the local APIs:\nimport boto3 def handler(event, context): client = boto3.client(\"s3\") print(client.list_buckets())  Note: This functionality only works when using the SDKs provided by the Lambda execution environment itself. If you choose to ship your own SDKs with your Lambda or using a layer, it will fallback to the DNS based transparent execution if enabled, since those SDK versions will not be patched.  This feature works by patching the AWS SDKs in the docker images, which provide the execution environment for Lambdas within LocalStack.\nThe main advantage of this mode is, that no DNS magic is involved, and SSL certificate checks do not have to be disabled.\nConfiguration If you want to disable this behavior, and use the DNS server to resolve the endpoints for AWS, you can disable this behavior by using:\nTRANSPARENT_LOCAL_ENDPOINTS=0 Supported Runtimes Currently, LocalStack supports patching the SDKs for the following runtimes:\n Python (using boto3) NodeJS Ruby Java  Also, these patched SDKs are only available in the following Lambda execution modes:\n docker docker-reuse  This feature is currently not supported for custom Lambda container images.\n","categories":["LocalStack Pro","Tools"],"description":"Using patched SDKs in Lambdas to transparently redirect AWS API calls to LocalStack\n","excerpt":"Using patched SDKs in Lambdas to transparently redirect AWS API calls ‚Ä¶","ref":"/tools/local-endpoint-injection/patched-sdks/","tags":"","title":"Patched AWS SDKs for Lambdas"},{"body":"Overview This guide describes how you can monitor and debug your AWS Lambda functions with Thundra.\nIntegrating Thundra with LocalStack Supported languages Currently only Node.js, Python and Java Lambdas are supported in this integration - support for other runtimes (.NET, Go) is coming soon.  LocalStack comes with out-of-the-box support for Thundra. Simply obtain a Thundra API key here and add it to your Lambda function‚Äôs environment variables (THUNDRA_APIKEY):\nAWS SAM  AWS CDK  Serverless Framework   Resources:MyFunction:Type:AWS::Serverless::FunctionProperties:// other function propertiesEnvironment:Variables:// other environment variablesTHUNDRA_APIKEY:\u003cYOUR-THUNDRA-API-KEY\u003e const myFunction = new Function(this, \"MyFunction\", { ..., // other function properties  environment: { ..., // other environment variables  THUNDRA_APIKEY: \u003cMY-THUNDRA-API-KEY\u003e } }); functions:MyFunction:// other function propertiesenvironment:// other environment variablesTHUNDRA_APIKEY:\u003cYOUR-THUNDRA-API-KEY\u003e  After invoking your AWS Lambda function, you can inspect the invocations and traces in the Thundra Console. You can find more details in the Thundra documentation.\nFurther Reading For a complete example, you may check our blog post ‚ÄúTest Monitoring for LocalStack Apps with Thundra‚Äù and take a look at the example project here.\n","categories":"","description":"Monitor and debug your AWS Lambda functions with LocalStack and [Thundra](https://thundra.io).\n","excerpt":"Monitor and debug your AWS Lambda functions with LocalStack and ‚Ä¶","ref":"/integrations/thundra/","tags":["thundra","tracing","observability"],"title":"Thundra"},{"body":"This guide shows how to start and use LocalStack in your Travis CI jobs.\nSetting up the Travis CI job When you want to integrate LocalStack into your job configuration, you just have to execute the following steps:\n Install the LocalStack CLI (and maybe also awslocal). Make sure your LocalStack docker image is up-to-date by pulling the latest version. Use the LocalStack CLI to start LocalStack. Make sure to use the -d flag to start the LocalStack docker container in detached mode. Wait for the container to report that it is up and running.  The following example Travis CI job config (.travis.yaml) executes these steps, creates a new S3 bucket, and prints a nice message in the end:\nlanguage:pythonservices:- dockerpython:- \"3.8\"before_install:# Install the LocalStack CLI and awslocal- python -m pip install localstack awscli-local[ver1]# Make sure to pull the latest version of the image- docker pull localstack/localstack# Start LocalStack in the background- localstack start -d# Wait 30 seconds for the LocalStack container to become ready before timing out- echo \"Waiting for LocalStack startup...\"- localstack wait -t 30- echo \"Startup complete\"script:# Test LocalStack by creating a new S3 bucket (and verify that it has been created by listing all buckets)- awslocal s3 mb s3://test- awslocal s3 ls- echo \"Execute your tests here :)\"Activate LocalStack Pro You can easily enable LocalStack Pro by adding your API key to the project‚Äôs environment variables. The LocalStack CLI will automatically pick it up and activate the Pro features.\nJust go to the project settings in Travis CI (More options ‚Üí Settings), scroll down to the Environment Variables section, and add your API key:\n","categories":"","description":"Use LocalStack in [Travis CI](https://www.travis-ci.com/)\n","excerpt":"Use LocalStack in [Travis CI](https://www.travis-ci.com/)\n","ref":"/ci/travis-ci/","tags":["continuous-integration","ci","continuous-delivery","testing"],"title":"Travis CI"},{"body":"Overview The AWS Serverless Application Model (SAM) is a framework on top of CloudFormation to quickly develop Cloud Applications with a focus on serverless services such as S3, Lambda, API Gateway, Step Functions and more.\nAWS SAM CLI for LocalStack To deploy SAM applications on LocalStack you can use samlocal, a wrapper for the AWS SAM CLI.\nInstallation Simply use pip to install samlocal as a Python library on your machine:\n$ pip install aws-sam-cli-local Usage The samlocal command has the exact same usage as the underlying sam command. The main difference is that for commands like samlocal deploy the operations will be executed against the LocalStack endpoints (http://localhost:4566 by default) instead of real AWS endpoints.\n$ samlocal --help Start using samlocal by deploying a Hello World Application. Please make sure to replace all sam calls with samlocal when following the AWS tutorial.\nConfiguration  EDGE_PORT: Port number under which the LocalStack edge service is available (default: 4566) LOCALSTACK_HOSTNAME: Host under which the LocalStack edge service is available (default: localhost)  ","categories":"","description":"Use the AWS SAM (Serverless Application Model) with LocalStack\n","excerpt":"Use the AWS SAM (Serverless Application Model) with LocalStack\n","ref":"/integrations/aws-sam/","tags":["sam","cloudformation","infrastructure-as-code"],"title":"AWS SAM"},{"body":"With LocalStack 1.0 we have introduced LocalStack Extensions that allow developers to extend and customize LocalStack. Both the feature and the API are currently experimental and may be subject to change.\nUsing Extensions Extensions are a LocalStack Pro feature. To use and install extensions, use the CLI to first log in to your account\n$ localstack login Please provide your login credentials below Username: ... $ localstack extensions --help Usage: localstack extensions [OPTIONS] COMMAND [ARGS]... Manage LocalStack extensions (beta) Options: --help Show this message and exit. Commands: init Initialize the LocalStack extensions environment install Install a LocalStack extension uninstall Remove a LocalStack extension To install an extension, specify the name of the pip dependency that contains the extension. For example, for the official Stripe extension, you can either use the package distributed on pypi:\n$ localstack extensions install localstack-extensions-stripe or you can install it directly from this git repository\n$ localstack extensions install \"git+https://github.com/localstack/localstack-extensions/#egg=localstack-extensions-stripe\u0026subdirectory=stripe\" Developing Extensions The extensions API LocalStack exposes a Python API for building extensions that can be found in the core codebase in localstack.extensions.api.\nThe basic interface to implement is as follows:\nclass Extension(BaseExtension): \"\"\" An extension that is loaded into LocalStack dynamically. The method execution order of an extension is as follows: - on_extension_load - on_platform_start - update_gateway_routes - update_request_handlers - update_response_handlers - on_platform_ready \"\"\" namespace: str = \"localstack.extensions\" \"\"\"The namespace of all basic localstack extensions.\"\"\" name: str \"\"\"The unique name of the extension set by the implementing class.\"\"\" def on_extension_load(self): \"\"\" Called when LocalStack loads the extension. \"\"\" pass def on_platform_start(self): \"\"\" Called when LocalStack starts the main runtime. \"\"\" pass def update_gateway_routes(self, router: Router[RouteHandler]): \"\"\" Called with the Router attached to the LocalStack gateway. Overwrite this to add or update routes. :param router: the Router attached in the gateway \"\"\" pass def update_request_handlers(self, handlers: CompositeHandler): \"\"\" Called with the custom request handlers of the LocalStack gateway. Overwrite this to add or update handlers. :param handlers: custom request handlers of the gateway \"\"\" pass def update_response_handlers(self, handlers: CompositeResponseHandler): \"\"\" Called with the custom response handlers of the LocalStack gateway. Overwrite this to add or update handlers. :param handlers: custom response handlers of the gateway \"\"\" pass def on_platform_ready(self): \"\"\" Called when LocalStack is ready and the Ready marker has been printed. \"\"\" pass A minimal example would look like this:\nimport logging from localstack.extensions.api import Extension LOG = logging.getLogger(__name__) class ReadyAnnoucerExtension(Extension): name = \"my_ready_annoucer\" def on_platform_ready(self): LOG.info(\"my plugin is laded and localstack is ready to roll!\") Package your Extension Your extensions needs to be packaged as a Python distribution with a setup.cfg or setup.py config. LocalStack uses the Plux code loading framework to load your code from a Python entry point.\nYou can either use Plux to discover the entrypoints from your code when building and publishing your distribution, or manually define them as in the example below.\nA minimal setup.cfg for the extension above could look like this:\n[metadata] name = localstack-extension-ready-announcer description = LocalStack extension that logs when LocalStack is ready to receive requests author = Your Name author_email = your@email.com url = https://link-to-your-project [options] zip_safe = False packages = find: install_requires =localstack\u003e=1.0.0 [options.entry_points] localstack.extensions =my_ready_annoucer = localstack_annoucer.extension:ReadyAnnoucerExtension The entry point group is the Plux namespace locastack.extensions, and the entry point name is the plugin name my_ready_announcer. The object reference points to the plugin class.\n","categories":"","description":"LocalStack Extensions allows developers to extend and customize LocalStack.\n","excerpt":"LocalStack Extensions allows developers to extend and customize ‚Ä¶","ref":"/developer-guide/localstack-extensions/","tags":"","title":"LocalStack Extensions"},{"body":"Overview The AWS Cloud Development Kit (CDK) is an IaC (Infrastructure-as-Code) tool using general-purpose programming languages such as TypeScript/JavaScript, Python, Java, and .NET to programmatically define your cloud architecture on AWS.\nAWS CDK CLI for LocalStack cdklocal is a thin wrapper script for using the AWS CDK library against local APIs provided by LocalStack.\nInstallation The cdklocal command line is published as an npm library:\n# Install globally npm install -g aws-cdk-local aws-cdk # Verify it installed correctly cdklocal --version # e.g. 1.65.5  Local node_modules Using cdklocal locally (e.g. within the node_modules of your repo instead of globally installed) does not work at the moment for some setups, so make sure you install both aws-cdk and aws-cdk-local with the -G flag.  Usage cdklocal can be used as a drop-in replacement of where you would otherwise use cdk when targeting the AWS Cloud.\n$ cdklocal --help Configuration The following environment variables can be configured:\n EDGE_PORT: Port under which LocalStack edge service is accessible (default: 4566) LOCALSTACK_HOSTNAME: Target host under which LocalStack edge service is accessible (default: localhost) LAMBDA_MOUNT_CODE: Whether to use local Lambda code mounting (via setting __local__ S3 bucket name)  Example Make sure that LocalStack is installed and successfully started with the required services before running the example\n$ curl http://localhost:4566/health The CDK command line ships with a sample app generator to run a quick test for getting started.\n# create sample app mkdir /tmp/test; cd /tmp/test cdklocal init sample-app --language=javascript # deploy the sample app  cdklocal deploy \u003e Do you wish to deploy these changes (y/n)? y Once the deployment is done, you can inspect the created resources via the awslocal command line\n$ awslocal sns list-topics { \"Topics\": [ { \"TopicArn\": \"arn:aws:sns:us-east-1:000000000000:TestStack-TestTopic339EC197-79F43WWCCS4Z\" } ] } External resources  aws-cdk-local AWS CDK API reference AWS CDK Developer Guide  Community resources  https://blog.dennisokeeffe.com/blog/2021-08-07-using-the-aws-cdk-with-localstack-and-aws-cdk-local https://www.youtube.com/watch?v=3_sqr0G9zb0  ","categories":"","description":"Use the AWS CDK (Cloud Development Kit) with LocalStack\n","excerpt":"Use the AWS CDK (Cloud Development Kit) with LocalStack\n","ref":"/integrations/aws-cdk/","tags":["cdk","cloudformation","infrastructure-as-code"],"title":"AWS CDK"},{"body":"Cloud Pods are a mechanism that allows you to take a snapshot of the state in your current LocalStack instance, persist it to a storage backend, and easily share it with your team members.\nWhile the Persistence feature ensures that the service state survives container restarts, Cloud Pods go beyond and allow more fine-grained control over your state. Instead of simply restoring a state when restarting LocalStack, Cloud Pods allow you to take snapshots of your local instance (with the commit command) and inject such snapshots into a running instance (with the inject command) without requiring a restart.\nIn addition, we provide a remote storage backend that can be used to store the state of your running application and share it with your team members.\nYou can interact with Cloud Pods via the Web UI, and to load and store the persistent state of pods, you can use the localstack command-line interface (CLI).\nBelow is a simple example of how you can push and pull Cloud Pods to/from the remote platform using the localstack CLI:\n# User 1 pushes state of Cloud Pod to persistent server $ awslocal kinesis list-streams {\"StreamNames\": [\"mystream123\"]} $ localstack pod push --name mypod1 ... # User 2 pulls state from the server to local instance $ localstack pod pull --name mypod1 $ awslocal kinesis list-streams {\"StreamNames\": [\"mystream123\"]}  Current Limitations Currently, Cloud Pods CLI commands require to set a LOCALSTACK_API_KEY. Additionally, they require to install localstack runtime dependencies. You can install them with pip install localstack\"[runtime]\".  After pulling the pod, LocalStack will automatically inject its state into your instance at runtime, without requiring a restart. By default, the injecting state will replace the one in current the application state. The application and the injecting state can be merged with the --merge flag.\nPlease be aware that the merge feature is still experimental and might lead sometimes to unwanted results. Please make sure to create a backup of any data before merging a cloud pod, if required.  ","categories":["LocalStack Pro","Tools","Persistence"],"description":"Cloud Pods provides a new way of collaborating in cloud application development workflows.\n","excerpt":"Cloud Pods provides a new way of collaborating in cloud application ‚Ä¶","ref":"/tools/cloud-pods/","tags":"","title":"Cloud Pods"},{"body":"LocalStack supports a wide range of tools from the cloud development ecosystem. This section of the documentation covers tools that are officially supported by LocalStack.\nThe Cloud Development Ecosystem Cloud development has many facets and a rich ecosystem of tools to cover them. Whether you are using Infrastructure-as-Code (IaC) to manage your AWS infrastructure, or are developing applications using AWS SDKs like boto, LocalStack allows you to run your workflow completely on your local machine.\n  Integrations We strive to make the integration of LocalStack into your workflow as seamless as possible. Sometimes it‚Äôs as easy as calling one of our wrapper tools, like awslocal, a drop-in replacement for the aws CLI. Other times there is a bit of configuration involved.\nHere is a list of tools we support, and documentation on how to integrate LocalStack:\n","categories":"","description":"How to use your favorite cloud development tools with LocalStack.\n","excerpt":"How to use your favorite cloud development tools with LocalStack.\n","ref":"/integrations/","tags":"","title":"Integrations"},{"body":"Lambdas are awesome!\n","categories":"","description":"Develop your Lambdas more efficiently.\n","excerpt":"Develop your Lambdas more efficiently.\n","ref":"/tools/lambda-tools/","tags":"","title":"Lambda Tools"},{"body":"In the community (open source) edition, the application code needs to configure each AWS SDK client instance with the target endpoint URL to point to the APIs on localhost or, in the case of Lambdas running in the context of LocalStack, the endpoint URL should point to http://${LOCALSTACK_HOSTNAME}:${EDGE_PORT}.\nThe Pro version provides two options for transparently making your application logic speak to the local APIs instead of real AWS (without having to change your production code):\n integrated DNS server patched AWS SDKs  More details can be found in the subsections below.\n","categories":"","description":"Transparently inject local endpoints into AWS SDKs and redirect your AWS calls to LocalStack\n","excerpt":"Transparently inject local endpoints into AWS SDKs and redirect your ‚Ä¶","ref":"/tools/local-endpoint-injection/","tags":"","title":"Local Endpoint Injection"},{"body":"Getting started with LocalStack via the Cockpit is easy: just download the Cockpit App for your operating system at https://localstack.cloud/products/cockpit make sure you have Docker installed, and you‚Äôre ready to go!\nPrerequisites To run LocalStack using the Cockpit you only need Docker and the Cockpit app.\nNote: The Cockpit beta version is not yet verified on Windows and Mac app stores. On Windows and Mac you need to allow your OS to run untrusted code.  Features The LocalStack Cockpit makes it easy for you to manage your LocalStack instance. Here are some of the Cockpit‚Äôs features:\nAutomatic environment check When the Cockpit starts it will automatically check your system environment whether everything is ready to start LocalStack. It will also download the LocalStack Docker image for you, should it not be on your system.\n Run configurations Manage and select LocalStack run configurations to start LocalStack with a particular configuration. Save your LocalStack Pro API key, or a particular set of environment variables into a run configuration.\n  Manage your LocalStack instance Start and stop LocalStack by simply clicking a button. No mucking about in the CLI or a docker-compose file. The environment and Services screen give you instant insights into your running instance.\n Quick log access Get quick access to your LocalStack logs for instant insights.\nNote: The beta version does not yet have auto-followcockpit, so you need to click ‚ÄúRefresh‚Äù and ‚ÄúScroll to end‚Äù.\n Known issues  MacOS ‚â§ v10 not supported yet. There may be glibc issues on older Linux versions.  Report issues Please help us make LocalStack Cockpit better! If you experience a problem, have feedback or a feature request for us, please submit an issue. Ideally add your log files, so that we can investigate into your problem more easily.\nLogs folder:\n Linux: ~/.config/localstack-cockpit/logs/ macOS: ~/Library/Logs/localstack-cockpit/ Windows: %USERPROFILE%\\AppData\\Roaming\\localstack-cockpit\\logs\\  ","categories":["LocalStack Cockpit"],"description":"Manage your local LocalStack instance via the Cockpit Desktop UI.\n","excerpt":"Manage your local LocalStack instance via the Cockpit Desktop UI.\n","ref":"/get-started/cockpit/","tags":"","title":"LocalStack Cockpit"},{"body":"Overview Pulumi‚Äôs infrastructure-as-code SDK helps you create, deploy, and manage AWS containers, serverless functions, and infrastructure using familiar programming languages. The endpoints configuration environment of Pulumi allows us to easily point Pulumi to LocalStack. This guide follows the instructions from Pulumi‚Äôs Get Started with Pulumi and AWS guide, with additional explanations of how to make it work with LocalStack.\nQuickstart Create a new Pulumi stack First, run the following commands and follow the instructions in the CLI to create a new project.\n$ mkdir quickstart \u0026\u0026 cd quickstart $ pulumi new aws-typescript We use the default configuration values:\nThis command will walk you through creating a new Pulumi project. Enter a value or leave blank to accept the (default), and press \u003cENTER\u003e. Press ^C at any time to quit. project name: (quickstart) project description: (A minimal AWS TypeScript Pulumi program) Created project 'quickstart' Please enter your desired stack name. To create a stack in an organization, use the format \u003corg-name\u003e/\u003cstack-name\u003e (e.g. `acmecorp/dev`). stack name: (dev) Created stack 'dev' aws:region: The AWS region to deploy into: (us-east-1) Saved config Installing dependencies... This will create the following directory structure.\n$ tree -L 1 . ‚îú‚îÄ‚îÄ index.ts ‚îú‚îÄ‚îÄ node_modules ‚îú‚îÄ‚îÄ package.json ‚îú‚îÄ‚îÄ package-lock.json ‚îú‚îÄ‚îÄ Pulumi.dev.yaml ‚îú‚îÄ‚îÄ Pulumi.yaml ‚îî‚îÄ‚îÄ tsconfig.json Now edit your stack configuration Pulumi.dev.yaml as follows:\nconfig:aws:accessKey:testaws:secretKey:testaws:s3ForcePathStyle:'true'aws:skipCredentialsValidation:'true'aws:skipRequestingAccountId:'true'aws:endpoints:- accessanalyzer:http://localhost:4566account:http://localhost:4566acm:http://localhost:4566acmpca:http://localhost:4566alexaforbusiness:http://localhost:4566amp:http://localhost:4566amplify:http://localhost:4566amplifybackend:http://localhost:4566apigateway:http://localhost:4566apigatewayv2:http://localhost:4566appautoscaling:http://localhost:4566appconfig:http://localhost:4566appflow:http://localhost:4566appintegrations:http://localhost:4566appintegrationsservice:http://localhost:4566applicationautoscaling:http://localhost:4566applicationcostprofiler:http://localhost:4566applicationdiscovery:http://localhost:4566applicationdiscoveryservice:http://localhost:4566applicationinsights:http://localhost:4566appmesh:http://localhost:4566appregistry:http://localhost:4566apprunner:http://localhost:4566appstream:http://localhost:4566appsync:http://localhost:4566athena:http://localhost:4566auditmanager:http://localhost:4566augmentedairuntime:http://localhost:4566autoscaling:http://localhost:4566autoscalingplans:http://localhost:4566backup:http://localhost:4566batch:http://localhost:4566braket:http://localhost:4566budgets:http://localhost:4566chime:http://localhost:4566cloud9:http://localhost:4566cloudcontrol:http://localhost:4566cloudcontrolapi:http://localhost:4566clouddirectory:http://localhost:4566cloudformation:http://localhost:4566cloudfront:http://localhost:4566cloudhsm:http://localhost:4566cloudhsmv2:http://localhost:4566cloudsearch:http://localhost:4566cloudsearchdomain:http://localhost:4566cloudtrail:http://localhost:4566cloudwatch:http://localhost:4566cloudwatchevents:http://localhost:4566cloudwatchlogs:http://localhost:4566codeartifact:http://localhost:4566codebuild:http://localhost:4566codecommit:http://localhost:4566codedeploy:http://localhost:4566codeguruprofiler:http://localhost:4566codegurureviewer:http://localhost:4566codepipeline:http://localhost:4566codestar:http://localhost:4566codestarconnections:http://localhost:4566codestarnotifications:http://localhost:4566cognitoidentity:http://localhost:4566cognitoidentityprovider:http://localhost:4566cognitoidp:http://localhost:4566cognitosync:http://localhost:4566comprehend:http://localhost:4566comprehendmedical:http://localhost:4566config:http://localhost:4566configservice:http://localhost:4566connect:http://localhost:4566connectcontactlens:http://localhost:4566connectparticipant:http://localhost:4566costandusagereportservice:http://localhost:4566costexplorer:http://localhost:4566cur:http://localhost:4566databasemigration:http://localhost:4566databasemigrationservice:http://localhost:4566dataexchange:http://localhost:4566datapipeline:http://localhost:4566datasync:http://localhost:4566dax:http://localhost:4566detective:http://localhost:4566devicefarm:http://localhost:4566devopsguru:http://localhost:4566directconnect:http://localhost:4566dlm:http://localhost:4566dms:http://localhost:4566docdb:http://localhost:4566ds:http://localhost:4566dynamodb:http://localhost:4566dynamodbstreams:http://localhost:4566ec2:http://localhost:4566ec2instanceconnect:http://localhost:4566ecr:http://localhost:4566ecrpublic:http://localhost:4566ecs:http://localhost:4566efs:http://localhost:4566eks:http://localhost:4566elasticache:http://localhost:4566elasticbeanstalk:http://localhost:4566elasticinference:http://localhost:4566elasticsearch:http://localhost:4566elasticsearchservice:http://localhost:4566elastictranscoder:http://localhost:4566elb:http://localhost:4566elbv2:http://localhost:4566emr:http://localhost:4566emrcontainers:http://localhost:4566es:http://localhost:4566eventbridge:http://localhost:4566events:http://localhost:4566finspace:http://localhost:4566finspacedata:http://localhost:4566firehose:http://localhost:4566fis:http://localhost:4566fms:http://localhost:4566forecast:http://localhost:4566forecastquery:http://localhost:4566forecastqueryservice:http://localhost:4566forecastservice:http://localhost:4566frauddetector:http://localhost:4566fsx:http://localhost:4566gamelift:http://localhost:4566glacier:http://localhost:4566globalaccelerator:http://localhost:4566glue:http://localhost:4566gluedatabrew:http://localhost:4566greengrass:http://localhost:4566greengrassv2:http://localhost:4566groundstation:http://localhost:4566guardduty:http://localhost:4566health:http://localhost:4566healthlake:http://localhost:4566honeycode:http://localhost:4566iam:http://localhost:4566identitystore:http://localhost:4566imagebuilder:http://localhost:4566inspector:http://localhost:4566iot:http://localhost:4566iot1clickdevices:http://localhost:4566iot1clickdevicesservice:http://localhost:4566iot1clickprojects:http://localhost:4566iotanalytics:http://localhost:4566iotdataplane:http://localhost:4566iotdeviceadvisor:http://localhost:4566iotevents:http://localhost:4566ioteventsdata:http://localhost:4566iotfleethub:http://localhost:4566iotjobsdataplane:http://localhost:4566iotsecuretunneling:http://localhost:4566iotsitewise:http://localhost:4566iotthingsgraph:http://localhost:4566iotwireless:http://localhost:4566kafka:http://localhost:4566kafkaconnect:http://localhost:4566kendra:http://localhost:4566kinesis:http://localhost:4566kinesisanalytics:http://localhost:4566kinesisanalyticsv2:http://localhost:4566kinesisvideo:http://localhost:4566kinesisvideoarchivedmedia:http://localhost:4566kinesisvideomedia:http://localhost:4566kinesisvideosignalingchannels:http://localhost:4566kms:http://localhost:4566lakeformation:http://localhost:4566lambda:http://localhost:4566lexmodelbuilding:http://localhost:4566lexmodelbuildingservice:http://localhost:4566lexmodels:http://localhost:4566lexmodelsv2:http://localhost:4566lexruntime:http://localhost:4566lexruntimeservice:http://localhost:4566lexruntimev2:http://localhost:4566licensemanager:http://localhost:4566lightsail:http://localhost:4566location:http://localhost:4566lookoutequipment:http://localhost:4566lookoutforvision:http://localhost:4566lookoutmetrics:http://localhost:4566machinelearning:http://localhost:4566macie:http://localhost:4566macie2:http://localhost:4566managedblockchain:http://localhost:4566marketplacecatalog:http://localhost:4566marketplacecommerceanalytics:http://localhost:4566marketplaceentitlement:http://localhost:4566marketplaceentitlementservice:http://localhost:4566marketplacemetering:http://localhost:4566mediaconnect:http://localhost:4566mediaconvert:http://localhost:4566medialive:http://localhost:4566mediapackage:http://localhost:4566mediapackagevod:http://localhost:4566mediastore:http://localhost:4566mediastoredata:http://localhost:4566mediatailor:http://localhost:4566memorydb:http://localhost:4566mgn:http://localhost:4566migrationhub:http://localhost:4566migrationhubconfig:http://localhost:4566mobile:http://localhost:4566mobileanalytics:http://localhost:4566mq:http://localhost:4566mturk:http://localhost:4566mwaa:http://localhost:4566neptune:http://localhost:4566networkfirewall:http://localhost:4566networkmanager:http://localhost:4566nimblestudio:http://localhost:4566opsworks:http://localhost:4566opsworkscm:http://localhost:4566organizations:http://localhost:4566outposts:http://localhost:4566personalize:http://localhost:4566personalizeevents:http://localhost:4566personalizeruntime:http://localhost:4566pi:http://localhost:4566pinpoint:http://localhost:4566pinpointemail:http://localhost:4566pinpointsmsvoice:http://localhost:4566polly:http://localhost:4566pricing:http://localhost:4566prometheus:http://localhost:4566prometheusservice:http://localhost:4566proton:http://localhost:4566qldb:http://localhost:4566qldbsession:http://localhost:4566quicksight:http://localhost:4566ram:http://localhost:4566rds:http://localhost:4566rdsdata:http://localhost:4566rdsdataservice:http://localhost:4566redshift:http://localhost:4566redshiftdata:http://localhost:4566rekognition:http://localhost:4566resourcegroups:http://localhost:4566resourcegroupstagging:http://localhost:4566resourcegroupstaggingapi:http://localhost:4566robomaker:http://localhost:4566route53:http://localhost:4566route53domains:http://localhost:4566route53recoverycontrolconfig:http://localhost:4566route53recoveryreadiness:http://localhost:4566route53resolver:http://localhost:4566s3:http://localhost:4566s3control:http://localhost:4566s3outposts:http://localhost:4566sagemaker:http://localhost:4566sagemakeredgemanager:http://localhost:4566sagemakerfeaturestoreruntime:http://localhost:4566sagemakerruntime:http://localhost:4566savingsplans:http://localhost:4566schemas:http://localhost:4566sdb:http://localhost:4566secretsmanager:http://localhost:4566securityhub:http://localhost:4566serverlessapplicationrepository:http://localhost:4566serverlessapprepo:http://localhost:4566serverlessrepo:http://localhost:4566servicecatalog:http://localhost:4566servicediscovery:http://localhost:4566servicequotas:http://localhost:4566ses:http://localhost:4566sesv2:http://localhost:4566sfn:http://localhost:4566shield:http://localhost:4566signer:http://localhost:4566simpledb:http://localhost:4566sms:http://localhost:4566snowball:http://localhost:4566sns:http://localhost:4566sqs:http://localhost:4566ssm:http://localhost:4566ssmcontacts:http://localhost:4566ssmincidents:http://localhost:4566sso:http://localhost:4566ssoadmin:http://localhost:4566ssooidc:http://localhost:4566stepfunctions:http://localhost:4566storagegateway:http://localhost:4566sts:http://localhost:4566support:http://localhost:4566swf:http://localhost:4566synthetics:http://localhost:4566textract:http://localhost:4566timestreamquery:http://localhost:4566timestreamwrite:http://localhost:4566transcribe:http://localhost:4566transcribeservice:http://localhost:4566transcribestreaming:http://localhost:4566transcribestreamingservice:http://localhost:4566transfer:http://localhost:4566translate:http://localhost:4566waf:http://localhost:4566wafregional:http://localhost:4566wafv2:http://localhost:4566wellarchitected:http://localhost:4566workdocs:http://localhost:4566worklink:http://localhost:4566workmail:http://localhost:4566workmailmessageflow:http://localhost:4566workspaces:http://localhost:4566xray:http://localhost:4566Deploy the stack to LocalStack Make sure your LocalStack is running. For the example stack, the only required service is S3. After updating the stack configuration, and starting localstack, you can run:\n$ pulumi up once the stack update was performed, you can run:\n$ awslocal s3 ls Where you should see something like\n2021-09-30 11:50:59 my-bucket-6c21027 Pulumilocal pulumilocal is a wrapper script and drop-in replacement for the pulumi CLI, that also provides commands to better interface Pulumi with LocalStack. You can find the source code repository here: https://github.com/localstack/pulumi-local\nInstall pulumilocal requires that you already have the pulumi command in your path. Then, simply run\n$ pip install pulumi-local then,\npulumi version pulumilocal version should output the same value.\nUse Instead of manually editing a stack configuration as explained earlier, you can run\n$ pulumilocal init which will create a Pulumi.localstack.yaml stack configuration, and initialize an additional stack named localstack.\nYou can now run\n$ pulumilocal up to start the localstack stack.\nConfiguration You can configure the integration between pulumi-local and LocalStack by adding these environment variables before running pulumilocal:\n   Variable Default value Description     PULUMI_CMD pulumi The Pulumi command that is being delegated to   PULUMI_STACK_NAME localstack The Pulumi stack name used for looking up the stack file (Pulumi.\u003cstack\u003e.yaml)   LOCALSTACK_HOSTNAME localhost The name of the host LocalStack is reachable at   EDGE_PORT 4566 The port LocalStack is reachable at   USE_SSL 0 A truthy (1, true) string that indicates whether to use SSL when connecting to LocalStack    Community resources Articles  Pulumi and LocalStack ‚Äì beyond the basics. 2021-08-26 How to deploy LocalStack with Pulumi. 2020-09-22  ","categories":"","description":"Use the Pulumi Infrastructure as Code framework with LocalStack\n","excerpt":"Use the Pulumi Infrastructure as Code framework with LocalStack\n","ref":"/integrations/pulumi/","tags":["pulumi","infrastructure-as-code"],"title":"Pulumi"},{"body":"We regularly run the test suite of the Terraform AWS provider against LocalStack to test the compatibility of LocalStack to Terraform. To that end we have a dedicated repository localstack/localstack-terraform-test, where you can also find instructions on how to run the tests.\n","categories":["Stub"],"description":"How to run the Terraform test suite.\n","excerpt":"How to run the Terraform test suite.\n","ref":"/developer-guide/terraform-tests/","tags":"","title":"Terraform test suite"},{"body":"LocalStack does not currently support AWS MSK out of the box, but you can run your own self-managed Kafka cluster and integrate it with your own applications.\nRunning self-managed Kafka You can find the example Docker Compose file which contains a single-noded ZooKeeper and a Kafka cluster and a simple LocalStack setup as well as Kowl, an Apache Kafka Web UI.\n Run Docker Compose:  $ docker-compose up -d Create the Lambda function:  $ awslocal lambda create-function \\ --function-name fun1 \\ --handler lambda.handler \\ --runtime python3.8 \\ --role r1 \\ --zip-file fileb://lambda.zip { \"FunctionName\": \"fun1\", \"FunctionArn\": \"arn:aws:lambda:us-east-1:000000000000:function:fun1\", \"Runtime\": \"python3.8\", \"Role\": \"r1\", \"Handler\": \"lambda.handler\", \"CodeSize\": 294, \"Description\": \"\", \"Timeout\": 3, \"LastModified\": \"2021-05-19T02:01:06.617+0000\", \"CodeSha256\": \"/GPsiNXaq4tBA4QpxPCwgpeVfP7j+1tTH6zdkJ3jiU4=\", \"Version\": \"$LATEST\", \"VpcConfig\": {}, \"TracingConfig\": { \"Mode\": \"PassThrough\" }, \"RevisionId\": \"d85469d2-8558-4d75-bc0e-5926f373e12c\", \"State\": \"Active\", \"LastUpdateStatus\": \"Successful\", \"PackageType\": \"Zip\" } Create an example secret:  $ awslocal secretsmanager create-secret --name localstack { \"ARN\": \"arn:aws:secretsmanager:us-east-1:000000000000:secret:localstack-TDIuI\", \"Name\": \"localstack\", \"VersionId\": \"32bbb8e2-46ee-4322-b3d5-b6459d54513b\" } Create an example Kafka topic:  $ docker exec -ti kafka kafka-topics --zookeeper zookeeper:2181 --create --replication-factor 1 --partitions 1 --topic t1 Created topic t1. Create the event source mapping to your local kafka cluster:  $ awslocal lambda create-event-source-mapping \\ --topics t1 \\ --source-access-configuration Type=SASL_SCRAM_512_AUTH,URI=arn:aws:secretsmanager:us-east-1:000000000000:secret:localstack-TDIuI \\ --function-name arn:aws:lambda:us-east-1:000000000000:function:fun1 \\ --self-managed-event-source '{\"Endpoints\":{\"KAFKA_BOOTSTRAP_SERVERS\":[\"localhost:9092\"]}}' { \"UUID\": \"4a2b0ea6-960c-4847-8684-465876dd6dbd\", \"BatchSize\": 100, \"FunctionArn\": \"arn:aws:lambda:us-east-1:000000000000:function:fun1\", \"LastModified\": \"2021-05-19T04:02:49+02:00\", \"LastProcessingResult\": \"OK\", \"State\": \"Enabled\", \"StateTransitionReason\": \"User action\", \"Topics\": [ \"t1\" ], \"SourceAccessConfigurations\": [ { \"Type\": \"SASL_SCRAM_512_AUTH\", \"URI\": \"arn:aws:secretsmanager:us-east-1:000000000000:secret:localstack-TDIuI\" } ], \"SelfManagedEventSource\": { \"Endpoints\": { \"KAFKA_BOOTSTRAP_SERVERS\": [ \"localhost:9092\" ] } } } Aditionally visit http://localhost:8080 for Kowl‚Äôs UI.  ","categories":"","description":"Using LocalStack lambda with self-managed Kafka cluster\n","excerpt":"Using LocalStack lambda with self-managed Kafka cluster\n","ref":"/integrations/kafka/","tags":["kafka","self-managed"],"title":"Self-managed Kafka cluster"},{"body":"AWS Chalice is a serverless micro framework used to develop and deploy your serverless applications on AWS resources. Chalice provides integrated functionality with most of the AWS Toolings like S3 Storage, Simple Queue Service, API Gateway and more. It offers a handy CLI interface that allows you to easily create, develop \u0026 deploy your serverless applications.\nLocalStack offers an AWS Chalice client that allows you to interact with your Chalice applications locally. Using LocalStack, you can kick-start your development process, create a new Chalice application, and test it application locally.\nCreating a new Chalice project Start LocalStack inside a Docker container by running:\n$ localstack start -d Install the chalice-local package by running:\n$ pip install chalice-local You can now create a new Chalice project by running:\n$ chalice-local new-project You will be prompted with an interactive menu where you can choose the name of your project and the project type. In this example, we are using localstack-test as the project name and REST API as the project type:\n___ _ _ _ _ ___ ___ ___ / __|| || | /_\\  | | |_ _|/ __|| __| | (__ | __ | / _ \\ | |__ | || (__ | _| \\___||_||_|/_/ \\_\\|____||___|\\___||___| The python serverless microframework for AWS allows you to quickly create and deploy applications using Amazon API Gateway and AWS Lambda. Please enter the project name [?] Enter the project name: localstack-test [?] Select your project type: REST API \u003e REST API S3 Event Handler Lambda Functions only Legacy REST API Template [CDK] Rest API with a DynamoDB table Your project has been generated in ./localstack-test Let‚Äôs take a look inside the project structure:\ntree . ‚îú‚îÄ‚îÄ app.py ‚îú‚îÄ‚îÄ chalicelib ‚îÇ¬†‚îî‚îÄ‚îÄ __init__.py ‚îú‚îÄ‚îÄ requirements-dev.txt ‚îú‚îÄ‚îÄ requirements.txt ‚îî‚îÄ‚îÄ tests ‚îú‚îÄ‚îÄ __init__.py ‚îî‚îÄ‚îÄ test_app.py 2 directories, 6 files The app.py is our main API file. It has only one Route that would assign the URL of the application to the function. The decorators here primarily ‚Äúwrap‚Äù functions here which makes it easy to write Code Logic by breaking them down into separate routes. For now, our Application is serving only a JSON Message which is {'hello': 'world'}.\nTesting the Chalice API Just as with AWS, you can now test your API using chalice-local local:\n$ chalice-local local Serving on http://127.0.0.1:8000 You can also do a curl to test the API:\n$ curl -X GET http://127.0.0.1:8000 {\"hello\":\"world\"} Deploying the Chalice API You can use chalice-local deploy to deploy the REST API now:\n$ chalice-local deploy Creating deployment package. Creating IAM role: localstack-test-dev Creating lambda function: localstack-test-dev Creating Rest API Resources deployed: - Lambda ARN: arn:aws:lambda:us-east-1:000000000000:function:localstack-test-dev - Rest API URL: https://y5iuni004m.execute-api.us-east-1.amazonaws.com/api/ We now have our Chalice Application deployed on a Lambda Amazon Resource Name (ARN) along with a REST API URL.\n","categories":"","description":"Understanding the usage of AWS Chalice with LocalStack\n","excerpt":"Understanding the usage of AWS Chalice with LocalStack\n","ref":"/integrations/chalice/","tags":["chalice"],"title":"AWS Chalice"},{"body":"LocalStack is key component of testing and delivering cloud-native applications in Continuous Integration/Delivery pipelines without complicated AWS testing and staging environments.\nExample workflow The following image shows an example workflow. The CI build is triggered through pushing code to the version control repository. The CI runner starts LocalStack and executes the test suite. The same Infrastructure-as-Code (IaC) configuration that sets up AWS in your production environment can be used to set up LocalStack in the CI environment. LocalStack Cloud Pods can be used to pre-seed state into the services (e.g., DynamoDB entries, or S3 files). The tests then execute the application in the cloud environment emulated by LocalStack. After a successful test run, the more expensive AWS CodeBuild pipeline for deploying your application can be executed. The test reports created by your testing framework can be enriched with traces and analytics generated inside LocalStack.\n  Running LocalStack in CI environments It is easy to run LocalStack in your CI runners. For some CI environments, for example Circle CI, we provide plugins that allow seamless integration of LocalStack in your workflow. But LocalStack can work in any CI environment, and we have several examples in the sections below.\n","categories":"","description":"Using LocalStack in your Continuous Integration workflow\n","excerpt":"Using LocalStack in your Continuous Integration workflow\n","ref":"/ci/","tags":"","title":"LocalStack in CI"},{"body":"With version 0.13, LocalStack officially publishes a multi-architecture Docker manifest. This manifest contains links to a Linux AMD64 as well as a Linux ARM64 image.\nExperimental The ARM64 image of LocalStack is still experimental. Help us getting aware of current issues with the ARM64 image by filing an issue if you experience any problems.\nCurrently known limitations are collected in the GitHub issue localstack/localstack#4921.\n Pulling the image With the multi-arch Docker manifest, your Docker client (and therefore the LocalStack CLI) now automatically selects the image according to your platform: $ docker pull localstack/localstack\nYou can check the architecture of the pulled image by using docker inspect: $ docker inspect localstack/localstack | jq '.[0].Architecture' \"arm64\"\nUsing AMD64 Lambda functions and binaries on ARM64 If you want to execute Docker Lambda functions or binaries which have not been built for your architecture, you need to configure cross-platform emulation on your system.\nYou can do so by installing a AMD64 bin_fmt emulator on your ARM64 host system with the following command:\nAffects host system The following command installs additionals emulators on your host system.  $ docker run --privileged --rm tonistiigi/binfmt --install amd64 You can check the current status with: $ docker run --privileged --rm tonistiigi/binfmt { \"supported\": [ \"linux/amd64\", \"linux/arm64\", \"linux/386\" ],  \"emulators\": [ \"jar\", \"llvm-12-runtime.binfmt\", \"python3.10\", \"python3.9\", \"qemu-aarch64\" ] }\nTroubleshooting Pulling images for other architectures  Unsupported Please be aware that this workaround is not supported by LocalStack at all.  If you want to use a LocalStack image which has been built for another architecture than yours, you can instruct Docker to use another platform by setting the DOCKER_DEFAULT_PLATFORM environment variable: $ export DOCKER_DEFAULT_PLATFORM=linux/amd64 When using Docker Compose, you can use the platform element as described in the specification.\nApple Silicon / Apple M1 If you are experiencing issues with the ARM64 image (and after you created an issue to make us aware of the problem üòâ), you can try to use the AMD64 packages on your Apple Silicon device and use Apple Rosetta to emulate the AMD64 / x86_64 CPU architecture.\nUnsupported Please be aware that this workaround is not supported by LocalStack at all.  First, you should enable ‚ÄúRosetta‚Äù on your preferred terminal. This way you‚Äôll be installing packages for x86_64 platform.\nWhat we will be doing now is installing Java and Python executables using Homebrew, it should automatically resolve packages to proper architecture versions.\n# Install Homebrew /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" # Install java11 and follow instructions brew install java11 # Install jenv and follow instructions brew install jenv # Add Java11 to jenv and use it globally jenv add /Library/Java/JavaVirtualMachines/openjdk-11.jdk/Contents/Home/ jenv global 11 # Install pyenv and follow instructions brew install pyenv # Install python 3.8.10 and enable it globally pyenv install 3.8.10 pyenv global 3.8.10 Then clone LocalStack to your machine, run make install and then make start.\nNote on JVM Lambda You need to use the local lambda executor for JVM Lambda functions.  Raspberry Pi If you want to run LocalStack on your Raspberry Pi, make sure to use a 64bit operating system. In our experience, it works best on a Raspberry Pi 4 8GB with Ubuntu Server 20.04 64Bit for Raspberry Pi.\nYou can check if Docker is running and your architecture is ARM64 / aarch64 by using docker info: $ docker info Client: ... Server: ... Operating System: Ubuntu 20.04 OSType: linux Architecture: aarch64  ...\n","categories":"","description":"Describes the support for the ARM64 CPU architecture in LocalStack.\n","excerpt":"Describes the support for the ARM64 CPU architecture in LocalStack.\n","ref":"/localstack/arm64-support/","tags":["apple","silicon","m1","raspberry pi"],"title":"ARM64 Support"},{"body":"","categories":"","description":"","excerpt":"","ref":"/aws/","tags":"","title":"Local AWS Services"},{"body":"Overview By default, the LocalStack CLI starts the LocalStack runtime inside a Docker container. Docker may not be available on your system, and a popular alternative is Podman which you can use to run LocalStack. Podman support is still experimental, and the following docs give you an overview of the current state.\nFrom the Podman docs:\n Podman is a daemonless, open source, Linux native tool designed to make it easy to find, run, build, share and deploy applications using Open Containers Initiative (OCI) Containers and Container Images. Podman provides a command line interface (CLI) familiar to anyone who has used the Docker Container Engine. Most users can simply alias Docker to Podman (alias docker=podman) without any problems.\n Options To run localstack, simply aliasing alias docker=podman is not enough, for the following reasons:\n localstack is using docker-py which requires a connection to /var/run/docker.sock LAMBDA_EXECUTOR=docker requires mounting /var/run/docker.sock into the container  Here are several options on running LocalStack using podman:\npodman-docker The package podman-docker emulates the Docker CLI using podman. It creates the following links:\n /usr/bin/docker -\u003e /usr/bin/podman /var/run/docker.sock -\u003e /run/podman/podman.sock  This package is available for some distros:\n https://archlinux.org/packages/community/x86_64/podman-docker/ https://packages.ubuntu.com/impish/podman-docker https://packages.debian.org/sid/podman-docker  Rootfull Podman with podman-docker The simplest option is to run localstack using podman by having podman-docker and running localstack start as root\n# you have to start the podman socket first sudo systemctl start podman # then sudo sh -c 'DEBUG=1 localstack start' Rootfull Podman without podman-docker # you still have to start the podman socket first sudo systemctl start podman # you have to pass a bunch of env variables sudo sh -c 'DEBUG=1 DOCKER_CMD=podman DOCKER_HOST=unix://run/podman/podman.sock DOCKER_SOCK=/run/podman/podman.sock localstack start' Rootless Podman You have to prepare your environment first:\n https://wiki.archlinux.org/title/Podman#Rootless_Podman https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md https://www.redhat.com/sysadmin/rootless-podman  # again, you have to start the podman socket first systemctl --user start podman.service # and then localstack DEBUG=1 DOCKER_CMD=\"podman\" DOCKER_SOCK=$XDG_RUNTIME_DIR/podman/podman.sock DOCKER_HOST=unix://$XDG_RUNTIME_DIR/podman/podman.sock localstack start If you have problems with subuid and subgid, you could try to use overlay.ignore_chown_errors option\nDEBUG=1 DOCKER_CMD=\"podman --storage-opt overlay.ignore_chown_errors=true\" DOCKER_SOCK=$XDG_RUNTIME_DIR/podman/podman.sock DOCKER_HOST=unix://$XDG_RUNTIME_DIR/podman/podman.sock localstack start ","categories":"","description":"Describes how to run LocalStack inside Podman.\n","excerpt":"Describes how to run LocalStack inside Podman.\n","ref":"/localstack/podman/","tags":["podman","docker"],"title":"Podman"},{"body":"The core of LocalStack is the cloud service emulation. But LocalStack also provides a variety of tools to make your life as a cloud developer easier.\nWith LocalStack Cloud Developer Tools you can:\n persist the state of the AWS services running in your LocalStack instance via Cloud Pods hot-swap your Lambda code changes instantly debug Lambda executions directly from your IDE inject LocalStack service endpoints automatically into your application ‚Ä¶ and much more!  ","categories":"","description":"Increase your development efficiency with LocalStack Cloud Developer Tools.\n","excerpt":"Increase your development efficiency with LocalStack Cloud Developer ‚Ä¶","ref":"/tools/","tags":"","title":"LocalStack Tools"},{"body":"This page describes known limitations of LocalStack and its services, either due to missing implementations or due to third-party integrations.\nImplementation Limitations Limitations that exist due to missing features in LocalStack.\nDynamoDB At the moment only a locally launched LocalStack instance can properly run the DynamoDB service.\nLambda Functions Only the local executor with locally launched LocalStack can be used together with JVM Lambda Functions.\nIntegration Limitations Limitations that may occur because of third party integrations behavior.\nCDK Stacks with validated certificates By default, stacks with validated certificates may not be deployed using the local lambda executor. This originates from the way how CDK ensures the certificate is ready - it creates a single-file lambda function with a single dependency on aws-sdk which is usually preinstalled and available globally in lambda runtime. When this lambda is executed locally from the /tmp folder, the package can not be discovered by Node due to the way how Node package resolution works.\nDNS Rebind Protection For certain LocalStack features it is necessary that the DNS resolves to the local network. For example, LocalStack is using virtual-host based addressing for S3, ElasticSearch, and OpenSearch by default. S3 buckets can be reached via \u003cbucket-name\u003e.s3.\u003cregion\u003e.localhost.localstack.cloud and OpenSearch clusters which are created by LocalStack can be reached via \u003cdomain-name\u003e.\u003cregion\u003e.opensearch.localhost.localstack.cloud. This is handled correctly if you configured your system‚Äôs DNS for the transparent execution mode of LocalStack Pro.\nHowever, if you rely on your local network‚Äôs DNS, your router / DNS server might block those requests due to the DNS Rebind Protection. This feature is enabled by default in pfSense, OPNSense, OpenWRT, AVM FritzBox, and potentially also other devices. Some of the vendors might allow upstream responses in the 127.0.0.0/8 range (like OpenWRT).\nYou can check if your DNS setup works correctly by resolving a subdomain of localhost.localstack.cloud: $ dig test.localhost.localstack.cloud ; \u003c\u003c\u003e\u003e DiG 9.16.8-Ubuntu \u003c\u003c\u003e\u003e test.localhost.localstack.cloud ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 45150 ;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 65494 ;; QUESTION SECTION: ;test.localhost.localstack.cloud. IN\tA ;; ANSWER SECTION: test.localhost.localstack.cloud. 10786 IN CNAME\tlocalhost.localstack.cloud. localhost.localstack.cloud. 389\tIN\tA\t127.0.0.1  ;; Query time: 16 msec ;; SERVER: 127.0.0.53#53(127.0.0.53) ;; WHEN: Fr J√§n 14 11:23:12 CET 2022 ;; MSG SIZE rcvd: 90 If the the DNS resolves the subdomain to your localhost (127.0.0.1), your setup is working. If not, please check the configuration of your router / DNS if the Rebind Protection is active or enable the LocalStack DNS on your system.\n","categories":"","description":"Known limitations of LocalStack and its services\n","excerpt":"Known limitations of LocalStack and its services\n","ref":"/localstack/limitations/","tags":"","title":"LocalStack Limitations"},{"body":"The documents in this section are dedicated to the internals, the configuration options, and the limitations of LocalStack.\nThe following figure shows an overview of the covered topics:\n  ","categories":"","description":"Learn how LocalStack emulates services and runs your serverless applications.\n","excerpt":"Learn how LocalStack emulates services and runs your serverless ‚Ä¶","ref":"/localstack/","tags":"","title":"Understanding LocalStack"},{"body":"We welcome contributions to LocalStack, under the Contributor LicenseAgreement (CLA).\nThe guides in this section are for developers of LocalStack, to better understand how LocalStack works internally, how to set up local development environments, and how to contribute to the codebase.\n","categories":"","description":"A guide to the LocalStack system, its code base on how to contribute to the project.\n","excerpt":"A guide to the LocalStack system, its code base on how to contribute ‚Ä¶","ref":"/developer-guide/","tags":"","title":"Developer Guide"},{"body":"acm    Operation Implemented     AddTagsToCertificate ‚úÖ   DeleteCertificate ‚ú® ‚úÖ   DescribeCertificate ‚ú® ‚úÖ   ExportCertificate ‚úÖ   GetCertificate ‚úÖ   ImportCertificate ‚ú® ‚úÖ   ListCertificates ‚ú® ‚úÖ   ListTagsForCertificate ‚ú® ‚úÖ   RemoveTagsFromCertificate ‚úÖ   RequestCertificate ‚ú® ‚úÖ   ResendValidationEmail ‚úÖ     Show missing     GetAccountConfiguration -   PutAccountConfiguration -   RenewCertificate -   UpdateCertificateOptions -    amplify    Operation Implemented     CreateApp (Pro) ‚ú® ‚úÖ   CreateBackendEnvironment (Pro) ‚ú® ‚úÖ   CreateBranch (Pro) ‚ú® ‚úÖ   CreateWebhook (Pro) ‚ú® ‚úÖ   DeleteApp (Pro) ‚ú® ‚úÖ   DeleteBackendEnvironment (Pro) ‚ú® ‚úÖ   DeleteBranch (Pro) ‚ú® ‚úÖ   DeleteWebhook (Pro) ‚ú® ‚úÖ   GetApp (Pro) ‚ú® ‚úÖ   GetBackendEnvironment (Pro) ‚ú® ‚úÖ   GetBranch (Pro) ‚ú® ‚úÖ   GetWebhook (Pro) ‚ú® ‚úÖ   ListBranches (Pro) ‚ú® ‚úÖ   UpdateApp (Pro) ‚ú® ‚úÖ   UpdateWebhook (Pro) ‚ú® ‚úÖ     Show missing     CreateDeployment -   CreateDomainAssociation -   DeleteDomainAssociation -   DeleteJob -   GenerateAccessLogs -   GetArtifactUrl -   GetDomainAssociation -   GetJob -   ListApps -   ListArtifacts -   ListBackendEnvironments -   ListDomainAssociations -   ListJobs -   ListTagsForResource -   ListWebhooks -   StartDeployment -   StartJob -   StopJob -   TagResource -   UntagResource -   UpdateBranch -   UpdateDomainAssociation -    apigateway    Operation Implemented     CreateApiKey ‚ú® ‚úÖ   CreateAuthorizer ‚ú® ‚úÖ   CreateBasePathMapping ‚ú® ‚úÖ   CreateDeployment ‚ú® ‚úÖ   CreateDocumentationPart ‚úÖ   CreateDomainName ‚ú® ‚úÖ   CreateModel ‚ú® ‚úÖ   CreateRequestValidator ‚ú® ‚úÖ   CreateResource ‚ú® ‚úÖ   CreateStage ‚ú® ‚úÖ   CreateUsagePlan ‚ú® ‚úÖ   CreateUsagePlanKey ‚ú® ‚úÖ   CreateVpcLink ‚úÖ   DeleteAuthorizer ‚ú® ‚úÖ   DeleteBasePathMapping ‚ú® ‚úÖ   DeleteClientCertificate ‚úÖ   DeleteDeployment ‚úÖ   DeleteDomainName ‚ú® ‚úÖ   DeleteGatewayResponse ‚úÖ   DeleteIntegration ‚ú® ‚úÖ   DeleteIntegrationResponse ‚ú® ‚úÖ   DeleteMethod ‚ú® ‚úÖ   DeleteMethodResponse ‚ú® ‚úÖ   DeleteModel ‚úÖ   DeleteRequestValidator ‚ú® ‚úÖ   DeleteResource ‚ú® ‚úÖ   DeleteRestApi ‚ú® ‚úÖ   DeleteStage ‚ú® ‚úÖ   DeleteVpcLink ‚úÖ   GenerateClientCertificate ‚úÖ   GetAccount ‚ú® ‚úÖ   GetApiKey ‚úÖ   GetApiKeys ‚ú® ‚úÖ   GetAuthorizer ‚ú® ‚úÖ   GetAuthorizers ‚ú® ‚úÖ   GetBasePathMapping ‚ú® ‚úÖ   GetBasePathMappings ‚ú® ‚úÖ   GetClientCertificate ‚úÖ   GetClientCertificates ‚úÖ   GetDeployment ‚ú® ‚úÖ   GetDeployments ‚ú® ‚úÖ   GetDocumentationPart ‚úÖ   GetDocumentationParts ‚úÖ   GetDomainName ‚ú® ‚úÖ   GetDomainNames ‚ú® ‚úÖ   GetGatewayResponse ‚úÖ   GetGatewayResponses ‚úÖ   GetIntegration ‚ú® ‚úÖ   GetIntegrationResponse ‚ú® ‚úÖ   GetMethod ‚ú® ‚úÖ   GetMethodResponse ‚ú® ‚úÖ   GetModel ‚ú® ‚úÖ   GetModels ‚ú® ‚úÖ   GetRequestValidator ‚ú® ‚úÖ   GetRequestValidators ‚ú® ‚úÖ   GetResource ‚ú® ‚úÖ   GetResources ‚ú® ‚úÖ   GetRestApi ‚ú® ‚úÖ   GetStage ‚ú® ‚úÖ   GetStages ‚úÖ   GetTags ‚ú® ‚úÖ   GetUsagePlan ‚úÖ   GetUsagePlanKey ‚úÖ   GetUsagePlanKeys ‚ú® ‚úÖ   GetUsagePlans ‚ú® ‚úÖ   GetVpcLink ‚úÖ   GetVpcLinks ‚úÖ   PutGatewayResponse ‚úÖ   PutIntegration ‚ú® ‚úÖ   PutIntegrationResponse ‚ú® ‚úÖ   PutMethod ‚ú® ‚úÖ   PutMethodResponse ‚ú® ‚úÖ   PutRestApi ‚ú® ‚úÖ   TagResource ‚ú® ‚úÖ   UntagResource ‚úÖ   UpdateAccount ‚ú® ‚úÖ   UpdateAuthorizer ‚ú® ‚úÖ   UpdateBasePathMapping ‚ú® ‚úÖ   UpdateClientCertificate ‚úÖ   UpdateDocumentationPart ‚úÖ   UpdateDomainName ‚úÖ   UpdateIntegration ‚úÖ   UpdateMethod ‚ú® ‚úÖ   UpdateMethodResponse ‚úÖ   UpdateModel ‚úÖ   UpdateRequestValidator ‚ú® ‚úÖ   UpdateResource ‚ú® ‚úÖ   UpdateRestApi ‚ú® ‚úÖ   UpdateStage ‚úÖ   UpdateUsagePlan ‚úÖ   UpdateVpcLink ‚úÖ     Show missing     CreateDocumentationVersion -   CreateRestApi -   DeleteApiKey -   DeleteDocumentationPart -   DeleteDocumentationVersion -   DeleteUsagePlan -   DeleteUsagePlanKey -   FlushStageAuthorizersCache -   FlushStageCache -   GetDocumentationVersion -   GetDocumentationVersions -   GetExport -   GetModelTemplate -   GetRestApis -   GetSdk -   GetSdkType -   GetSdkTypes -   GetUsage -   ImportApiKeys -   ImportDocumentationParts -   ImportRestApi -   TestInvokeAuthorizer -   TestInvokeMethod -   UpdateApiKey -   UpdateDeployment -   UpdateDocumentationVersion -   UpdateGatewayResponse -   UpdateIntegrationResponse -   UpdateUsage -    apigatewaymanagementapi    Operation Implemented     DeleteConnection (Pro)  ‚úÖ   GetConnection (Pro)  ‚úÖ   PostToConnection (Pro) ‚ú® ‚úÖ    apigatewayv2    Operation Implemented     CreateApi (Pro) ‚ú® ‚úÖ   CreateApiMapping (Pro) ‚ú® ‚úÖ   CreateAuthorizer (Pro) ‚ú® ‚úÖ   CreateDeployment (Pro) ‚ú® ‚úÖ   CreateDomainName (Pro) ‚ú® ‚úÖ   CreateIntegration (Pro) ‚ú® ‚úÖ   CreateIntegrationResponse (Pro) ‚ú® ‚úÖ   CreateModel (Pro) ‚ú® ‚úÖ   CreateRoute (Pro) ‚ú® ‚úÖ   CreateRouteResponse (Pro) ‚ú® ‚úÖ   CreateStage (Pro) ‚ú® ‚úÖ   CreateVpcLink (Pro) ‚ú® ‚úÖ   DeleteApi (Pro) ‚ú® ‚úÖ   DeleteApiMapping (Pro)  ‚úÖ   DeleteAuthorizer (Pro) ‚ú® ‚úÖ   DeleteCorsConfiguration (Pro)  ‚úÖ   DeleteDeployment (Pro) ‚ú® ‚úÖ   DeleteDomainName (Pro) ‚ú® ‚úÖ   DeleteIntegration (Pro) ‚ú® ‚úÖ   DeleteIntegrationResponse (Pro) ‚ú® ‚úÖ   DeleteModel (Pro)  ‚úÖ   DeleteRoute (Pro) ‚ú® ‚úÖ   DeleteRouteResponse (Pro) ‚ú® ‚úÖ   DeleteStage (Pro) ‚ú® ‚úÖ   DeleteVpcLink (Pro) ‚ú® ‚úÖ   GetApi (Pro) ‚ú® ‚úÖ   GetApiMapping (Pro)  ‚úÖ   GetApiMappings (Pro)  ‚úÖ   GetApis (Pro) ‚ú® ‚úÖ   GetAuthorizer (Pro) ‚ú® ‚úÖ   GetAuthorizers (Pro) ‚ú® ‚úÖ   GetDeployment (Pro) ‚ú® ‚úÖ   GetDeployments (Pro) ‚ú® ‚úÖ   GetDomainName (Pro) ‚ú® ‚úÖ   GetDomainNames (Pro) ‚ú® ‚úÖ   GetIntegration (Pro) ‚ú® ‚úÖ   GetIntegrationResponse (Pro) ‚ú® ‚úÖ   GetIntegrationResponses (Pro) ‚ú® ‚úÖ   GetIntegrations (Pro) ‚ú® ‚úÖ   GetModel (Pro)  ‚úÖ   GetModels (Pro) ‚ú® ‚úÖ   GetRoute (Pro) ‚ú® ‚úÖ   GetRouteResponse (Pro) ‚ú® ‚úÖ   GetRouteResponses (Pro) ‚ú® ‚úÖ   GetRoutes (Pro) ‚ú® ‚úÖ   GetStage (Pro) ‚ú® ‚úÖ   GetStages (Pro)  ‚úÖ   GetVpcLink (Pro)  ‚úÖ   GetVpcLinks (Pro) ‚ú® ‚úÖ   UpdateApi (Pro)  ‚úÖ   UpdateApiMapping (Pro)  ‚úÖ   UpdateAuthorizer (Pro)  ‚úÖ   UpdateDeployment (Pro)  ‚úÖ   UpdateDomainName (Pro)  ‚úÖ   UpdateIntegration (Pro) ‚ú® ‚úÖ   UpdateIntegrationResponse (Pro) ‚ú® ‚úÖ   UpdateModel (Pro)  ‚úÖ   UpdateRoute (Pro) ‚ú® ‚úÖ   UpdateRouteResponse (Pro) ‚ú® ‚úÖ   UpdateStage (Pro) ‚ú® ‚úÖ   UpdateVpcLink (Pro)  ‚úÖ     Show missing     DeleteAccessLogSettings -   DeleteRouteRequestParameter -   DeleteRouteSettings -   ExportApi -   GetModelTemplate -   GetTags -   ImportApi -   ReimportApi -   ResetAuthorizersCache -   TagResource -   UntagResource -    appconfig    Operation Implemented     CreateApplication (Pro) ‚ú® ‚úÖ   CreateConfigurationProfile (Pro) ‚ú® ‚úÖ   CreateDeploymentStrategy (Pro) ‚ú® ‚úÖ   CreateEnvironment (Pro) ‚ú® ‚úÖ   CreateHostedConfigurationVersion (Pro) ‚ú® ‚úÖ   DeleteApplication (Pro) ‚ú® ‚úÖ   DeleteConfigurationProfile (Pro) ‚ú® ‚úÖ   DeleteDeploymentStrategy (Pro) ‚ú® ‚úÖ   DeleteEnvironment (Pro) ‚ú® ‚úÖ   DeleteHostedConfigurationVersion (Pro) ‚ú® ‚úÖ   GetApplication (Pro) ‚ú® ‚úÖ   GetConfiguration (Pro) ‚ú® ‚úÖ   GetConfigurationProfile (Pro) ‚ú® ‚úÖ   GetDeployment (Pro)  ‚úÖ   GetDeploymentStrategy (Pro) ‚ú® ‚úÖ   GetEnvironment (Pro) ‚ú® ‚úÖ   GetHostedConfigurationVersion (Pro) ‚ú® ‚úÖ   ListApplications (Pro) ‚ú® ‚úÖ   ListConfigurationProfiles (Pro) ‚ú® ‚úÖ   ListDeploymentStrategies (Pro) ‚ú® ‚úÖ   ListDeployments (Pro) ‚ú® ‚úÖ   ListEnvironments (Pro) ‚ú® ‚úÖ   ListHostedConfigurationVersions (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro)  ‚úÖ   StartDeployment (Pro) ‚ú® ‚úÖ   StopDeployment (Pro)  ‚úÖ   TagResource (Pro)  ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateApplication (Pro) ‚ú® ‚úÖ   UpdateConfigurationProfile (Pro) ‚ú® ‚úÖ   UpdateDeploymentStrategy (Pro) ‚ú® ‚úÖ   UpdateEnvironment (Pro) ‚ú® ‚úÖ   ValidateConfiguration (Pro) ‚ú® ‚úÖ    application-autoscaling    Operation Implemented     DeleteScalingPolicy (Pro) ‚ú® ‚úÖ   DeleteScheduledAction (Pro)  ‚úÖ   DeregisterScalableTarget (Pro) ‚ú® ‚úÖ   DescribeScalableTargets (Pro) ‚ú® ‚úÖ   DescribeScalingPolicies (Pro) ‚ú® ‚úÖ   DescribeScheduledActions (Pro)  ‚úÖ   PutScalingPolicy (Pro) ‚ú® ‚úÖ   PutScheduledAction (Pro)  ‚úÖ   RegisterScalableTarget (Pro) ‚ú® ‚úÖ     Show missing     DescribeScalingActivities -    appsync    Operation Implemented     CreateApiCache (Pro) ‚ú® ‚úÖ   CreateApiKey (Pro) ‚ú® ‚úÖ   CreateDataSource (Pro) ‚ú® ‚úÖ   CreateDomainName (Pro)  ‚úÖ   CreateFunction (Pro) ‚ú® ‚úÖ   CreateGraphqlApi (Pro) ‚ú® ‚úÖ   CreateResolver (Pro) ‚ú® ‚úÖ   CreateType (Pro)  ‚úÖ   DeleteApiCache (Pro)  ‚úÖ   DeleteApiKey (Pro)  ‚úÖ   DeleteDataSource (Pro)  ‚úÖ   DeleteDomainName (Pro)  ‚úÖ   DeleteFunction (Pro)  ‚úÖ   DeleteGraphqlApi (Pro) ‚ú® ‚úÖ   DeleteResolver (Pro) ‚ú® ‚úÖ   DeleteType (Pro)  ‚úÖ   FlushApiCache (Pro)  ‚úÖ   GetApiCache (Pro)  ‚úÖ   GetDataSource (Pro)  ‚úÖ   GetDomainName (Pro)  ‚úÖ   GetFunction (Pro) ‚ú® ‚úÖ   GetGraphqlApi (Pro) ‚ú® ‚úÖ   GetIntrospectionSchema (Pro) ‚ú® ‚úÖ   GetResolver (Pro) ‚ú® ‚úÖ   GetSchemaCreationStatus (Pro) ‚ú® ‚úÖ   GetType (Pro)  ‚úÖ   ListApiKeys (Pro) ‚ú® ‚úÖ   ListDataSources (Pro) ‚ú® ‚úÖ   ListDomainNames (Pro)  ‚úÖ   ListFunctions (Pro) ‚ú® ‚úÖ   ListGraphqlApis (Pro) ‚ú® ‚úÖ   ListResolvers (Pro) ‚ú® ‚úÖ   ListResolversByFunction (Pro)  ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   ListTypes (Pro)  ‚úÖ   StartSchemaCreation (Pro) ‚ú® ‚úÖ   TagResource (Pro) ‚ú® ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateApiCache (Pro) ‚ú® ‚úÖ   UpdateApiKey (Pro) ‚ú® ‚úÖ   UpdateDataSource (Pro)  ‚úÖ   UpdateDomainName (Pro)  ‚úÖ   UpdateFunction (Pro)  ‚úÖ   UpdateGraphqlApi (Pro)  ‚úÖ   UpdateResolver (Pro) ‚ú® ‚úÖ   UpdateType (Pro)  ‚úÖ     Show missing     AssociateApi -   DisassociateApi -   GetApiAssociation -    athena    Operation Implemented     CreateDataCatalog (Pro) ‚ú® ‚úÖ   CreateNamedQuery (Pro) ‚ú® ‚úÖ   CreateWorkGroup (Pro) ‚ú® ‚úÖ   DeleteDataCatalog (Pro) ‚ú® ‚úÖ   DeleteNamedQuery (Pro) ‚ú® ‚úÖ   DeleteWorkGroup (Pro) ‚ú® ‚úÖ   GetDataCatalog (Pro) ‚ú® ‚úÖ   GetDatabase (Pro)  ‚úÖ   GetNamedQuery (Pro)  ‚úÖ   GetQueryExecution (Pro)  ‚úÖ   GetQueryResults (Pro)  ‚úÖ   GetWorkGroup (Pro) ‚ú® ‚úÖ   ListDataCatalogs (Pro) ‚ú® ‚úÖ   ListDatabases (Pro)  ‚úÖ   ListNamedQueries (Pro) ‚ú® ‚úÖ   ListQueryExecutions (Pro)  ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   ListWorkGroups (Pro) ‚ú® ‚úÖ   StartQueryExecution (Pro)  ‚úÖ   TagResource (Pro) ‚ú® ‚úÖ   UntagResource (Pro) ‚ú® ‚úÖ     Show missing     BatchGetNamedQuery -   BatchGetPreparedStatement -   BatchGetQueryExecution -   CreatePreparedStatement -   DeletePreparedStatement -   GetPreparedStatement -   GetTableMetadata -   ListEngineVersions -   ListPreparedStatements -   ListTableMetadata -   StopQueryExecution -   UpdateDataCatalog -   UpdateNamedQuery -   UpdatePreparedStatement -   UpdateWorkGroup -    autoscaling    Operation Implemented     CreateAutoScalingGroup (Pro)  ‚úÖ   CreateLaunchConfiguration (Pro)  ‚úÖ   DeleteLaunchConfiguration (Pro)  ‚úÖ   DeleteLifecycleHook (Pro)  ‚úÖ   DeletePolicy (Pro)  ‚úÖ   DescribeAutoScalingInstances (Pro)  ‚úÖ   DescribeLifecycleHooks (Pro)  ‚úÖ   DescribeMetricCollectionTypes (Pro) ‚ú® ‚úÖ   DescribePolicies (Pro)  ‚úÖ   DescribeTags (Pro)  ‚úÖ   DisableMetricsCollection (Pro) ‚ú® ‚úÖ   EnableMetricsCollection (Pro) ‚ú® ‚úÖ   PutLifecycleHook (Pro)  ‚úÖ   PutScalingPolicy (Pro)  ‚úÖ   TerminateInstanceInAutoScalingGroup (Pro)  ‚úÖ   UpdateAutoScalingGroup (Pro)  ‚úÖ     Show missing     AttachInstances -   AttachLoadBalancerTargetGroups -   AttachLoadBalancers -   BatchDeleteScheduledAction -   BatchPutScheduledUpdateGroupAction -   CancelInstanceRefresh -   CompleteLifecycleAction -   CreateOrUpdateTags -   DeleteAutoScalingGroup -   DeleteNotificationConfiguration -   DeleteScheduledAction -   DeleteTags -   DeleteWarmPool -   DescribeAccountLimits -   DescribeAdjustmentTypes -   DescribeAutoScalingGroups -   DescribeAutoScalingNotificationTypes -   DescribeInstanceRefreshes -   DescribeLaunchConfigurations -   DescribeLifecycleHookTypes -   DescribeLoadBalancerTargetGroups -   DescribeLoadBalancers -   DescribeNotificationConfigurations -   DescribeScalingActivities -   DescribeScalingProcessTypes -   DescribeScheduledActions -   DescribeTerminationPolicyTypes -   DescribeWarmPool -   DetachInstances -   DetachLoadBalancerTargetGroups -   DetachLoadBalancers -   EnterStandby -   ExecutePolicy -   ExitStandby -   GetPredictiveScalingForecast -   PutNotificationConfiguration -   PutScheduledUpdateGroupAction -   PutWarmPool -   RecordLifecycleActionHeartbeat -   ResumeProcesses -   SetDesiredCapacity -   SetInstanceHealth -   SetInstanceProtection -   StartInstanceRefresh -   SuspendProcesses -    backup    Operation Implemented     CreateBackupPlan (Pro) ‚ú® ‚úÖ   CreateBackupSelection (Pro) ‚ú® ‚úÖ   CreateBackupVault (Pro) ‚ú® ‚úÖ   DeleteBackupPlan (Pro) ‚ú® ‚úÖ   DeleteBackupSelection (Pro) ‚ú® ‚úÖ   DeleteBackupVault (Pro) ‚ú® ‚úÖ   DescribeBackupVault (Pro) ‚ú® ‚úÖ   DescribeRestoreJob (Pro) ‚ú® ‚úÖ   GetBackupPlan (Pro) ‚ú® ‚úÖ   GetBackupSelection (Pro) ‚ú® ‚úÖ   ListBackupPlans (Pro) ‚ú® ‚úÖ   ListBackupSelections (Pro) ‚ú® ‚úÖ   ListBackupVaults (Pro) ‚ú® ‚úÖ   ListRecoveryPointsByResource (Pro) ‚ú® ‚úÖ   StartRestoreJob (Pro) ‚ú® ‚úÖ   UpdateBackupPlan (Pro) ‚ú® ‚úÖ     Show missing     CreateFramework -   CreateReportPlan -   DeleteBackupVaultAccessPolicy -   DeleteBackupVaultLockConfiguration -   DeleteBackupVaultNotifications -   DeleteFramework -   DeleteRecoveryPoint -   DeleteReportPlan -   DescribeBackupJob -   DescribeCopyJob -   DescribeFramework -   DescribeGlobalSettings -   DescribeProtectedResource -   DescribeRecoveryPoint -   DescribeRegionSettings -   DescribeReportJob -   DescribeReportPlan -   DisassociateRecoveryPoint -   ExportBackupPlanTemplate -   GetBackupPlanFromJSON -   GetBackupPlanFromTemplate -   GetBackupVaultAccessPolicy -   GetBackupVaultNotifications -   GetRecoveryPointRestoreMetadata -   GetSupportedResourceTypes -   ListBackupJobs -   ListBackupPlanTemplates -   ListBackupPlanVersions -   ListCopyJobs -   ListFrameworks -   ListProtectedResources -   ListRecoveryPointsByBackupVault -   ListReportJobs -   ListReportPlans -   ListRestoreJobs -   ListTags -   PutBackupVaultAccessPolicy -   PutBackupVaultLockConfiguration -   PutBackupVaultNotifications -   StartBackupJob -   StartCopyJob -   StartReportJob -   StopBackupJob -   TagResource -   UntagResource -   UpdateFramework -   UpdateGlobalSettings -   UpdateRecoveryPointLifecycle -   UpdateRegionSettings -   UpdateReportPlan -    batch    Operation Implemented     CreateComputeEnvironment (Pro) ‚ú® ‚úÖ   CreateJobQueue (Pro) ‚ú® ‚úÖ   DeleteComputeEnvironment (Pro)  ‚úÖ   DeleteJobQueue (Pro) ‚ú® ‚úÖ   DeregisterJobDefinition (Pro) ‚ú® ‚úÖ   DescribeComputeEnvironments (Pro)  ‚úÖ   DescribeJobDefinitions (Pro) ‚ú® ‚úÖ   DescribeJobQueues (Pro)  ‚úÖ   DescribeJobs (Pro) ‚ú® ‚úÖ   ListJobs (Pro)  ‚úÖ   ListTagsForResource (Pro)  ‚úÖ   RegisterJobDefinition (Pro) ‚ú® ‚úÖ   SubmitJob (Pro) ‚ú® ‚úÖ   TagResource (Pro)  ‚úÖ   TerminateJob (Pro)  ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateComputeEnvironment (Pro)  ‚úÖ   UpdateJobQueue (Pro)  ‚úÖ     Show missing     CancelJob -   CreateSchedulingPolicy -   DeleteSchedulingPolicy -   DescribeSchedulingPolicies -   ListSchedulingPolicies -   UpdateSchedulingPolicy -    ce    Operation Implemented     DeleteAnomalyMonitor (Pro) ‚ú® ‚úÖ   DeleteAnomalySubscription (Pro) ‚ú® ‚úÖ   DeleteCostCategoryDefinition (Pro) ‚ú® ‚úÖ   DescribeCostCategoryDefinition (Pro) ‚ú® ‚úÖ   GetAnomalyMonitors (Pro) ‚ú® ‚úÖ   GetAnomalySubscriptions (Pro) ‚ú® ‚úÖ   UpdateAnomalyMonitor (Pro) ‚ú® ‚úÖ   UpdateAnomalySubscription (Pro) ‚ú® ‚úÖ   UpdateCostCategoryDefinition (Pro) ‚ú® ‚úÖ     Show missing     CreateAnomalyMonitor -   CreateAnomalySubscription -   CreateCostCategoryDefinition -   GetAnomalies -   GetCostAndUsage -   GetCostAndUsageWithResources -   GetCostCategories -   GetCostForecast -   GetDimensionValues -   GetReservationCoverage -   GetReservationPurchaseRecommendation -   GetReservationUtilization -   GetRightsizingRecommendation -   GetSavingsPlansCoverage -   GetSavingsPlansPurchaseRecommendation -   GetSavingsPlansUtilization -   GetSavingsPlansUtilizationDetails -   GetTags -   GetUsageForecast -   ListCostAllocationTags -   ListCostCategoryDefinitions -   ListTagsForResource -   ProvideAnomalyFeedback -   TagResource -   UntagResource -   UpdateCostAllocationTagsStatus -    cloudformation    Operation Implemented     ActivateType ‚úÖ   BatchDescribeTypeConfigurations ‚úÖ   CreateChangeSet ‚ú® ‚úÖ   CreateStackInstances ‚úÖ   CreateStackSet ‚úÖ   DeleteChangeSet ‚ú® ‚úÖ   DeleteStack ‚ú® ‚úÖ   DeleteStackSet ‚úÖ   DescribeChangeSet ‚ú® ‚úÖ   DescribeStackEvents ‚ú® ‚úÖ   DescribeStackResource ‚ú® ‚úÖ   DescribeStackResources ‚ú® ‚úÖ   DescribeStackSet ‚úÖ   DescribeStackSetOperation ‚úÖ   DescribeStacks ‚ú® ‚úÖ   ExecuteChangeSet ‚ú® ‚úÖ   GetTemplate ‚ú® ‚úÖ   GetTemplateSummary ‚ú® ‚úÖ   ListChangeSets ‚úÖ   ListExports ‚ú® ‚úÖ   ListImports ‚úÖ   ListStackInstances ‚úÖ   ListStackResources ‚ú® ‚úÖ   ListStackSets ‚úÖ   ListStacks ‚ú® ‚úÖ   UpdateStack ‚ú® ‚úÖ   UpdateStackSet ‚úÖ   ValidateTemplate ‚ú® ‚úÖ     Show missing     CancelUpdateStack -   ContinueUpdateRollback -   CreateStack -   DeactivateType -   DeleteStackInstances -   DeregisterType -   DescribeAccountLimits -   DescribeChangeSetHooks -   DescribePublisher -   DescribeStackDriftDetectionStatus -   DescribeStackInstance -   DescribeStackResourceDrifts -   DescribeType -   DescribeTypeRegistration -   DetectStackDrift -   DetectStackResourceDrift -   DetectStackSetDrift -   EstimateTemplateCost -   GetStackPolicy -   ImportStacksToStackSet -   ListStackSetOperationResults -   ListStackSetOperations -   ListTypeRegistrations -   ListTypeVersions -   ListTypes -   PublishType -   RecordHandlerProgress -   RegisterPublisher -   RegisterType -   RollbackStack -   SetStackPolicy -   SetTypeConfiguration -   SetTypeDefaultVersion -   SignalResource -   StopStackSetOperation -   TestType -   UpdateStackInstances -   UpdateTerminationProtection -    cloudfront    Operation Implemented     CreateCloudFrontOriginAccessIdentity (Pro) ‚ú® ‚úÖ   CreateDistribution (Pro) ‚ú® ‚úÖ   CreateDistributionWithTags (Pro) ‚ú® ‚úÖ   CreateFunction (Pro) ‚ú® ‚úÖ   CreateInvalidation (Pro) ‚ú® ‚úÖ   CreateOriginRequestPolicy (Pro) ‚ú® ‚úÖ   DeleteCloudFrontOriginAccessIdentity (Pro) ‚ú® ‚úÖ   DeleteDistribution (Pro) ‚ú® ‚úÖ   DeleteFunction (Pro) ‚ú® ‚úÖ   DeleteOriginRequestPolicy (Pro) ‚ú® ‚úÖ   GetCloudFrontOriginAccessIdentity (Pro) ‚ú® ‚úÖ   GetDistribution (Pro)  ‚úÖ   GetFunction (Pro) ‚ú® ‚úÖ   GetInvalidation (Pro) ‚ú® ‚úÖ   GetOriginRequestPolicy (Pro) ‚ú® ‚úÖ   ListCloudFrontOriginAccessIdentities (Pro) ‚ú® ‚úÖ   ListDistributions (Pro) ‚ú® ‚úÖ   ListFunctions (Pro) ‚ú® ‚úÖ   ListInvalidations (Pro) ‚ú® ‚úÖ   ListOriginRequestPolicies (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   TagResource (Pro)  ‚úÖ   UpdateDistribution (Pro)  ‚úÖ   UpdateFunction (Pro) ‚ú® ‚úÖ   UpdateOriginRequestPolicy (Pro) ‚ú® ‚úÖ     Show missing     AssociateAlias -   CreateCachePolicy -   CreateFieldLevelEncryptionConfig -   CreateFieldLevelEncryptionProfile -   CreateKeyGroup -   CreateMonitoringSubscription -   CreatePublicKey -   CreateRealtimeLogConfig -   CreateResponseHeadersPolicy -   CreateStreamingDistribution -   CreateStreamingDistributionWithTags -   DeleteCachePolicy -   DeleteFieldLevelEncryptionConfig -   DeleteFieldLevelEncryptionProfile -   DeleteKeyGroup -   DeleteMonitoringSubscription -   DeletePublicKey -   DeleteRealtimeLogConfig -   DeleteResponseHeadersPolicy -   DeleteStreamingDistribution -   DescribeFunction -   GetCachePolicy -   GetCachePolicyConfig -   GetCloudFrontOriginAccessIdentityConfig -   GetDistributionConfig -   GetFieldLevelEncryption -   GetFieldLevelEncryptionConfig -   GetFieldLevelEncryptionProfile -   GetFieldLevelEncryptionProfileConfig -   GetKeyGroup -   GetKeyGroupConfig -   GetMonitoringSubscription -   GetOriginRequestPolicyConfig -   GetPublicKey -   GetPublicKeyConfig -   GetRealtimeLogConfig -   GetResponseHeadersPolicy -   GetResponseHeadersPolicyConfig -   GetStreamingDistribution -   GetStreamingDistributionConfig -   ListCachePolicies -   ListConflictingAliases -   ListDistributionsByCachePolicyId -   ListDistributionsByKeyGroup -   ListDistributionsByOriginRequestPolicyId -   ListDistributionsByRealtimeLogConfig -   ListDistributionsByResponseHeadersPolicyId -   ListDistributionsByWebACLId -   ListFieldLevelEncryptionConfigs -   ListFieldLevelEncryptionProfiles -   ListKeyGroups -   ListPublicKeys -   ListRealtimeLogConfigs -   ListResponseHeadersPolicies -   ListStreamingDistributions -   PublishFunction -   TestFunction -   UntagResource -   UpdateCachePolicy -   UpdateCloudFrontOriginAccessIdentity -   UpdateFieldLevelEncryptionConfig -   UpdateFieldLevelEncryptionProfile -   UpdateKeyGroup -   UpdatePublicKey -   UpdateRealtimeLogConfig -   UpdateResponseHeadersPolicy -   UpdateStreamingDistribution -    cloudtrail    Operation Implemented     AddTags (Pro)  ‚úÖ   CreateTrail (Pro) ‚ú® ‚úÖ   DeleteTrail (Pro) ‚ú® ‚úÖ   DescribeTrails (Pro) ‚ú® ‚úÖ   GetEventSelectors (Pro)  ‚úÖ   GetInsightSelectors (Pro)  ‚úÖ   GetTrail (Pro) ‚ú® ‚úÖ   GetTrailStatus (Pro) ‚ú® ‚úÖ   ListTags (Pro) ‚ú® ‚úÖ   ListTrails (Pro) ‚ú® ‚úÖ   LookupEvents (Pro) ‚ú® ‚úÖ   PutEventSelectors (Pro) ‚ú® ‚úÖ   PutInsightSelectors (Pro)  ‚úÖ   RemoveTags (Pro)  ‚úÖ   StartLogging (Pro) ‚ú® ‚úÖ   StopLogging (Pro) ‚ú® ‚úÖ   UpdateTrail (Pro) ‚ú® ‚úÖ     Show missing     CancelQuery -   CreateEventDataStore -   DeleteEventDataStore -   DescribeQuery -   GetEventDataStore -   GetQueryResults -   ListEventDataStores -   ListPublicKeys -   ListQueries -   RestoreEventDataStore -   StartQuery -   UpdateEventDataStore -    cloudwatch    Operation Implemented     DeleteAlarms ‚ú® ‚úÖ   DeleteDashboards ‚úÖ   DescribeAlarms ‚ú® ‚úÖ   DescribeAlarmsForMetric ‚úÖ   GetDashboard ‚úÖ   GetMetricData ‚ú® ‚úÖ   GetMetricStatistics ‚ú® ‚úÖ   ListDashboards ‚úÖ   ListMetrics ‚ú® ‚úÖ   ListTagsForResource ‚ú® ‚úÖ   PutCompositeAlarm ‚ú® ‚úÖ   PutDashboard ‚úÖ   PutMetricAlarm ‚ú® ‚úÖ   PutMetricData ‚ú® ‚úÖ   SetAlarmState ‚ú® ‚úÖ   TagResource ‚ú® ‚úÖ   UntagResource ‚ú® ‚úÖ     Show missing     DeleteAnomalyDetector -   DeleteInsightRules -   DeleteMetricStream -   DescribeAlarmHistory -   DescribeAnomalyDetectors -   DescribeInsightRules -   DisableAlarmActions -   DisableInsightRules -   EnableAlarmActions -   EnableInsightRules -   GetInsightRuleReport -   GetMetricStream -   GetMetricWidgetImage -   ListMetricStreams -   PutAnomalyDetector -   PutInsightRule -   PutMetricStream -   StartMetricStreams -   StopMetricStreams -    codecommit    Operation Implemented     CreateBranch (Pro) ‚ú® ‚úÖ   CreateCommit (Pro) ‚ú® ‚úÖ   CreatePullRequest (Pro) ‚ú® ‚úÖ   CreateRepository (Pro) ‚ú® ‚úÖ   DeleteBranch (Pro) ‚ú® ‚úÖ   DeleteRepository (Pro) ‚ú® ‚úÖ   GetBranch (Pro) ‚ú® ‚úÖ   GetFile (Pro) ‚ú® ‚úÖ   GetFolder (Pro) ‚ú® ‚úÖ   GetRepository (Pro) ‚ú® ‚úÖ   ListPullRequests (Pro) ‚ú® ‚úÖ   ListRepositories (Pro)  ‚úÖ   ListTagsForResource (Pro)  ‚úÖ   TagResource (Pro)  ‚úÖ     Show missing     AssociateApprovalRuleTemplateWithRepository -   BatchAssociateApprovalRuleTemplateWithRepositories -   BatchDescribeMergeConflicts -   BatchDisassociateApprovalRuleTemplateFromRepositories -   BatchGetCommits -   BatchGetRepositories -   CreateApprovalRuleTemplate -   CreatePullRequestApprovalRule -   CreateUnreferencedMergeCommit -   DeleteApprovalRuleTemplate -   DeleteCommentContent -   DeleteFile -   DeletePullRequestApprovalRule -   DescribeMergeConflicts -   DescribePullRequestEvents -   DisassociateApprovalRuleTemplateFromRepository -   EvaluatePullRequestApprovalRules -   GetApprovalRuleTemplate -   GetBlob -   GetComment -   GetCommentReactions -   GetCommentsForComparedCommit -   GetCommentsForPullRequest -   GetCommit -   GetDifferences -   GetMergeCommit -   GetMergeConflicts -   GetMergeOptions -   GetPullRequest -   GetPullRequestApprovalStates -   GetPullRequestOverrideState -   GetRepositoryTriggers -   ListApprovalRuleTemplates -   ListAssociatedApprovalRuleTemplatesForRepository -   ListBranches -   ListRepositoriesForApprovalRuleTemplate -   MergeBranchesByFastForward -   MergeBranchesBySquash -   MergeBranchesByThreeWay -   MergePullRequestByFastForward -   MergePullRequestBySquash -   MergePullRequestByThreeWay -   OverridePullRequestApprovalRules -   PostCommentForComparedCommit -   PostCommentForPullRequest -   PostCommentReply -   PutCommentReaction -   PutFile -   PutRepositoryTriggers -   TestRepositoryTriggers -   UntagResource -   UpdateApprovalRuleTemplateContent -   UpdateApprovalRuleTemplateDescription -   UpdateApprovalRuleTemplateName -   UpdateComment -   UpdateDefaultBranch -   UpdatePullRequestApprovalRuleContent -   UpdatePullRequestApprovalState -   UpdatePullRequestDescription -   UpdatePullRequestStatus -   UpdatePullRequestTitle -   UpdateRepositoryDescription -   UpdateRepositoryName -    cognito-identity    Operation Implemented     CreateIdentityPool (Pro) ‚ú® ‚úÖ   DeleteIdentityPool (Pro) ‚ú® ‚úÖ   DescribeIdentityPool (Pro)  ‚úÖ   GetCredentialsForIdentity (Pro) ‚ú® ‚úÖ   GetIdentityPoolRoles (Pro) ‚ú® ‚úÖ   GetOpenIdToken (Pro)  ‚úÖ   GetOpenIdTokenForDeveloperIdentity (Pro)  ‚úÖ   ListIdentityPools (Pro) ‚ú® ‚úÖ   SetIdentityPoolRoles (Pro) ‚ú® ‚úÖ     Show missing     DeleteIdentities -   DescribeIdentity -   GetId -   GetPrincipalTagAttributeMap -   ListIdentities -   ListTagsForResource -   LookupDeveloperIdentity -   MergeDeveloperIdentities -   SetPrincipalTagAttributeMap -   TagResource -   UnlinkDeveloperIdentity -   UnlinkIdentity -   UntagResource -   UpdateIdentityPool -    cognito-idp    Operation Implemented     AddCustomAttributes (Pro)  ‚úÖ   AdminDeleteUser (Pro) ‚ú® ‚úÖ   AdminDeleteUserAttributes (Pro) ‚ú® ‚úÖ   AdminDisableUser (Pro) ‚ú® ‚úÖ   AdminEnableUser (Pro)  ‚úÖ   AdminGetUser (Pro) ‚ú® ‚úÖ   AdminInitiateAuth (Pro) ‚ú® ‚úÖ   AdminResetUserPassword (Pro)  ‚úÖ   AdminSetUserMFAPreference (Pro) ‚ú® ‚úÖ   AdminSetUserPassword (Pro) ‚ú® ‚úÖ   AdminUpdateUserAttributes (Pro) ‚ú® ‚úÖ   AdminUserGlobalSignOut (Pro) ‚ú® ‚úÖ   ChangePassword (Pro) ‚ú® ‚úÖ   ConfirmDevice (Pro)  ‚úÖ   ConfirmForgotPassword (Pro) ‚ú® ‚úÖ   ConfirmSignUp (Pro)  ‚úÖ   CreateGroup (Pro) ‚ú® ‚úÖ   CreateIdentityProvider (Pro) ‚ú® ‚úÖ   CreateResourceServer (Pro) ‚ú® ‚úÖ   CreateUserPoolDomain (Pro)  ‚úÖ   DeleteGroup (Pro) ‚ú® ‚úÖ   DeleteIdentityProvider (Pro) ‚ú® ‚úÖ   DeleteResourceServer (Pro) ‚ú® ‚úÖ   DeleteUserAttributes (Pro) ‚ú® ‚úÖ   DeleteUserPool (Pro) ‚ú® ‚úÖ   DeleteUserPoolClient (Pro) ‚ú® ‚úÖ   DeleteUserPoolDomain (Pro)  ‚úÖ   DescribeIdentityProvider (Pro) ‚ú® ‚úÖ   DescribeResourceServer (Pro) ‚ú® ‚úÖ   DescribeUserPool (Pro) ‚ú® ‚úÖ   DescribeUserPoolClient (Pro) ‚ú® ‚úÖ   DescribeUserPoolDomain (Pro)  ‚úÖ   ForgotPassword (Pro) ‚ú® ‚úÖ   GetGroup (Pro)  ‚úÖ   GetSigningCertificate (Pro) ‚ú® ‚úÖ   GetUser (Pro) ‚ú® ‚úÖ   GlobalSignOut (Pro) ‚ú® ‚úÖ   InitiateAuth (Pro) ‚ú® ‚úÖ   ListGroups (Pro) ‚ú® ‚úÖ   ListIdentityProviders (Pro) ‚ú® ‚úÖ   ListResourceServers (Pro) ‚ú® ‚úÖ   ListUserPoolClients (Pro) ‚ú® ‚úÖ   ListUserPools (Pro) ‚ú® ‚úÖ   ListUsers (Pro) ‚ú® ‚úÖ   ListUsersInGroup (Pro) ‚ú® ‚úÖ   RespondToAuthChallenge (Pro) ‚ú® ‚úÖ   SetUserMFAPreference (Pro) ‚ú® ‚úÖ   SignUp (Pro) ‚ú® ‚úÖ   UpdateGroup (Pro)  ‚úÖ   UpdateIdentityProvider (Pro) ‚ú® ‚úÖ   UpdateResourceServer (Pro)  ‚úÖ   UpdateUserAttributes (Pro)  ‚úÖ     Show missing     AdminAddUserToGroup -   AdminConfirmSignUp -   AdminCreateUser -   AdminDisableProviderForUser -   AdminForgetDevice -   AdminGetDevice -   AdminLinkProviderForUser -   AdminListDevices -   AdminListGroupsForUser -   AdminListUserAuthEvents -   AdminRemoveUserFromGroup -   AdminRespondToAuthChallenge -   AdminSetUserSettings -   AdminUpdateAuthEventFeedback -   AdminUpdateDeviceStatus -   AssociateSoftwareToken -   CreateUserImportJob -   CreateUserPool -   CreateUserPoolClient -   DeleteUser -   DescribeRiskConfiguration -   DescribeUserImportJob -   ForgetDevice -   GetCSVHeader -   GetDevice -   GetIdentityProviderByIdentifier -   GetUICustomization -   GetUserAttributeVerificationCode -   GetUserPoolMfaConfig -   ListDevices -   ListTagsForResource -   ListUserImportJobs -   ResendConfirmationCode -   RevokeToken -   SetRiskConfiguration -   SetUICustomization -   SetUserPoolMfaConfig -   SetUserSettings -   StartUserImportJob -   StopUserImportJob -   TagResource -   UntagResource -   UpdateAuthEventFeedback -   UpdateDeviceStatus -   UpdateUserPool -   UpdateUserPoolClient -   UpdateUserPoolDomain -   VerifySoftwareToken -   VerifyUserAttribute -    config    Operation Implemented     BatchGetAggregateResourceConfig ‚úÖ   BatchGetResourceConfig ‚úÖ   DeleteAggregationAuthorization ‚úÖ   DeleteConfigRule ‚úÖ   DeleteConfigurationAggregator ‚úÖ   DeleteConfigurationRecorder ‚ú® ‚úÖ   DeleteDeliveryChannel ‚ú® ‚úÖ   DeleteOrganizationConformancePack ‚úÖ   DescribeAggregationAuthorizations ‚úÖ   DescribeConfigRules ‚úÖ   DescribeConfigurationAggregators ‚úÖ   DescribeConfigurationRecorderStatus ‚úÖ   DescribeConfigurationRecorders ‚ú® ‚úÖ   DescribeDeliveryChannels ‚ú® ‚úÖ   DescribeOrganizationConformancePackStatuses ‚úÖ   DescribeOrganizationConformancePacks ‚úÖ   GetOrganizationConformancePackDetailedStatus ‚úÖ   GetResourceConfigHistory ‚úÖ   ListAggregateDiscoveredResources ‚úÖ   ListDiscoveredResources ‚úÖ   ListTagsForResource ‚úÖ   PutAggregationAuthorization ‚úÖ   PutConfigRule ‚úÖ   PutConfigurationAggregator ‚úÖ   PutConfigurationRecorder ‚ú® ‚úÖ   PutDeliveryChannel ‚ú® ‚úÖ   PutEvaluations ‚úÖ   PutOrganizationConformancePack ‚úÖ   StartConfigurationRecorder ‚úÖ   StopConfigurationRecorder ‚úÖ   TagResource ‚úÖ   UntagResource ‚úÖ     Show missing     DeleteConformancePack -   DeleteEvaluationResults -   DeleteOrganizationConfigRule -   DeletePendingAggregationRequest -   DeleteRemediationConfiguration -   DeleteRemediationExceptions -   DeleteResourceConfig -   DeleteRetentionConfiguration -   DeleteStoredQuery -   DeliverConfigSnapshot -   DescribeAggregateComplianceByConfigRules -   DescribeAggregateComplianceByConformancePacks -   DescribeComplianceByConfigRule -   DescribeComplianceByResource -   DescribeConfigRuleEvaluationStatus -   DescribeConfigurationAggregatorSourcesStatus -   DescribeConformancePackCompliance -   DescribeConformancePackStatus -   DescribeConformancePacks -   DescribeDeliveryChannelStatus -   DescribeOrganizationConfigRuleStatuses -   DescribeOrganizationConfigRules -   DescribePendingAggregationRequests -   DescribeRemediationConfigurations -   DescribeRemediationExceptions -   DescribeRemediationExecutionStatus -   DescribeRetentionConfigurations -   GetAggregateComplianceDetailsByConfigRule -   GetAggregateConfigRuleComplianceSummary -   GetAggregateConformancePackComplianceSummary -   GetAggregateDiscoveredResourceCounts -   GetAggregateResourceConfig -   GetComplianceDetailsByConfigRule -   GetComplianceDetailsByResource -   GetComplianceSummaryByConfigRule -   GetComplianceSummaryByResourceType -   GetConformancePackComplianceDetails -   GetConformancePackComplianceSummary -   GetCustomRulePolicy -   GetDiscoveredResourceCounts -   GetOrganizationConfigRuleDetailedStatus -   GetOrganizationCustomRulePolicy -   GetStoredQuery -   ListStoredQueries -   PutConformancePack -   PutExternalEvaluation -   PutOrganizationConfigRule -   PutRemediationConfigurations -   PutRemediationExceptions -   PutResourceConfig -   PutRetentionConfiguration -   PutStoredQuery -   SelectAggregateResourceConfig -   SelectResourceConfig -   StartConfigRulesEvaluation -   StartRemediationExecution -    docdb    Operation Implemented     CopyDBClusterSnapshot (Pro)  ‚úÖ   CreateDBCluster (Pro)  ‚úÖ   CreateDBClusterParameterGroup (Pro)  ‚úÖ   CreateDBClusterSnapshot (Pro)  ‚úÖ   CreateDBInstance (Pro)  ‚úÖ   CreateDBSubnetGroup (Pro)  ‚úÖ   CreateEventSubscription (Pro)  ‚úÖ   DeleteDBCluster (Pro)  ‚úÖ   DeleteDBClusterParameterGroup (Pro)  ‚úÖ   DeleteDBClusterSnapshot (Pro)  ‚úÖ   DeleteDBInstance (Pro)  ‚úÖ   DeleteDBSubnetGroup (Pro)  ‚úÖ   DeleteEventSubscription (Pro)  ‚úÖ   DescribeCertificates (Pro)  ‚úÖ   DescribeDBClusterParameterGroups (Pro)  ‚úÖ   DescribeDBClusterParameters (Pro)  ‚úÖ   DescribeDBClusterSnapshots (Pro)  ‚úÖ   DescribeDBClusters (Pro)  ‚úÖ   DescribeDBEngineVersions (Pro)  ‚úÖ   DescribeDBInstances (Pro)  ‚úÖ   DescribeDBSubnetGroups (Pro)  ‚úÖ   DescribeEventSubscriptions (Pro)  ‚úÖ   DescribeGlobalClusters (Pro)  ‚úÖ   ModifyDBCluster (Pro)  ‚úÖ   ModifyDBClusterParameterGroup (Pro)  ‚úÖ   ModifyDBInstance (Pro)  ‚úÖ   ModifyDBSubnetGroup (Pro)  ‚úÖ   RebootDBInstance (Pro)  ‚úÖ   ResetDBClusterParameterGroup (Pro)  ‚úÖ   StartDBCluster (Pro)  ‚úÖ   StopDBCluster (Pro)  ‚úÖ     Show missing     AddSourceIdentifierToSubscription -   AddTagsToResource -   ApplyPendingMaintenanceAction -   CopyDBClusterParameterGroup -   CreateGlobalCluster -   DeleteGlobalCluster -   DescribeDBClusterSnapshotAttributes -   DescribeEngineDefaultClusterParameters -   DescribeEventCategories -   DescribeEvents -   DescribeOrderableDBInstanceOptions -   DescribePendingMaintenanceActions -   FailoverDBCluster -   ListTagsForResource -   ModifyDBClusterSnapshotAttribute -   ModifyEventSubscription -   ModifyGlobalCluster -   RemoveFromGlobalCluster -   RemoveSourceIdentifierFromSubscription -   RemoveTagsFromResource -   RestoreDBClusterFromSnapshot -   RestoreDBClusterToPointInTime -    dynamodb    Operation Implemented     BatchExecuteStatement ‚ú® ‚úÖ   BatchGetItem ‚ú® ‚úÖ   CreateGlobalTable ‚ú® ‚úÖ   CreateTable ‚ú® ‚úÖ   DeleteBackup (Pro) ‚ú® ‚úÖ   DeleteItem ‚ú® ‚úÖ   DeleteTable ‚ú® ‚úÖ   DescribeGlobalTable ‚ú® ‚úÖ   DescribeKinesisStreamingDestination ‚ú® ‚úÖ   DescribeLimits ‚úÖ   DescribeTable ‚ú® ‚úÖ   DescribeTimeToLive ‚ú® ‚úÖ   DisableKinesisStreamingDestination ‚ú® ‚úÖ   EnableKinesisStreamingDestination ‚ú® ‚úÖ   ExecuteStatement ‚ú® ‚úÖ   ExecuteTransaction ‚ú® ‚úÖ   GetItem ‚ú® ‚úÖ   ListGlobalTables ‚úÖ   ListTables ‚ú® ‚úÖ   ListTagsOfResource ‚ú® ‚úÖ   PutItem ‚ú® ‚úÖ   RestoreTableFromBackup (Pro) ‚ú® ‚úÖ   Scan ‚ú® ‚úÖ   TagResource ‚ú® ‚úÖ   TransactGetItems ‚ú® ‚úÖ   UntagResource ‚ú® ‚úÖ   UpdateGlobalTable ‚ú® ‚úÖ   UpdateItem ‚ú® ‚úÖ   UpdateTable ‚ú® ‚úÖ   UpdateTimeToLive ‚ú® ‚úÖ     Show missing     BatchWriteItem -   CreateBackup -   DescribeBackup -   DescribeContinuousBackups -   DescribeContributorInsights -   DescribeEndpoints -   DescribeExport -   DescribeGlobalTableSettings -   DescribeTableReplicaAutoScaling -   ExportTableToPointInTime -   ListBackups -   ListContributorInsights -   ListExports -   Query -   RestoreTableToPointInTime -   TransactWriteItems -   UpdateContinuousBackups -   UpdateContributorInsights -   UpdateGlobalTableSettings -   UpdateTableReplicaAutoScaling -    dynamodbstreams    Operation Implemented     DescribeStream ‚ú® ‚úÖ   ListStreams ‚ú® ‚úÖ     Show missing     GetRecords -   GetShardIterator -    ec2    Operation Implemented     AcceptVpcPeeringConnection ‚ú® ‚úÖ   AllocateAddress ‚ú® ‚úÖ   AssignIpv6Addresses ‚úÖ   AssignPrivateIpAddresses ‚úÖ   AssociateAddress ‚úÖ   AssociateDhcpOptions ‚úÖ   AssociateIamInstanceProfile ‚úÖ   AssociateRouteTable ‚ú® ‚úÖ   AssociateSubnetCidrBlock ‚úÖ   AssociateVpcCidrBlock ‚úÖ   AttachInternetGateway ‚ú® ‚úÖ   AttachNetworkInterface ‚úÖ   AttachVolume ‚úÖ   AttachVpnGateway ‚ú® ‚úÖ   AuthorizeSecurityGroupEgress ‚ú® ‚úÖ   AuthorizeSecurityGroupIngress ‚ú® ‚úÖ   CancelSpotInstanceRequests ‚úÖ   CopyImage ‚úÖ   CopySnapshot ‚úÖ   CreateCarrierGateway ‚úÖ   CreateCustomerGateway ‚úÖ   CreateDhcpOptions ‚úÖ   CreateEgressOnlyInternetGateway ‚úÖ   CreateFlowLogs ‚úÖ   CreateImage ‚ú® ‚úÖ   CreateInternetGateway ‚ú® ‚úÖ   CreateKeyPair ‚ú® ‚úÖ   CreateLaunchTemplate ‚úÖ   CreateManagedPrefixList ‚úÖ   CreateNatGateway ‚ú® ‚úÖ   CreateNetworkAcl ‚úÖ   CreateNetworkAclEntry ‚úÖ   CreateNetworkInterface ‚úÖ   CreatePlacementGroup ‚úÖ   CreateRoute ‚ú® ‚úÖ   CreateRouteTable ‚ú® ‚úÖ   CreateSecurityGroup ‚ú® ‚úÖ   CreateSnapshot ‚úÖ   CreateSnapshots ‚úÖ   CreateSpotDatafeedSubscription ‚úÖ   CreateSubnet ‚ú® ‚úÖ   CreateTags ‚ú® ‚úÖ   CreateTransitGateway ‚úÖ   CreateTransitGatewayPeeringAttachment ‚úÖ   CreateTransitGatewayRouteTable ‚úÖ   CreateTransitGatewayVpcAttachment ‚úÖ   CreateVolume ‚úÖ   CreateVpc ‚ú® ‚úÖ   CreateVpcEndpoint ‚ú® ‚úÖ   CreateVpcEndpointServiceConfiguration ‚úÖ   CreateVpnConnection ‚úÖ   CreateVpnGateway ‚ú® ‚úÖ   DeleteCarrierGateway ‚úÖ   DeleteCustomerGateway ‚úÖ   DeleteDhcpOptions ‚úÖ   DeleteEgressOnlyInternetGateway ‚úÖ   DeleteFlowLogs ‚úÖ   DeleteInternetGateway ‚úÖ   DeleteKeyPair ‚úÖ   DeleteLaunchTemplate ‚úÖ   DeleteNetworkAcl ‚úÖ   DeleteNetworkAclEntry ‚úÖ   DeleteNetworkInterface ‚úÖ   DeletePlacementGroup ‚úÖ   DeleteRoute ‚ú® ‚úÖ   DeleteRouteTable ‚ú® ‚úÖ   DeleteSecurityGroup ‚ú® ‚úÖ   DeleteSnapshot ‚úÖ   DeleteSpotDatafeedSubscription ‚úÖ   DeleteSubnet ‚ú® ‚úÖ   DeleteTags ‚úÖ   DeleteVolume ‚úÖ   DeleteVpc ‚ú® ‚úÖ   DeleteVpcEndpointServiceConfigurations ‚úÖ   DeleteVpcEndpoints ‚ú® ‚úÖ   DeleteVpcPeeringConnection ‚ú® ‚úÖ   DeleteVpnConnection ‚úÖ   DeleteVpnGateway ‚ú® ‚úÖ   DeregisterImage ‚úÖ   DescribeAccountAttributes ‚ú® ‚úÖ   DescribeAddresses ‚úÖ   DescribeAvailabilityZones ‚úÖ   DescribeCarrierGateways ‚úÖ   DescribeCustomerGateways ‚úÖ   DescribeDhcpOptions ‚úÖ   DescribeEgressOnlyInternetGateways ‚úÖ   DescribeFlowLogs ‚úÖ   DescribeImageAttribute ‚úÖ   DescribeImages ‚ú® ‚úÖ   DescribeInstanceAttribute ‚úÖ   DescribeInstanceCreditSpecifications ‚úÖ   DescribeInstanceStatus ‚úÖ   DescribeInstanceTypeOfferings ‚úÖ   DescribeInstanceTypes ‚úÖ   DescribeInstances ‚ú® ‚úÖ   DescribeInternetGateways ‚ú® ‚úÖ   DescribeKeyPairs ‚úÖ   DescribeLaunchTemplates ‚úÖ   DescribeManagedPrefixLists ‚úÖ   DescribeNatGateways ‚ú® ‚úÖ   DescribeNetworkAcls ‚ú® ‚úÖ   DescribeNetworkInterfaceAttribute ‚úÖ   DescribeNetworkInterfaces ‚ú® ‚úÖ   DescribePrefixLists ‚úÖ   DescribeRegions ‚úÖ   DescribeReservedInstances ‚ú® ‚úÖ   DescribeReservedInstancesOfferings ‚ú® ‚úÖ   DescribeRouteTables ‚ú® ‚úÖ   DescribeSecurityGroups ‚ú® ‚úÖ   DescribeSnapshotAttribute ‚úÖ   DescribeSnapshots ‚úÖ   DescribeSpotFleetRequests ‚úÖ   DescribeSpotInstanceRequests ‚úÖ   DescribeSpotPriceHistory ‚úÖ   DescribeSubnets ‚ú® ‚úÖ   DescribeTags ‚úÖ   DescribeTransitGatewayAttachments ‚úÖ   DescribeTransitGatewayPeeringAttachments ‚úÖ   DescribeTransitGatewayRouteTables ‚úÖ   DescribeTransitGatewayVpcAttachments ‚úÖ   DescribeTransitGateways ‚úÖ   DescribeVolumes ‚úÖ   DescribeVpcAttribute ‚ú® ‚úÖ   DescribeVpcClassicLink ‚ú® ‚úÖ   DescribeVpcClassicLinkDnsSupport ‚ú® ‚úÖ   DescribeVpcEndpointServiceConfigurations ‚úÖ   DescribeVpcEndpointServicePermissions ‚úÖ   DescribeVpcEndpointServices ‚ú® ‚úÖ   DescribeVpcEndpoints ‚ú® ‚úÖ   DescribeVpcPeeringConnections ‚ú® ‚úÖ   DescribeVpcs ‚ú® ‚úÖ   DescribeVpnConnections ‚úÖ   DescribeVpnGateways ‚ú® ‚úÖ   DetachInternetGateway ‚úÖ   DetachNetworkInterface ‚úÖ   DetachVolume ‚úÖ   DetachVpnGateway ‚ú® ‚úÖ   DisableEbsEncryptionByDefault ‚úÖ   DisableVpcClassicLink ‚úÖ   DisableVpcClassicLinkDnsSupport ‚úÖ   DisassociateAddress ‚úÖ   DisassociateIamInstanceProfile ‚úÖ   DisassociateRouteTable ‚ú® ‚úÖ   DisassociateSubnetCidrBlock ‚úÖ   DisassociateVpcCidrBlock ‚úÖ   EnableEbsEncryptionByDefault ‚úÖ   EnableVolumeIO ‚úÖ   EnableVpcClassicLink ‚úÖ   EnableVpcClassicLinkDnsSupport ‚úÖ   GetConsoleOutput ‚úÖ   GetEbsEncryptionByDefault ‚úÖ   GetManagedPrefixListEntries ‚úÖ   GetTransitGatewayRouteTableAssociations ‚úÖ   GetTransitGatewayRouteTablePropagations ‚úÖ   ImportKeyPair ‚ú® ‚úÖ   ImportVolume ‚úÖ   ModifyImageAttribute ‚úÖ   ModifyInstanceAttribute ‚úÖ   ModifyNetworkInterfaceAttribute ‚úÖ   ModifySnapshotAttribute ‚úÖ   ModifySubnetAttribute ‚ú® ‚úÖ   ModifyVolumeAttribute ‚úÖ   ModifyVpcAttribute ‚úÖ   ModifyVpcEndpointServiceConfiguration ‚úÖ   ModifyVpcEndpointServicePermissions ‚úÖ   ModifyVpcPeeringConnectionOptions ‚úÖ   ModifyVpcTenancy ‚úÖ   MonitorInstances ‚úÖ   PurchaseReservedInstancesOffering ‚ú® ‚úÖ   RebootInstances ‚úÖ   RegisterImage ‚úÖ   RejectVpcPeeringConnection ‚úÖ   ReleaseAddress ‚ú® ‚úÖ   ReplaceIamInstanceProfileAssociation ‚úÖ   ReplaceNetworkAclAssociation ‚úÖ   ReplaceNetworkAclEntry (Pro)  ‚úÖ   ReplaceRoute ‚úÖ   ReplaceRouteTableAssociation ‚úÖ   RequestSpotFleet ‚úÖ   RequestSpotInstances ‚úÖ   ResetImageAttribute ‚úÖ   ResetNetworkInterfaceAttribute ‚úÖ   ResetSnapshotAttribute ‚úÖ   RevokeSecurityGroupEgress ‚ú® ‚úÖ   RevokeSecurityGroupIngress ‚úÖ   RunInstances ‚ú® ‚úÖ   SearchTransitGatewayRoutes ‚úÖ   StartInstances ‚ú® ‚úÖ   StopInstances ‚ú® ‚úÖ   TerminateInstances ‚ú® ‚úÖ   UnassignIpv6Addresses ‚úÖ   UnassignPrivateIpAddresses ‚úÖ   UnmonitorInstances ‚úÖ   UpdateSecurityGroupRuleDescriptionsEgress ‚úÖ   UpdateSecurityGroupRuleDescriptionsIngress ‚úÖ     Show missing     AcceptReservedInstancesExchangeQuote -   AcceptTransitGatewayMulticastDomainAssociations -   AcceptTransitGatewayPeeringAttachment -   AcceptTransitGatewayVpcAttachment -   AcceptVpcEndpointConnections -   AdvertiseByoipCidr -   AllocateHosts -   AllocateIpamPoolCidr -   ApplySecurityGroupsToClientVpnTargetNetwork -   AssociateClientVpnTargetNetwork -   AssociateEnclaveCertificateIamRole -   AssociateInstanceEventWindow -   AssociateTransitGatewayMulticastDomain -   AssociateTransitGatewayRouteTable -   AssociateTrunkInterface -   AttachClassicLinkVpc -   AuthorizeClientVpnIngress -   BundleInstance -   CancelBundleTask -   CancelCapacityReservation -   CancelCapacityReservationFleets -   CancelConversionTask -   CancelExportTask -   CancelImportTask -   CancelReservedInstancesListing -   CancelSpotFleetRequests -   ConfirmProductInstance -   CopyFpgaImage -   CreateCapacityReservation -   CreateCapacityReservationFleet -   CreateClientVpnEndpoint -   CreateClientVpnRoute -   CreateDefaultSubnet -   CreateDefaultVpc -   CreateFleet -   CreateFpgaImage -   CreateInstanceEventWindow -   CreateInstanceExportTask -   CreateIpam -   CreateIpamPool -   CreateIpamScope -   CreateLaunchTemplateVersion -   CreateLocalGatewayRoute -   CreateLocalGatewayRouteTableVpcAssociation -   CreateNetworkInsightsAccessScope -   CreateNetworkInsightsPath -   CreateNetworkInterfacePermission -   CreatePublicIpv4Pool -   CreateReplaceRootVolumeTask -   CreateReservedInstancesListing -   CreateRestoreImageTask -   CreateStoreImageTask -   CreateSubnetCidrReservation -   CreateTrafficMirrorFilter -   CreateTrafficMirrorFilterRule -   CreateTrafficMirrorSession -   CreateTrafficMirrorTarget -   CreateTransitGatewayConnect -   CreateTransitGatewayConnectPeer -   CreateTransitGatewayMulticastDomain -   CreateTransitGatewayPrefixListReference -   CreateTransitGatewayRoute -   CreateVpcEndpointConnectionNotification -   CreateVpcPeeringConnection -   CreateVpnConnectionRoute -   DeleteClientVpnEndpoint -   DeleteClientVpnRoute -   DeleteFleets -   DeleteFpgaImage -   DeleteInstanceEventWindow -   DeleteIpam -   DeleteIpamPool -   DeleteIpamScope -   DeleteLaunchTemplateVersions -   DeleteLocalGatewayRoute -   DeleteLocalGatewayRouteTableVpcAssociation -   DeleteManagedPrefixList -   DeleteNatGateway -   DeleteNetworkInsightsAccessScope -   DeleteNetworkInsightsAccessScopeAnalysis -   DeleteNetworkInsightsAnalysis -   DeleteNetworkInsightsPath -   DeleteNetworkInterfacePermission -   DeletePublicIpv4Pool -   DeleteQueuedReservedInstances -   DeleteSubnetCidrReservation -   DeleteTrafficMirrorFilter -   DeleteTrafficMirrorFilterRule -   DeleteTrafficMirrorSession -   DeleteTrafficMirrorTarget -   DeleteTransitGateway -   DeleteTransitGatewayConnect -   DeleteTransitGatewayConnectPeer -   DeleteTransitGatewayMulticastDomain -   DeleteTransitGatewayPeeringAttachment -   DeleteTransitGatewayPrefixListReference -   DeleteTransitGatewayRoute -   DeleteTransitGatewayRouteTable -   DeleteTransitGatewayVpcAttachment -   DeleteVpcEndpointConnectionNotifications -   DeleteVpnConnectionRoute -   DeprovisionByoipCidr -   DeprovisionIpamPoolCidr -   DeprovisionPublicIpv4PoolCidr -   DeregisterInstanceEventNotificationAttributes -   DeregisterTransitGatewayMulticastGroupMembers -   DeregisterTransitGatewayMulticastGroupSources -   DescribeAddressesAttribute -   DescribeAggregateIdFormat -   DescribeBundleTasks -   DescribeByoipCidrs -   DescribeCapacityReservationFleets -   DescribeCapacityReservations -   DescribeClassicLinkInstances -   DescribeClientVpnAuthorizationRules -   DescribeClientVpnConnections -   DescribeClientVpnEndpoints -   DescribeClientVpnRoutes -   DescribeClientVpnTargetNetworks -   DescribeCoipPools -   DescribeConversionTasks -   DescribeElasticGpus -   DescribeExportImageTasks -   DescribeExportTasks -   DescribeFastLaunchImages -   DescribeFastSnapshotRestores -   DescribeFleetHistory -   DescribeFleetInstances -   DescribeFleets -   DescribeFpgaImageAttribute -   DescribeFpgaImages -   DescribeHostReservationOfferings -   DescribeHostReservations -   DescribeHosts -   DescribeIamInstanceProfileAssociations -   DescribeIdFormat -   DescribeIdentityIdFormat -   DescribeImportImageTasks -   DescribeImportSnapshotTasks -   DescribeInstanceEventNotificationAttributes -   DescribeInstanceEventWindows -   DescribeIpamPools -   DescribeIpamScopes -   DescribeIpams -   DescribeIpv6Pools -   DescribeLaunchTemplateVersions -   DescribeLocalGatewayRouteTableVirtualInterfaceGroupAssociations -   DescribeLocalGatewayRouteTableVpcAssociations -   DescribeLocalGatewayRouteTables -   DescribeLocalGatewayVirtualInterfaceGroups -   DescribeLocalGatewayVirtualInterfaces -   DescribeLocalGateways -   DescribeMovingAddresses -   DescribeNetworkInsightsAccessScopeAnalyses -   DescribeNetworkInsightsAccessScopes -   DescribeNetworkInsightsAnalyses -   DescribeNetworkInsightsPaths -   DescribeNetworkInterfacePermissions -   DescribePlacementGroups -   DescribePrincipalIdFormat -   DescribePublicIpv4Pools -   DescribeReplaceRootVolumeTasks -   DescribeReservedInstancesListings -   DescribeReservedInstancesModifications -   DescribeScheduledInstanceAvailability -   DescribeScheduledInstances -   DescribeSecurityGroupReferences -   DescribeSecurityGroupRules -   DescribeSnapshotTierStatus -   DescribeSpotDatafeedSubscription -   DescribeSpotFleetInstances -   DescribeSpotFleetRequestHistory -   DescribeStaleSecurityGroups -   DescribeStoreImageTasks -   DescribeTrafficMirrorFilters -   DescribeTrafficMirrorSessions -   DescribeTrafficMirrorTargets -   DescribeTransitGatewayConnectPeers -   DescribeTransitGatewayConnects -   DescribeTransitGatewayMulticastDomains -   DescribeTrunkInterfaceAssociations -   DescribeVolumeAttribute -   DescribeVolumeStatus -   DescribeVolumesModifications -   DescribeVpcEndpointConnectionNotifications -   DescribeVpcEndpointConnections -   DetachClassicLinkVpc -   DisableFastLaunch -   DisableFastSnapshotRestores -   DisableImageDeprecation -   DisableIpamOrganizationAdminAccount -   DisableSerialConsoleAccess -   DisableTransitGatewayRouteTablePropagation -   DisableVgwRoutePropagation -   DisassociateClientVpnTargetNetwork -   DisassociateEnclaveCertificateIamRole -   DisassociateInstanceEventWindow -   DisassociateTransitGatewayMulticastDomain -   DisassociateTransitGatewayRouteTable -   DisassociateTrunkInterface -   EnableFastLaunch -   EnableFastSnapshotRestores -   EnableImageDeprecation -   EnableIpamOrganizationAdminAccount -   EnableSerialConsoleAccess -   EnableTransitGatewayRouteTablePropagation -   EnableVgwRoutePropagation -   ExportClientVpnClientCertificateRevocationList -   ExportClientVpnClientConfiguration -   ExportImage -   ExportTransitGatewayRoutes -   GetAssociatedEnclaveCertificateIamRoles -   GetAssociatedIpv6PoolCidrs -   GetCapacityReservationUsage -   GetCoipPoolUsage -   GetConsoleScreenshot -   GetDefaultCreditSpecification -   GetEbsDefaultKmsKeyId -   GetFlowLogsIntegrationTemplate -   GetGroupsForCapacityReservation -   GetHostReservationPurchasePreview -   GetInstanceTypesFromInstanceRequirements -   GetInstanceUefiData -   GetIpamAddressHistory -   GetIpamPoolAllocations -   GetIpamPoolCidrs -   GetIpamResourceCidrs -   GetLaunchTemplateData -   GetManagedPrefixListAssociations -   GetNetworkInsightsAccessScopeAnalysisFindings -   GetNetworkInsightsAccessScopeContent -   GetPasswordData -   GetReservedInstancesExchangeQuote -   GetSerialConsoleAccessStatus -   GetSpotPlacementScores -   GetSubnetCidrReservations -   GetTransitGatewayAttachmentPropagations -   GetTransitGatewayMulticastDomainAssociations -   GetTransitGatewayPrefixListReferences -   GetVpnConnectionDeviceSampleConfiguration -   GetVpnConnectionDeviceTypes -   ImportClientVpnClientCertificateRevocationList -   ImportImage -   ImportInstance -   ImportSnapshot -   ListImagesInRecycleBin -   ListSnapshotsInRecycleBin -   ModifyAddressAttribute -   ModifyAvailabilityZoneGroup -   ModifyCapacityReservation -   ModifyCapacityReservationFleet -   ModifyClientVpnEndpoint -   ModifyDefaultCreditSpecification -   ModifyEbsDefaultKmsKeyId -   ModifyFleet -   ModifyFpgaImageAttribute -   ModifyHosts -   ModifyIdFormat -   ModifyIdentityIdFormat -   ModifyInstanceCapacityReservationAttributes -   ModifyInstanceCreditSpecification -   ModifyInstanceEventStartTime -   ModifyInstanceEventWindow -   ModifyInstanceMaintenanceOptions -   ModifyInstanceMetadataOptions -   ModifyInstancePlacement -   ModifyIpam -   ModifyIpamPool -   ModifyIpamResourceCidr -   ModifyIpamScope -   ModifyLaunchTemplate -   ModifyManagedPrefixList -   ModifyPrivateDnsNameOptions -   ModifyReservedInstances -   ModifySecurityGroupRules -   ModifySnapshotTier -   ModifySpotFleetRequest -   ModifyTrafficMirrorFilterNetworkServices -   ModifyTrafficMirrorFilterRule -   ModifyTrafficMirrorSession -   ModifyTransitGateway -   ModifyTransitGatewayPrefixListReference -   ModifyTransitGatewayVpcAttachment -   ModifyVolume -   ModifyVpcEndpoint -   ModifyVpcEndpointConnectionNotification -   ModifyVpcEndpointServicePayerResponsibility -   ModifyVpnConnection -   ModifyVpnConnectionOptions -   ModifyVpnTunnelCertificate -   ModifyVpnTunnelOptions -   MoveAddressToVpc -   MoveByoipCidrToIpam -   ProvisionByoipCidr -   ProvisionIpamPoolCidr -   ProvisionPublicIpv4PoolCidr -   PurchaseHostReservation -   PurchaseScheduledInstances -   RegisterInstanceEventNotificationAttributes -   RegisterTransitGatewayMulticastGroupMembers -   RegisterTransitGatewayMulticastGroupSources -   RejectTransitGatewayMulticastDomainAssociations -   RejectTransitGatewayPeeringAttachment -   RejectTransitGatewayVpcAttachment -   RejectVpcEndpointConnections -   ReleaseHosts -   ReleaseIpamPoolAllocation -   ReplaceTransitGatewayRoute -   ReportInstanceStatus -   ResetAddressAttribute -   ResetEbsDefaultKmsKeyId -   ResetFpgaImageAttribute -   ResetInstanceAttribute -   RestoreAddressToClassic -   RestoreImageFromRecycleBin -   RestoreManagedPrefixListVersion -   RestoreSnapshotFromRecycleBin -   RestoreSnapshotTier -   RevokeClientVpnIngress -   RunScheduledInstances -   SearchLocalGatewayRoutes -   SearchTransitGatewayMulticastGroups -   SendDiagnosticInterrupt -   StartNetworkInsightsAccessScopeAnalysis -   StartNetworkInsightsAnalysis -   StartVpcEndpointServicePrivateDnsVerification -   TerminateClientVpnConnections -   WithdrawByoipCidr -    ecr    Operation Implemented     BatchCheckLayerAvailability (Pro)  ‚úÖ   BatchDeleteImage (Pro) ‚ú® ‚úÖ   BatchGetImage (Pro) ‚ú® ‚úÖ   CreateRepository (Pro) ‚ú® ‚úÖ   DeleteLifecyclePolicy (Pro) ‚ú® ‚úÖ   DeleteRegistryPolicy (Pro)  ‚úÖ   DeleteRepository (Pro) ‚ú® ‚úÖ   DeleteRepositoryPolicy (Pro)  ‚úÖ   DescribeImageScanFindings (Pro)  ‚úÖ   DescribeRegistry (Pro)  ‚úÖ   DescribeRepositories (Pro) ‚ú® ‚úÖ   GetAuthorizationToken (Pro) ‚ú® ‚úÖ   GetLifecyclePolicy (Pro) ‚ú® ‚úÖ   GetRegistryPolicy (Pro)  ‚úÖ   GetRepositoryPolicy (Pro)  ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   PutImage (Pro)  ‚úÖ   PutImageScanningConfiguration (Pro)  ‚úÖ   PutImageTagMutability (Pro) ‚ú® ‚úÖ   PutLifecyclePolicy (Pro) ‚ú® ‚úÖ   PutRegistryPolicy (Pro)  ‚úÖ   PutReplicationConfiguration (Pro)  ‚úÖ   SetRepositoryPolicy (Pro)  ‚úÖ   StartImageScan (Pro)  ‚úÖ   TagResource (Pro) ‚ú® ‚úÖ   UntagResource (Pro) ‚ú® ‚úÖ     Show missing     BatchGetRepositoryScanningConfiguration -   CompleteLayerUpload -   CreatePullThroughCacheRule -   DeletePullThroughCacheRule -   DescribeImageReplicationStatus -   DescribeImages -   DescribePullThroughCacheRules -   GetDownloadUrlForLayer -   GetLifecyclePolicyPreview -   GetRegistryScanningConfiguration -   InitiateLayerUpload -   ListImages -   PutRegistryScanningConfiguration -   StartLifecyclePolicyPreview -   UploadLayerPart -    ecs    Operation Implemented     CreateCapacityProvider (Pro)  ‚úÖ   CreateCluster (Pro) ‚ú® ‚úÖ   CreateService (Pro) ‚ú® ‚úÖ   CreateTaskSet (Pro) ‚ú® ‚úÖ   DeleteAccountSetting (Pro)  ‚úÖ   DeleteAttributes (Pro)  ‚úÖ   DeleteCluster (Pro) ‚ú® ‚úÖ   DeleteService (Pro) ‚ú® ‚úÖ   DeregisterContainerInstance (Pro)  ‚úÖ   DeregisterTaskDefinition (Pro) ‚ú® ‚úÖ   DescribeCapacityProviders (Pro)  ‚úÖ   DescribeClusters (Pro) ‚ú® ‚úÖ   DescribeServices (Pro) ‚ú® ‚úÖ   DescribeTaskSets (Pro)  ‚úÖ   DescribeTasks (Pro) ‚ú® ‚úÖ   DiscoverPollEndpoint (Pro)  ‚úÖ   ListAccountSettings (Pro)  ‚úÖ   ListAttributes (Pro)  ‚úÖ   ListClusters (Pro) ‚ú® ‚úÖ   ListContainerInstances (Pro)  ‚úÖ   ListServices (Pro)  ‚úÖ   ListTagsForResource (Pro)  ‚úÖ   ListTaskDefinitionFamilies (Pro)  ‚úÖ   ListTaskDefinitions (Pro) ‚ú® ‚úÖ   ListTasks (Pro) ‚ú® ‚úÖ   PutAccountSetting (Pro)  ‚úÖ   PutAttributes (Pro)  ‚úÖ   PutClusterCapacityProviders (Pro) ‚ú® ‚úÖ   RegisterTaskDefinition (Pro) ‚ú® ‚úÖ   StartTask (Pro)  ‚úÖ   StopTask (Pro) ‚ú® ‚úÖ   TagResource (Pro)  ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateCluster (Pro) ‚ú® ‚úÖ   UpdateService (Pro)  ‚úÖ   UpdateServicePrimaryTaskSet (Pro)  ‚úÖ   UpdateTaskSet (Pro)  ‚úÖ     Show missing     DeleteCapacityProvider -   DeleteTaskSet -   DescribeContainerInstances -   DescribeTaskDefinition -   ExecuteCommand -   PutAccountSettingDefault -   RegisterContainerInstance -   RunTask -   SubmitAttachmentStateChanges -   SubmitContainerStateChange -   SubmitTaskStateChange -   UpdateCapacityProvider -   UpdateClusterSettings -   UpdateContainerAgent -   UpdateContainerInstancesState -    efs    Operation Implemented     CreateFileSystem (Pro) ‚ú® ‚úÖ   DeleteFileSystem (Pro) ‚ú® ‚úÖ   DescribeFileSystems (Pro) ‚ú® ‚úÖ     Show missing     CreateAccessPoint -   CreateMountTarget -   CreateReplicationConfiguration -   CreateTags -   DeleteAccessPoint -   DeleteFileSystemPolicy -   DeleteMountTarget -   DeleteReplicationConfiguration -   DeleteTags -   DescribeAccessPoints -   DescribeAccountPreferences -   DescribeBackupPolicy -   DescribeFileSystemPolicy -   DescribeLifecycleConfiguration -   DescribeMountTargetSecurityGroups -   DescribeMountTargets -   DescribeReplicationConfigurations -   DescribeTags -   ListTagsForResource -   ModifyMountTargetSecurityGroups -   PutAccountPreferences -   PutBackupPolicy -   PutFileSystemPolicy -   PutLifecycleConfiguration -   TagResource -   UntagResource -   UpdateFileSystem -    eks    Operation Implemented     CreateCluster (Pro) ‚ú® ‚úÖ   CreateFargateProfile (Pro)  ‚úÖ   CreateNodegroup (Pro)  ‚úÖ   DeleteCluster (Pro) ‚ú® ‚úÖ   DeleteFargateProfile (Pro)  ‚úÖ   DeleteNodegroup (Pro)  ‚úÖ   DescribeCluster (Pro) ‚ú® ‚úÖ   DescribeFargateProfile (Pro)  ‚úÖ   DescribeNodegroup (Pro)  ‚úÖ   ListClusters (Pro)  ‚úÖ   ListFargateProfiles (Pro)  ‚úÖ   ListNodegroups (Pro)  ‚úÖ   UpdateClusterConfig (Pro)  ‚úÖ   UpdateNodegroupConfig (Pro)  ‚úÖ   UpdateNodegroupVersion (Pro)  ‚úÖ     Show missing     AssociateEncryptionConfig -   AssociateIdentityProviderConfig -   CreateAddon -   DeleteAddon -   DeregisterCluster -   DescribeAddon -   DescribeAddonVersions -   DescribeIdentityProviderConfig -   DescribeUpdate -   DisassociateIdentityProviderConfig -   ListAddons -   ListIdentityProviderConfigs -   ListTagsForResource -   ListUpdates -   RegisterCluster -   TagResource -   UntagResource -   UpdateAddon -   UpdateClusterVersion -    elasticache    Operation Implemented     AddTagsToResource (Pro)  ‚úÖ   CreateCacheCluster (Pro) ‚ú® ‚úÖ   CreateCacheParameterGroup (Pro) ‚ú® ‚úÖ   CreateCacheSecurityGroup (Pro) ‚ú® ‚úÖ   CreateCacheSubnetGroup (Pro) ‚ú® ‚úÖ   CreateReplicationGroup (Pro) ‚ú® ‚úÖ   DeleteCacheCluster (Pro) ‚ú® ‚úÖ   DeleteCacheParameterGroup (Pro) ‚ú® ‚úÖ   DeleteCacheSecurityGroup (Pro) ‚ú® ‚úÖ   DeleteCacheSubnetGroup (Pro) ‚ú® ‚úÖ   DescribeCacheClusters (Pro) ‚ú® ‚úÖ   DescribeCacheParameterGroups (Pro) ‚ú® ‚úÖ   DescribeCacheSecurityGroups (Pro) ‚ú® ‚úÖ   DescribeCacheSubnetGroups (Pro) ‚ú® ‚úÖ   DescribeReplicationGroups (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro)  ‚úÖ   ModifyCacheCluster (Pro) ‚ú® ‚úÖ   ModifyCacheParameterGroup (Pro) ‚ú® ‚úÖ   ModifyCacheSubnetGroup (Pro) ‚ú® ‚úÖ   ModifyReplicationGroup (Pro) ‚ú® ‚úÖ   RemoveTagsFromResource (Pro)  ‚úÖ     Show missing     AuthorizeCacheSecurityGroupIngress -   BatchApplyUpdateAction -   BatchStopUpdateAction -   CompleteMigration -   CopySnapshot -   CreateGlobalReplicationGroup -   CreateSnapshot -   CreateUser -   CreateUserGroup -   DecreaseNodeGroupsInGlobalReplicationGroup -   DecreaseReplicaCount -   DeleteGlobalReplicationGroup -   DeleteReplicationGroup -   DeleteSnapshot -   DeleteUser -   DeleteUserGroup -   DescribeCacheEngineVersions -   DescribeCacheParameters -   DescribeEngineDefaultParameters -   DescribeEvents -   DescribeGlobalReplicationGroups -   DescribeReservedCacheNodes -   DescribeReservedCacheNodesOfferings -   DescribeServiceUpdates -   DescribeSnapshots -   DescribeUpdateActions -   DescribeUserGroups -   DescribeUsers -   DisassociateGlobalReplicationGroup -   FailoverGlobalReplicationGroup -   IncreaseNodeGroupsInGlobalReplicationGroup -   IncreaseReplicaCount -   ListAllowedNodeTypeModifications -   ModifyGlobalReplicationGroup -   ModifyReplicationGroupShardConfiguration -   ModifyUser -   ModifyUserGroup -   PurchaseReservedCacheNodesOffering -   RebalanceSlotsInGlobalReplicationGroup -   RebootCacheCluster -   ResetCacheParameterGroup -   RevokeCacheSecurityGroupIngress -   StartMigration -   TestFailover -    elasticbeanstalk    Operation Implemented     CreateApplication (Pro) ‚ú® ‚úÖ   CreateApplicationVersion (Pro) ‚ú® ‚úÖ   DeleteApplication (Pro) ‚ú® ‚úÖ   DeleteApplicationVersion (Pro) ‚ú® ‚úÖ   DeleteEnvironmentConfiguration (Pro) ‚ú® ‚úÖ   DescribeApplicationVersions (Pro) ‚ú® ‚úÖ   DescribeApplications (Pro) ‚ú® ‚úÖ   DescribeEnvironments (Pro) ‚ú® ‚úÖ   UpdateApplication (Pro) ‚ú® ‚úÖ   UpdateApplicationVersion (Pro) ‚ú® ‚úÖ   UpdateEnvironment (Pro) ‚ú® ‚úÖ     Show missing     AbortEnvironmentUpdate -   ApplyEnvironmentManagedAction -   AssociateEnvironmentOperationsRole -   CheckDNSAvailability -   ComposeEnvironments -   CreateConfigurationTemplate -   CreateEnvironment -   CreatePlatformVersion -   CreateStorageLocation -   DeleteConfigurationTemplate -   DeletePlatformVersion -   DescribeAccountAttributes -   DescribeConfigurationOptions -   DescribeConfigurationSettings -   DescribeEnvironmentHealth -   DescribeEnvironmentManagedActionHistory -   DescribeEnvironmentManagedActions -   DescribeEnvironmentResources -   DescribeEvents -   DescribeInstancesHealth -   DescribePlatformVersion -   DisassociateEnvironmentOperationsRole -   ListAvailableSolutionStacks -   ListPlatformBranches -   ListPlatformVersions -   ListTagsForResource -   RebuildEnvironment -   RequestEnvironmentInfo -   RestartAppServer -   RetrieveEnvironmentInfo -   SwapEnvironmentCNAMEs -   TerminateEnvironment -   UpdateApplicationResourceLifecycle -   UpdateConfigurationTemplate -   UpdateTagsForResource -   ValidateConfigurationSettings -    elb    Operation Implemented     AddTags (Pro)  ‚úÖ   ApplySecurityGroupsToLoadBalancer (Pro)  ‚úÖ   ConfigureHealthCheck (Pro)  ‚úÖ   CreateLoadBalancer (Pro)  ‚úÖ   CreateLoadBalancerListeners (Pro)  ‚úÖ   DeleteLoadBalancer (Pro)  ‚úÖ   DescribeLoadBalancerPolicies (Pro)  ‚úÖ   DescribeLoadBalancers (Pro)  ‚úÖ   DescribeTags (Pro)  ‚úÖ   RemoveTags (Pro)  ‚úÖ   SetLoadBalancerListenerSSLCertificate (Pro)  ‚úÖ     Show missing     AttachLoadBalancerToSubnets -   CreateAppCookieStickinessPolicy -   CreateLBCookieStickinessPolicy -   CreateLoadBalancerPolicy -   DeleteLoadBalancerListeners -   DeleteLoadBalancerPolicy -   DeregisterInstancesFromLoadBalancer -   DescribeAccountLimits -   DescribeInstanceHealth -   DescribeLoadBalancerAttributes -   DescribeLoadBalancerPolicyTypes -   DetachLoadBalancerFromSubnets -   DisableAvailabilityZonesForLoadBalancer -   EnableAvailabilityZonesForLoadBalancer -   ModifyLoadBalancerAttributes -   RegisterInstancesWithLoadBalancer -   SetLoadBalancerPoliciesForBackendServer -   SetLoadBalancerPoliciesOfListener -    elbv2    Operation Implemented     AddListenerCertificates (Pro)  ‚úÖ   AddTags (Pro)  ‚úÖ   CreateListener (Pro) ‚ú® ‚úÖ   CreateLoadBalancer (Pro) ‚ú® ‚úÖ   CreateRule (Pro) ‚ú® ‚úÖ   CreateTargetGroup (Pro) ‚ú® ‚úÖ   DeleteListener (Pro)  ‚úÖ   DeleteLoadBalancer (Pro)  ‚úÖ   DeleteRule (Pro)  ‚úÖ   DeleteTargetGroup (Pro)  ‚úÖ   DeregisterTargets (Pro)  ‚úÖ   DescribeAccountLimits (Pro)  ‚úÖ   DescribeListenerCertificates (Pro)  ‚úÖ   DescribeListeners (Pro) ‚ú® ‚úÖ   DescribeLoadBalancerAttributes (Pro)  ‚úÖ   DescribeLoadBalancers (Pro) ‚ú® ‚úÖ   DescribeRules (Pro) ‚ú® ‚úÖ   DescribeSSLPolicies (Pro)  ‚úÖ   DescribeTags (Pro)  ‚úÖ   DescribeTargetGroupAttributes (Pro)  ‚úÖ   DescribeTargetGroups (Pro) ‚ú® ‚úÖ   DescribeTargetHealth (Pro)  ‚úÖ   ModifyListener (Pro)  ‚úÖ   ModifyLoadBalancerAttributes (Pro) ‚ú® ‚úÖ   ModifyRule (Pro)  ‚úÖ   ModifyTargetGroup (Pro)  ‚úÖ   ModifyTargetGroupAttributes (Pro)  ‚úÖ   RegisterTargets (Pro) ‚ú® ‚úÖ   RemoveListenerCertificates (Pro)  ‚úÖ   RemoveTags (Pro)  ‚úÖ   SetIpAddressType (Pro)  ‚úÖ   SetRulePriorities (Pro)  ‚úÖ   SetSecurityGroups (Pro)  ‚úÖ   SetSubnets (Pro)  ‚úÖ    emr    Operation Implemented     AddInstanceFleet (Pro) ‚ú® ‚úÖ   AddTags (Pro)  ‚úÖ   CreateSecurityConfiguration (Pro)  ‚úÖ   DeleteSecurityConfiguration (Pro)  ‚úÖ   DescribeCluster (Pro) ‚ú® ‚úÖ   DescribeJobFlows (Pro)  ‚úÖ   DescribeSecurityConfiguration (Pro)  ‚úÖ   GetAutoTerminationPolicy (Pro) ‚ú® ‚úÖ   ListInstanceFleets (Pro) ‚ú® ‚úÖ   ModifyInstanceFleet (Pro) ‚ú® ‚úÖ   PutAutoScalingPolicy (Pro)  ‚úÖ   PutAutoTerminationPolicy (Pro) ‚ú® ‚úÖ   RemoveAutoScalingPolicy (Pro)  ‚úÖ   RemoveAutoTerminationPolicy (Pro) ‚ú® ‚úÖ   RemoveTags (Pro)  ‚úÖ     Show missing     AddInstanceGroups -   AddJobFlowSteps -   CancelSteps -   CreateStudio -   CreateStudioSessionMapping -   DeleteStudio -   DeleteStudioSessionMapping -   DescribeNotebookExecution -   DescribeReleaseLabel -   DescribeStep -   DescribeStudio -   GetBlockPublicAccessConfiguration -   GetManagedScalingPolicy -   GetStudioSessionMapping -   ListBootstrapActions -   ListClusters -   ListInstanceGroups -   ListInstances -   ListNotebookExecutions -   ListReleaseLabels -   ListSecurityConfigurations -   ListSteps -   ListStudioSessionMappings -   ListStudios -   ModifyCluster -   ModifyInstanceGroups -   PutBlockPublicAccessConfiguration -   PutManagedScalingPolicy -   RemoveManagedScalingPolicy -   RunJobFlow -   SetTerminationProtection -   SetVisibleToAllUsers -   StartNotebookExecution -   StopNotebookExecution -   TerminateJobFlows -   UpdateStudio -   UpdateStudioSessionMapping -    es    Operation Implemented     AddTags ‚ú® ‚úÖ   CreateElasticsearchDomain ‚ú® ‚úÖ   DeleteElasticsearchDomain ‚ú® ‚úÖ   DescribeElasticsearchDomain ‚ú® ‚úÖ   DescribeElasticsearchDomainConfig ‚ú® ‚úÖ   DescribeElasticsearchDomains ‚ú® ‚úÖ   GetCompatibleElasticsearchVersions ‚ú® ‚úÖ   ListDomainNames ‚ú® ‚úÖ   ListElasticsearchVersions ‚ú® ‚úÖ   ListTags ‚ú® ‚úÖ   RemoveTags ‚úÖ   UpdateElasticsearchDomainConfig ‚ú® ‚úÖ     Show missing     AcceptInboundCrossClusterSearchConnection -   AssociatePackage -   CancelElasticsearchServiceSoftwareUpdate -   CreateOutboundCrossClusterSearchConnection -   CreatePackage -   DeleteElasticsearchServiceRole -   DeleteInboundCrossClusterSearchConnection -   DeleteOutboundCrossClusterSearchConnection -   DeletePackage -   DescribeDomainAutoTunes -   DescribeDomainChangeProgress -   DescribeElasticsearchInstanceTypeLimits -   DescribeInboundCrossClusterSearchConnections -   DescribeOutboundCrossClusterSearchConnections -   DescribePackages -   DescribeReservedElasticsearchInstanceOfferings -   DescribeReservedElasticsearchInstances -   DissociatePackage -   GetPackageVersionHistory -   GetUpgradeHistory -   GetUpgradeStatus -   ListDomainsForPackage -   ListElasticsearchInstanceTypes -   ListPackagesForDomain -   PurchaseReservedElasticsearchInstanceOffering -   RejectInboundCrossClusterSearchConnection -   StartElasticsearchServiceSoftwareUpdate -   UpdatePackage -   UpgradeElasticsearchDomain -    events    Operation Implemented     CancelReplay ‚úÖ   CreateApiDestination ‚ú® ‚úÖ   CreateArchive ‚úÖ   CreateConnection ‚ú® ‚úÖ   CreateEventBus ‚ú® ‚úÖ   DeleteApiDestination ‚ú® ‚úÖ   DeleteArchive ‚úÖ   DeleteConnection ‚ú® ‚úÖ   DeleteEventBus ‚ú® ‚úÖ   DescribeApiDestination ‚ú® ‚úÖ   DescribeArchive ‚úÖ   DescribeConnection ‚ú® ‚úÖ   DescribeEventBus ‚ú® ‚úÖ   DescribeReplay ‚úÖ   DescribeRule ‚ú® ‚úÖ   DisableRule ‚ú® ‚úÖ   EnableRule ‚úÖ   ListApiDestinations ‚úÖ   ListArchives ‚úÖ   ListConnections ‚ú® ‚úÖ   ListEventBuses ‚ú® ‚úÖ   ListReplays ‚úÖ   ListRuleNamesByTarget ‚úÖ   ListRules ‚ú® ‚úÖ   ListTagsForResource ‚ú® ‚úÖ   ListTargetsByRule ‚ú® ‚úÖ   PutEvents ‚ú® ‚úÖ   PutPermission ‚ú® ‚úÖ   PutRule ‚ú® ‚úÖ   PutTargets ‚ú® ‚úÖ   RemovePermission ‚ú® ‚úÖ   RemoveTargets ‚ú® ‚úÖ   StartReplay ‚úÖ   TagResource ‚ú® ‚úÖ   TestEventPattern ‚úÖ   UntagResource ‚ú® ‚úÖ   UpdateApiDestination ‚úÖ   UpdateArchive ‚úÖ   UpdateConnection ‚úÖ     Show missing     ActivateEventSource -   CreateEndpoint -   CreatePartnerEventSource -   DeactivateEventSource -   DeauthorizeConnection -   DeleteEndpoint -   DeletePartnerEventSource -   DeleteRule -   DescribeEndpoint -   DescribeEventSource -   DescribePartnerEventSource -   ListEndpoints -   ListEventSources -   ListPartnerEventSourceAccounts -   ListPartnerEventSources -   PutPartnerEvents -   UpdateEndpoint -    firehose    Operation Implemented     CreateDeliveryStream ‚ú® ‚úÖ   DeleteDeliveryStream ‚ú® ‚úÖ   DescribeDeliveryStream ‚ú® ‚úÖ   ListDeliveryStreams ‚ú® ‚úÖ   ListTagsForDeliveryStream ‚ú® ‚úÖ   PutRecord ‚ú® ‚úÖ   PutRecordBatch ‚úÖ   TagDeliveryStream ‚úÖ   UntagDeliveryStream ‚úÖ   UpdateDestination ‚ú® ‚úÖ     Show missing     StartDeliveryStreamEncryption -   StopDeliveryStreamEncryption -    glacier    Operation Implemented     AddTagsToVault (Pro) ‚ú® ‚úÖ   CreateVault (Pro) ‚ú® ‚úÖ   DeleteVaultAccessPolicy (Pro)  ‚úÖ   DeleteVaultNotifications (Pro)  ‚úÖ   GetVaultAccessPolicy (Pro) ‚ú® ‚úÖ   GetVaultNotifications (Pro) ‚ú® ‚úÖ   InitiateJob (Pro) ‚ú® ‚úÖ   ListTagsForVault (Pro) ‚ú® ‚úÖ   ListVaults (Pro) ‚ú® ‚úÖ   RemoveTagsFromVault (Pro)  ‚úÖ   SetVaultAccessPolicy (Pro)  ‚úÖ   SetVaultNotifications (Pro)  ‚úÖ     Show missing     AbortMultipartUpload -   AbortVaultLock -   CompleteMultipartUpload -   CompleteVaultLock -   DeleteArchive -   DeleteVault -   DescribeJob -   DescribeVault -   GetDataRetrievalPolicy -   GetJobOutput -   GetVaultLock -   InitiateMultipartUpload -   InitiateVaultLock -   ListJobs -   ListMultipartUploads -   ListParts -   ListProvisionedCapacity -   PurchaseProvisionedCapacity -   SetDataRetrievalPolicy -   UploadArchive -   UploadMultipartPart -    glue    Operation Implemented     BatchCreatePartition (Pro)  ‚úÖ   BatchDeletePartition (Pro)  ‚úÖ   BatchDeleteTable (Pro)  ‚úÖ   BatchGetPartition (Pro)  ‚úÖ   BatchUpdatePartition (Pro)  ‚úÖ   CheckSchemaVersionValidity (Pro)  ‚úÖ   CreateClassifier (Pro) ‚ú® ‚úÖ   CreateConnection (Pro) ‚ú® ‚úÖ   CreateCrawler (Pro) ‚ú® ‚úÖ   CreateJob (Pro) ‚ú® ‚úÖ   CreatePartition (Pro) ‚ú® ‚úÖ   CreatePartitionIndex (Pro) ‚ú® ‚úÖ   CreateRegistry (Pro) ‚ú® ‚úÖ   CreateSchema (Pro) ‚ú® ‚úÖ   CreateSecurityConfiguration (Pro) ‚ú® ‚úÖ   CreateTable (Pro) ‚ú® ‚úÖ   CreateTrigger (Pro) ‚ú® ‚úÖ   CreateWorkflow (Pro) ‚ú® ‚úÖ   DeleteClassifier (Pro) ‚ú® ‚úÖ   DeleteConnection (Pro) ‚ú® ‚úÖ   DeleteCrawler (Pro) ‚ú® ‚úÖ   DeleteDatabase (Pro) ‚ú® ‚úÖ   DeleteJob (Pro) ‚ú® ‚úÖ   DeletePartition (Pro) ‚ú® ‚úÖ   DeletePartitionIndex (Pro) ‚ú® ‚úÖ   DeleteRegistry (Pro) ‚ú® ‚úÖ   DeleteResourcePolicy (Pro) ‚ú® ‚úÖ   DeleteSchema (Pro) ‚ú® ‚úÖ   DeleteSchemaVersions (Pro) ‚ú® ‚úÖ   DeleteSecurityConfiguration (Pro) ‚ú® ‚úÖ   DeleteTable (Pro) ‚ú® ‚úÖ   DeleteTrigger (Pro) ‚ú® ‚úÖ   DeleteWorkflow (Pro) ‚ú® ‚úÖ   GetCatalogImportStatus (Pro)  ‚úÖ   GetClassifier (Pro) ‚ú® ‚úÖ   GetClassifiers (Pro) ‚ú® ‚úÖ   GetConnection (Pro) ‚ú® ‚úÖ   GetConnections (Pro) ‚ú® ‚úÖ   GetCrawler (Pro) ‚ú® ‚úÖ   GetCrawlers (Pro) ‚ú® ‚úÖ   GetDatabase (Pro) ‚ú® ‚úÖ   GetDatabases (Pro) ‚ú® ‚úÖ   GetJob (Pro) ‚ú® ‚úÖ   GetJobRun (Pro) ‚ú® ‚úÖ   GetJobRuns (Pro) ‚ú® ‚úÖ   GetJobs (Pro) ‚ú® ‚úÖ   GetPartition (Pro) ‚ú® ‚úÖ   GetPartitionIndexes (Pro) ‚ú® ‚úÖ   GetPartitions (Pro) ‚ú® ‚úÖ   GetRegistry (Pro) ‚ú® ‚úÖ   GetResourcePolicy (Pro) ‚ú® ‚úÖ   GetSchema (Pro) ‚ú® ‚úÖ   GetSchemaByDefinition (Pro)  ‚úÖ   GetSchemaVersion (Pro) ‚ú® ‚úÖ   GetSchemaVersionsDiff (Pro)  ‚úÖ   GetSecurityConfiguration (Pro) ‚ú® ‚úÖ   GetSecurityConfigurations (Pro) ‚ú® ‚úÖ   GetTable (Pro) ‚ú® ‚úÖ   GetTableVersion (Pro)  ‚úÖ   GetTableVersions (Pro)  ‚úÖ   GetTables (Pro) ‚ú® ‚úÖ   GetTags (Pro)  ‚úÖ   GetTrigger (Pro) ‚ú® ‚úÖ   GetWorkflow (Pro) ‚ú® ‚úÖ   ImportCatalogToGlue (Pro)  ‚úÖ   ListCrawlers (Pro)  ‚úÖ   ListJobs (Pro) ‚ú® ‚úÖ   ListRegistries (Pro) ‚ú® ‚úÖ   ListSchemaVersions (Pro) ‚ú® ‚úÖ   ListSchemas (Pro) ‚ú® ‚úÖ   ListWorkflows (Pro) ‚ú® ‚úÖ   PutSchemaVersionMetadata (Pro) ‚ú® ‚úÖ   QuerySchemaVersionMetadata (Pro) ‚ú® ‚úÖ   RegisterSchemaVersion (Pro) ‚ú® ‚úÖ   RemoveSchemaVersionMetadata (Pro) ‚ú® ‚úÖ   StartCrawler (Pro) ‚ú® ‚úÖ   StartJobRun (Pro) ‚ú® ‚úÖ   StartTrigger (Pro)  ‚úÖ   StopCrawler (Pro)  ‚úÖ   StopTrigger (Pro)  ‚úÖ   TagResource (Pro)  ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateConnection (Pro)  ‚úÖ   UpdateCrawler (Pro) ‚ú® ‚úÖ   UpdateDatabase (Pro) ‚ú® ‚úÖ   UpdateJob (Pro) ‚ú® ‚úÖ   UpdatePartition (Pro) ‚ú® ‚úÖ   UpdateRegistry (Pro) ‚ú® ‚úÖ   UpdateSchema (Pro) ‚ú® ‚úÖ   UpdateTable (Pro) ‚ú® ‚úÖ   UpdateTrigger (Pro) ‚ú® ‚úÖ   UpdateWorkflow (Pro)  ‚úÖ     Show missing     BatchDeleteConnection -   BatchDeleteTableVersion -   BatchGetBlueprints -   BatchGetCrawlers -   BatchGetCustomEntityTypes -   BatchGetDevEndpoints -   BatchGetJobs -   BatchGetTriggers -   BatchGetWorkflows -   BatchStopJobRun -   CancelMLTaskRun -   CancelStatement -   CreateBlueprint -   CreateCustomEntityType -   CreateDatabase -   CreateDevEndpoint -   CreateMLTransform -   CreateScript -   CreateSession -   CreateUserDefinedFunction -   DeleteBlueprint -   DeleteColumnStatisticsForPartition -   DeleteColumnStatisticsForTable -   DeleteCustomEntityType -   DeleteDevEndpoint -   DeleteMLTransform -   DeleteSession -   DeleteTableVersion -   DeleteUserDefinedFunction -   GetBlueprint -   GetBlueprintRun -   GetBlueprintRuns -   GetColumnStatisticsForPartition -   GetColumnStatisticsForTable -   GetCrawlerMetrics -   GetCustomEntityType -   GetDataCatalogEncryptionSettings -   GetDataflowGraph -   GetDevEndpoint -   GetDevEndpoints -   GetJobBookmark -   GetMLTaskRun -   GetMLTaskRuns -   GetMLTransform -   GetMLTransforms -   GetMapping -   GetPlan -   GetResourcePolicies -   GetSession -   GetStatement -   GetTriggers -   GetUnfilteredPartitionMetadata -   GetUnfilteredPartitionsMetadata -   GetUnfilteredTableMetadata -   GetUserDefinedFunction -   GetUserDefinedFunctions -   GetWorkflowRun -   GetWorkflowRunProperties -   GetWorkflowRuns -   ListBlueprints -   ListCrawls -   ListCustomEntityTypes -   ListDevEndpoints -   ListMLTransforms -   ListSessions -   ListStatements -   ListTriggers -   PutDataCatalogEncryptionSettings -   PutResourcePolicy -   PutWorkflowRunProperties -   ResetJobBookmark -   ResumeWorkflowRun -   RunStatement -   SearchTables -   StartBlueprintRun -   StartCrawlerSchedule -   StartExportLabelsTaskRun -   StartImportLabelsTaskRun -   StartMLEvaluationTaskRun -   StartMLLabelingSetGenerationTaskRun -   StartWorkflowRun -   StopCrawlerSchedule -   StopSession -   StopWorkflowRun -   UpdateBlueprint -   UpdateClassifier -   UpdateColumnStatisticsForPartition -   UpdateColumnStatisticsForTable -   UpdateCrawlerSchedule -   UpdateDevEndpoint -   UpdateMLTransform -   UpdateUserDefinedFunction -    iam    Operation Implemented     AddRoleToInstanceProfile ‚ú® ‚úÖ   AddUserToGroup ‚úÖ   AttachGroupPolicy ‚ú® ‚úÖ   AttachUserPolicy ‚ú® ‚úÖ   CreateAccessKey ‚ú® ‚úÖ   CreateAccountAlias ‚úÖ   CreateGroup ‚ú® ‚úÖ   CreateInstanceProfile ‚ú® ‚úÖ   CreateLoginProfile ‚úÖ   CreateOpenIDConnectProvider ‚úÖ   CreatePolicy ‚ú® ‚úÖ   CreatePolicyVersion ‚úÖ   CreateRole ‚ú® ‚úÖ   CreateSAMLProvider ‚úÖ   CreateServiceLinkedRole ‚ú® ‚úÖ   CreateUser ‚ú® ‚úÖ   CreateVirtualMFADevice (Pro)  ‚úÖ   DeactivateMFADevice ‚úÖ   DeleteAccessKey ‚úÖ   DeleteAccountAlias ‚úÖ   DeleteAccountPasswordPolicy ‚úÖ   DeleteGroup ‚ú® ‚úÖ   DeleteGroupPolicy ‚ú® ‚úÖ   DeleteInstanceProfile ‚ú® ‚úÖ   DeleteLoginProfile ‚úÖ   DeleteOpenIDConnectProvider ‚úÖ   DeletePolicy ‚ú® ‚úÖ   DeletePolicyVersion ‚úÖ   DeleteRole ‚ú® ‚úÖ   DeleteRolePermissionsBoundary ‚úÖ   DeleteRolePolicy ‚ú® ‚úÖ   DeleteSAMLProvider ‚úÖ   DeleteSSHPublicKey ‚úÖ   DeleteServerCertificate ‚úÖ   DeleteServiceLinkedRole ‚ú® ‚úÖ   DeleteSigningCertificate ‚úÖ   DeleteUser ‚ú® ‚úÖ   DeleteUserPolicy ‚ú® ‚úÖ   DeleteVirtualMFADevice ‚úÖ   DetachGroupPolicy ‚ú® ‚úÖ   DetachRolePolicy ‚ú® ‚úÖ   DetachUserPolicy ‚ú® ‚úÖ   EnableMFADevice ‚úÖ   GenerateCredentialReport ‚úÖ   GetAccessKeyLastUsed ‚úÖ   GetAccountAuthorizationDetails ‚ú® ‚úÖ   GetAccountPasswordPolicy ‚úÖ   GetAccountSummary ‚úÖ   GetCredentialReport ‚úÖ   GetGroup ‚ú® ‚úÖ   GetGroupPolicy ‚ú® ‚úÖ   GetInstanceProfile ‚ú® ‚úÖ   GetLoginProfile ‚úÖ   GetOpenIDConnectProvider ‚úÖ   GetPolicy ‚ú® ‚úÖ   GetPolicyVersion ‚ú® ‚úÖ   GetRole ‚ú® ‚úÖ   GetRolePolicy ‚ú® ‚úÖ   GetSAMLProvider ‚úÖ   GetSSHPublicKey ‚úÖ   GetServerCertificate ‚úÖ   GetServiceLinkedRoleDeletionStatus ‚úÖ   GetUser ‚ú® ‚úÖ   GetUserPolicy ‚ú® ‚úÖ   ListAccessKeys ‚úÖ   ListAccountAliases ‚úÖ   ListAttachedGroupPolicies ‚ú® ‚úÖ   ListAttachedRolePolicies ‚ú® ‚úÖ   ListAttachedUserPolicies ‚ú® ‚úÖ   ListEntitiesForPolicy ‚úÖ   ListGroupPolicies ‚ú® ‚úÖ   ListGroups ‚úÖ   ListGroupsForUser ‚úÖ   ListInstanceProfileTags ‚ú® ‚úÖ   ListInstanceProfiles ‚ú® ‚úÖ   ListInstanceProfilesForRole ‚ú® ‚úÖ   ListMFADevices ‚úÖ   ListOpenIDConnectProviderTags ‚úÖ   ListOpenIDConnectProviders ‚úÖ   ListPolicyTags ‚úÖ   ListPolicyVersions ‚ú® ‚úÖ   ListRolePolicies ‚ú® ‚úÖ   ListRoleTags ‚úÖ   ListRoles ‚ú® ‚úÖ   ListSAMLProviders ‚úÖ   ListSSHPublicKeys ‚úÖ   ListServerCertificates ‚úÖ   ListSigningCertificates ‚úÖ   ListUserPolicies ‚ú® ‚úÖ   ListUserTags ‚úÖ   ListUsers ‚úÖ   PutGroupPolicy ‚ú® ‚úÖ   PutRolePermissionsBoundary ‚úÖ   PutRolePolicy ‚ú® ‚úÖ   PutUserPolicy ‚ú® ‚úÖ   RemoveRoleFromInstanceProfile ‚ú® ‚úÖ   RemoveUserFromGroup ‚úÖ   SetDefaultPolicyVersion ‚úÖ   SimulatePrincipalPolicy ‚ú® ‚úÖ   TagInstanceProfile ‚ú® ‚úÖ   TagOpenIDConnectProvider ‚úÖ   TagPolicy ‚úÖ   TagRole ‚úÖ   TagUser ‚úÖ   UntagInstanceProfile ‚ú® ‚úÖ   UntagOpenIDConnectProvider ‚úÖ   UntagPolicy ‚úÖ   UntagRole ‚úÖ   UntagUser ‚úÖ   UpdateAccessKey ‚úÖ   UpdateAccountPasswordPolicy ‚úÖ   UpdateAssumeRolePolicy ‚úÖ   UpdateGroup ‚úÖ   UpdateLoginProfile ‚úÖ   UpdateOpenIDConnectProviderThumbprint ‚úÖ   UpdateRole ‚ú® ‚úÖ   UpdateRoleDescription ‚úÖ   UpdateSAMLProvider ‚úÖ   UpdateSSHPublicKey ‚úÖ   UpdateSigningCertificate ‚úÖ   UpdateUser ‚úÖ   UploadSSHPublicKey ‚úÖ   UploadServerCertificate ‚úÖ   UploadSigningCertificate ‚úÖ     Show missing     AddClientIDToOpenIDConnectProvider -   AttachRolePolicy -   ChangePassword -   CreateServiceSpecificCredential -   DeleteServiceSpecificCredential -   DeleteUserPermissionsBoundary -   GenerateOrganizationsAccessReport -   GenerateServiceLastAccessedDetails -   GetContextKeysForCustomPolicy -   GetContextKeysForPrincipalPolicy -   GetOrganizationsAccessReport -   GetServiceLastAccessedDetails -   GetServiceLastAccessedDetailsWithEntities -   ListMFADeviceTags -   ListPolicies -   ListPoliciesGrantingServiceAccess -   ListSAMLProviderTags -   ListServerCertificateTags -   ListServiceSpecificCredentials -   ListVirtualMFADevices -   PutUserPermissionsBoundary -   RemoveClientIDFromOpenIDConnectProvider -   ResetServiceSpecificCredential -   ResyncMFADevice -   SetSecurityTokenServicePreferences -   SimulateCustomPolicy -   TagMFADevice -   TagSAMLProvider -   TagServerCertificate -   UntagMFADevice -   UntagSAMLProvider -   UntagServerCertificate -   UpdateServerCertificate -   UpdateServiceSpecificCredential -    iot    Operation Implemented     AddThingToThingGroup (Pro) ‚ú® ‚úÖ   AttachPolicy (Pro) ‚ú® ‚úÖ   AttachPrincipalPolicy (Pro)  ‚úÖ   AttachThingPrincipal (Pro) ‚ú® ‚úÖ   CreateCertificateFromCsr (Pro)  ‚úÖ   CreateDomainConfiguration (Pro)  ‚úÖ   CreateDynamicThingGroup (Pro) ‚ú® ‚úÖ   CreateJob (Pro) ‚ú® ‚úÖ   CreateKeysAndCertificate (Pro)  ‚úÖ   CreatePolicy (Pro) ‚ú® ‚úÖ   CreatePolicyVersion (Pro)  ‚úÖ   CreateThing (Pro) ‚ú® ‚úÖ   CreateThingGroup (Pro) ‚ú® ‚úÖ   CreateThingType (Pro)  ‚úÖ   CreateTopicRule (Pro) ‚ú® ‚úÖ   CreateTopicRuleDestination (Pro) ‚ú® ‚úÖ   DeleteCACertificate (Pro)  ‚úÖ   DeleteCertificate (Pro)  ‚úÖ   DeleteDomainConfiguration (Pro)  ‚úÖ   DeleteDynamicThingGroup (Pro) ‚ú® ‚úÖ   DeletePolicy (Pro) ‚ú® ‚úÖ   DeletePolicyVersion (Pro)  ‚úÖ   DeleteThing (Pro) ‚ú® ‚úÖ   DeleteThingGroup (Pro) ‚ú® ‚úÖ   DeleteThingType (Pro)  ‚úÖ   DeleteTopicRule (Pro) ‚ú® ‚úÖ   DeleteTopicRuleDestination (Pro)  ‚úÖ   DeprecateThingType (Pro)  ‚úÖ   DescribeCACertificate (Pro)  ‚úÖ   DescribeCertificate (Pro)  ‚úÖ   DescribeDomainConfiguration (Pro)  ‚úÖ   DescribeEndpoint (Pro) ‚ú® ‚úÖ   DescribeJob (Pro) ‚ú® ‚úÖ   DescribeJobExecution (Pro) ‚ú® ‚úÖ   DescribeThing (Pro) ‚ú® ‚úÖ   DescribeThingGroup (Pro) ‚ú® ‚úÖ   DescribeThingType (Pro)  ‚úÖ   DetachPolicy (Pro)  ‚úÖ   DetachPrincipalPolicy (Pro)  ‚úÖ   DetachThingPrincipal (Pro) ‚ú® ‚úÖ   DisableTopicRule (Pro)  ‚úÖ   EnableTopicRule (Pro)  ‚úÖ   GetPolicy (Pro) ‚ú® ‚úÖ   GetPolicyVersion (Pro)  ‚úÖ   GetRegistrationCode (Pro)  ‚úÖ   GetTopicRule (Pro) ‚ú® ‚úÖ   GetTopicRuleDestination (Pro)  ‚úÖ   ListAttachedPolicies (Pro)  ‚úÖ   ListCertificates (Pro)  ‚úÖ   ListCertificatesByCA (Pro)  ‚úÖ   ListDomainConfigurations (Pro)  ‚úÖ   ListJobExecutionsForThing (Pro) ‚ú® ‚úÖ   ListJobs (Pro) ‚ú® ‚úÖ   ListPolicies (Pro) ‚ú® ‚úÖ   ListPolicyPrincipals (Pro)  ‚úÖ   ListPolicyVersions (Pro)  ‚úÖ   ListPrincipalPolicies (Pro)  ‚úÖ   ListPrincipalThings (Pro)  ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   ListThingGroups (Pro) ‚ú® ‚úÖ   ListThingGroupsForThing (Pro) ‚ú® ‚úÖ   ListThingPrincipals (Pro) ‚ú® ‚úÖ   ListThings (Pro) ‚ú® ‚úÖ   ListThingsInThingGroup (Pro) ‚ú® ‚úÖ   ListTopicRules (Pro) ‚ú® ‚úÖ   RegisterCACertificate (Pro)  ‚úÖ   RegisterCertificate (Pro) ‚ú® ‚úÖ   RegisterCertificateWithoutCA (Pro)  ‚úÖ   RemoveThingFromThingGroup (Pro) ‚ú® ‚úÖ   ReplaceTopicRule (Pro)  ‚úÖ   SearchIndex (Pro) ‚ú® ‚úÖ   SetDefaultPolicyVersion (Pro)  ‚úÖ   TagResource (Pro) ‚ú® ‚úÖ   UpdateCACertificate (Pro)  ‚úÖ   UpdateCertificate (Pro)  ‚úÖ   UpdateDomainConfiguration (Pro)  ‚úÖ   UpdateDynamicThingGroup (Pro) ‚ú® ‚úÖ   UpdateIndexingConfiguration (Pro) ‚ú® ‚úÖ   UpdateThing (Pro)  ‚úÖ   UpdateThingGroup (Pro)  ‚úÖ   UpdateThingGroupsForThing (Pro)  ‚úÖ     Show missing     AcceptCertificateTransfer -   AddThingToBillingGroup -   AssociateTargetsWithJob -   AttachSecurityProfile -   CancelAuditMitigationActionsTask -   CancelAuditTask -   CancelCertificateTransfer -   CancelDetectMitigationActionsTask -   CancelJob -   CancelJobExecution -   ClearDefaultAuthorizer -   ConfirmTopicRuleDestination -   CreateAuditSuppression -   CreateAuthorizer -   CreateBillingGroup -   CreateCustomMetric -   CreateDimension -   CreateFleetMetric -   CreateJobTemplate -   CreateMitigationAction -   CreateOTAUpdate -   CreateProvisioningClaim -   CreateProvisioningTemplate -   CreateProvisioningTemplateVersion -   CreateRoleAlias -   CreateScheduledAudit -   CreateSecurityProfile -   CreateStream -   DeleteAccountAuditConfiguration -   DeleteAuditSuppression -   DeleteAuthorizer -   DeleteBillingGroup -   DeleteCustomMetric -   DeleteDimension -   DeleteFleetMetric -   DeleteJob -   DeleteJobExecution -   DeleteJobTemplate -   DeleteMitigationAction -   DeleteOTAUpdate -   DeleteProvisioningTemplate -   DeleteProvisioningTemplateVersion -   DeleteRegistrationCode -   DeleteRoleAlias -   DeleteScheduledAudit -   DeleteSecurityProfile -   DeleteStream -   DeleteV2LoggingLevel -   DescribeAccountAuditConfiguration -   DescribeAuditFinding -   DescribeAuditMitigationActionsTask -   DescribeAuditSuppression -   DescribeAuditTask -   DescribeAuthorizer -   DescribeBillingGroup -   DescribeCustomMetric -   DescribeDefaultAuthorizer -   DescribeDetectMitigationActionsTask -   DescribeDimension -   DescribeEventConfigurations -   DescribeFleetMetric -   DescribeIndex -   DescribeJobTemplate -   DescribeManagedJobTemplate -   DescribeMitigationAction -   DescribeProvisioningTemplate -   DescribeProvisioningTemplateVersion -   DescribeRoleAlias -   DescribeScheduledAudit -   DescribeSecurityProfile -   DescribeStream -   DescribeThingRegistrationTask -   DetachSecurityProfile -   GetBehaviorModelTrainingSummaries -   GetBucketsAggregation -   GetCardinality -   GetEffectivePolicies -   GetIndexingConfiguration -   GetJobDocument -   GetLoggingOptions -   GetOTAUpdate -   GetPercentiles -   GetStatistics -   GetV2LoggingOptions -   ListActiveViolations -   ListAuditFindings -   ListAuditMitigationActionsExecutions -   ListAuditMitigationActionsTasks -   ListAuditSuppressions -   ListAuditTasks -   ListAuthorizers -   ListBillingGroups -   ListCACertificates -   ListCustomMetrics -   ListDetectMitigationActionsExecutions -   ListDetectMitigationActionsTasks -   ListDimensions -   ListFleetMetrics -   ListIndices -   ListJobExecutionsForJob -   ListJobTemplates -   ListManagedJobTemplates -   ListMetricValues -   ListMitigationActions -   ListOTAUpdates -   ListOutgoingCertificates -   ListProvisioningTemplateVersions -   ListProvisioningTemplates -   ListRoleAliases -   ListScheduledAudits -   ListSecurityProfiles -   ListSecurityProfilesForTarget -   ListStreams -   ListTargetsForPolicy -   ListTargetsForSecurityProfile -   ListThingRegistrationTaskReports -   ListThingRegistrationTasks -   ListThingTypes -   ListThingsInBillingGroup -   ListTopicRuleDestinations -   ListV2LoggingLevels -   ListViolationEvents -   PutVerificationStateOnViolation -   RegisterThing -   RejectCertificateTransfer -   RemoveThingFromBillingGroup -   SetDefaultAuthorizer -   SetLoggingOptions -   SetV2LoggingLevel -   SetV2LoggingOptions -   StartAuditMitigationActionsTask -   StartDetectMitigationActionsTask -   StartOnDemandAuditTask -   StartThingRegistrationTask -   StopThingRegistrationTask -   TestAuthorization -   TestInvokeAuthorizer -   TransferCertificate -   UntagResource -   UpdateAccountAuditConfiguration -   UpdateAuditSuppression -   UpdateAuthorizer -   UpdateBillingGroup -   UpdateCustomMetric -   UpdateDimension -   UpdateEventConfigurations -   UpdateFleetMetric -   UpdateJob -   UpdateMitigationAction -   UpdateProvisioningTemplate -   UpdateRoleAlias -   UpdateScheduledAudit -   UpdateSecurityProfile -   UpdateStream -   UpdateTopicRuleDestination -   ValidateSecurityProfileBehaviors -    iot-data    Operation Implemented     DeleteThingShadow (Pro)  ‚úÖ   GetThingShadow (Pro) ‚ú® ‚úÖ   Publish (Pro) ‚ú® ‚úÖ     Show missing     GetRetainedMessage -   ListNamedShadowsForThing -   ListRetainedMessages -   UpdateThingShadow -    iotanalytics    Operation Implemented     CreateChannel (Pro) ‚ú® ‚úÖ   CreateDataset (Pro) ‚ú® ‚úÖ   CreateDatastore (Pro) ‚ú® ‚úÖ   CreatePipeline (Pro) ‚ú® ‚úÖ   DeleteChannel (Pro) ‚ú® ‚úÖ   DeleteDataset (Pro) ‚ú® ‚úÖ   DeleteDatastore (Pro) ‚ú® ‚úÖ   DeletePipeline (Pro) ‚ú® ‚úÖ   DescribeChannel (Pro) ‚ú® ‚úÖ   DescribeDataset (Pro) ‚ú® ‚úÖ   DescribePipeline (Pro) ‚ú® ‚úÖ   ListChannels (Pro) ‚ú® ‚úÖ   ListDatasets (Pro) ‚ú® ‚úÖ   ListDatastores (Pro) ‚ú® ‚úÖ   ListPipelines (Pro) ‚ú® ‚úÖ     Show missing     BatchPutMessage -   CancelPipelineReprocessing -   CreateDatasetContent -   DeleteDatasetContent -   DescribeDatastore -   DescribeLoggingOptions -   GetDatasetContent -   ListDatasetContents -   ListTagsForResource -   PutLoggingOptions -   RunPipelineActivity -   SampleChannelData -   StartPipelineReprocessing -   TagResource -   UntagResource -   UpdateChannel -   UpdateDataset -   UpdateDatastore -   UpdatePipeline -    iotwireless    Operation Implemented     CreateDeviceProfile (Pro) ‚ú® ‚úÖ   CreateWirelessDevice (Pro) ‚ú® ‚úÖ   CreateWirelessGateway (Pro) ‚ú® ‚úÖ   DeleteDeviceProfile (Pro) ‚ú® ‚úÖ   DeleteWirelessDevice (Pro) ‚ú® ‚úÖ   DeleteWirelessGateway (Pro) ‚ú® ‚úÖ   GetDeviceProfile (Pro) ‚ú® ‚úÖ   GetWirelessDevice (Pro) ‚ú® ‚úÖ   GetWirelessGateway (Pro) ‚ú® ‚úÖ   ListDeviceProfiles (Pro) ‚ú® ‚úÖ   ListWirelessGateways (Pro) ‚ú® ‚úÖ   UpdateWirelessDevice (Pro)  ‚úÖ   UpdateWirelessGateway (Pro)  ‚úÖ     Show missing     AssociateAwsAccountWithPartnerAccount -   AssociateMulticastGroupWithFuotaTask -   AssociateWirelessDeviceWithFuotaTask -   AssociateWirelessDeviceWithMulticastGroup -   AssociateWirelessDeviceWithThing -   AssociateWirelessGatewayWithCertificate -   AssociateWirelessGatewayWithThing -   CancelMulticastGroupSession -   CreateDestination -   CreateFuotaTask -   CreateMulticastGroup -   CreateNetworkAnalyzerConfiguration -   CreateServiceProfile -   CreateWirelessGatewayTask -   CreateWirelessGatewayTaskDefinition -   DeleteDestination -   DeleteFuotaTask -   DeleteMulticastGroup -   DeleteNetworkAnalyzerConfiguration -   DeleteQueuedMessages -   DeleteServiceProfile -   DeleteWirelessGatewayTask -   DeleteWirelessGatewayTaskDefinition -   DisassociateAwsAccountFromPartnerAccount -   DisassociateMulticastGroupFromFuotaTask -   DisassociateWirelessDeviceFromFuotaTask -   DisassociateWirelessDeviceFromMulticastGroup -   DisassociateWirelessDeviceFromThing -   DisassociateWirelessGatewayFromCertificate -   DisassociateWirelessGatewayFromThing -   GetDestination -   GetEventConfigurationByResourceTypes -   GetFuotaTask -   GetLogLevelsByResourceTypes -   GetMulticastGroup -   GetMulticastGroupSession -   GetNetworkAnalyzerConfiguration -   GetPartnerAccount -   GetResourceEventConfiguration -   GetResourceLogLevel -   GetServiceEndpoint -   GetServiceProfile -   GetWirelessDeviceStatistics -   GetWirelessGatewayCertificate -   GetWirelessGatewayFirmwareInformation -   GetWirelessGatewayStatistics -   GetWirelessGatewayTask -   GetWirelessGatewayTaskDefinition -   ListDestinations -   ListEventConfigurations -   ListFuotaTasks -   ListMulticastGroups -   ListMulticastGroupsByFuotaTask -   ListNetworkAnalyzerConfigurations -   ListPartnerAccounts -   ListQueuedMessages -   ListServiceProfiles -   ListTagsForResource -   ListWirelessDevices -   ListWirelessGatewayTaskDefinitions -   PutResourceLogLevel -   ResetAllResourceLogLevels -   ResetResourceLogLevel -   SendDataToMulticastGroup -   SendDataToWirelessDevice -   StartBulkAssociateWirelessDeviceWithMulticastGroup -   StartBulkDisassociateWirelessDeviceFromMulticastGroup -   StartFuotaTask -   StartMulticastGroupSession -   TagResource -   TestWirelessDevice -   UntagResource -   UpdateDestination -   UpdateEventConfigurationByResourceTypes -   UpdateFuotaTask -   UpdateLogLevelsByResourceTypes -   UpdateMulticastGroup -   UpdateNetworkAnalyzerConfiguration -   UpdatePartnerAccount -   UpdateResourceEventConfiguration -    kafka    Operation Implemented     CreateCluster (Pro) ‚ú® ‚úÖ   CreateConfiguration (Pro) ‚ú® ‚úÖ   DeleteCluster (Pro) ‚ú® ‚úÖ   DeleteConfiguration (Pro) ‚ú® ‚úÖ   DescribeCluster (Pro) ‚ú® ‚úÖ   DescribeClusterOperation (Pro)  ‚úÖ   DescribeConfiguration (Pro) ‚ú® ‚úÖ   DescribeConfigurationRevision (Pro) ‚ú® ‚úÖ   GetBootstrapBrokers (Pro) ‚ú® ‚úÖ   ListClusters (Pro) ‚ú® ‚úÖ   ListConfigurationRevisions (Pro) ‚ú® ‚úÖ   ListConfigurations (Pro) ‚ú® ‚úÖ   ListNodes (Pro) ‚ú® ‚úÖ   UpdateClusterConfiguration (Pro)  ‚úÖ   UpdateClusterKafkaVersion (Pro)  ‚úÖ   UpdateConfiguration (Pro) ‚ú® ‚úÖ     Show missing     BatchAssociateScramSecret -   BatchDisassociateScramSecret -   CreateClusterV2 -   DescribeClusterV2 -   GetCompatibleKafkaVersions -   ListClusterOperations -   ListClustersV2 -   ListKafkaVersions -   ListScramSecrets -   ListTagsForResource -   RebootBroker -   TagResource -   UntagResource -   UpdateBrokerCount -   UpdateBrokerStorage -   UpdateBrokerType -   UpdateConnectivity -   UpdateMonitoring -   UpdateSecurity -    kinesis    Operation Implemented     AddTagsToStream ‚úÖ   CreateStream ‚ú® ‚úÖ   DecreaseStreamRetentionPeriod ‚úÖ   DeleteStream ‚ú® ‚úÖ   DeregisterStreamConsumer ‚ú® ‚úÖ   DescribeLimits ‚úÖ   DescribeStream ‚ú® ‚úÖ   DescribeStreamConsumer ‚ú® ‚úÖ   DescribeStreamSummary ‚ú® ‚úÖ   DisableEnhancedMonitoring ‚úÖ   EnableEnhancedMonitoring ‚úÖ   GetRecords ‚ú® ‚úÖ   GetShardIterator ‚ú® ‚úÖ   IncreaseStreamRetentionPeriod ‚úÖ   ListShards ‚ú® ‚úÖ   ListStreamConsumers ‚ú® ‚úÖ   ListStreams ‚ú® ‚úÖ   ListTagsForStream ‚úÖ   MergeShards ‚úÖ   PutRecord ‚ú® ‚úÖ   PutRecords ‚ú® ‚úÖ   RegisterStreamConsumer ‚ú® ‚úÖ   RemoveTagsFromStream ‚úÖ   SplitShard ‚úÖ   StartStreamEncryption ‚úÖ   StopStreamEncryption ‚úÖ   UpdateShardCount ‚úÖ   UpdateStreamMode ‚úÖ     Show missing     SubscribeToShard -    kinesisanalytics    Operation Implemented     AddApplicationInputProcessingConfiguration (Pro) ‚ú® ‚úÖ   AddApplicationOutput (Pro) ‚ú® ‚úÖ   CreateApplication (Pro) ‚ú® ‚úÖ   DeleteApplication (Pro) ‚ú® ‚úÖ   DeleteApplicationInputProcessingConfiguration (Pro) ‚ú® ‚úÖ   DescribeApplication (Pro) ‚ú® ‚úÖ   ListApplications (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   TagResource (Pro) ‚ú® ‚úÖ   UntagResource (Pro) ‚ú® ‚úÖ   UpdateApplication (Pro) ‚ú® ‚úÖ     Show missing     AddApplicationCloudWatchLoggingOption -   AddApplicationInput -   AddApplicationReferenceDataSource -   DeleteApplicationCloudWatchLoggingOption -   DeleteApplicationOutput -   DeleteApplicationReferenceDataSource -   DiscoverInputSchema -   StartApplication -   StopApplication -    kinesisanalyticsv2    Operation Implemented     AddApplicationInputProcessingConfiguration (Pro) ‚ú® ‚úÖ   AddApplicationOutput (Pro) ‚ú® ‚úÖ   CreateApplication (Pro) ‚ú® ‚úÖ   DeleteApplication (Pro) ‚ú® ‚úÖ   DescribeApplication (Pro) ‚ú® ‚úÖ   ListApplications (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   TagResource (Pro) ‚ú® ‚úÖ   UntagResource (Pro) ‚ú® ‚úÖ   UpdateApplication (Pro) ‚ú® ‚úÖ     Show missing     AddApplicationCloudWatchLoggingOption -   AddApplicationInput -   AddApplicationReferenceDataSource -   AddApplicationVpcConfiguration -   CreateApplicationPresignedUrl -   CreateApplicationSnapshot -   DeleteApplicationCloudWatchLoggingOption -   DeleteApplicationInputProcessingConfiguration -   DeleteApplicationOutput -   DeleteApplicationReferenceDataSource -   DeleteApplicationSnapshot -   DeleteApplicationVpcConfiguration -   DescribeApplicationSnapshot -   DescribeApplicationVersion -   DiscoverInputSchema -   ListApplicationSnapshots -   ListApplicationVersions -   RollbackApplication -   StartApplication -   StopApplication -   UpdateApplicationMaintenanceConfiguration -    kms    Operation Implemented     CancelKeyDeletion ‚úÖ   CreateAlias ‚ú® ‚úÖ   CreateGrant ‚ú® ‚úÖ   CreateKey ‚ú® ‚úÖ   Decrypt ‚ú® ‚úÖ   DeleteAlias ‚ú® ‚úÖ   DescribeKey ‚ú® ‚úÖ   DisableKey ‚ú® ‚úÖ   DisableKeyRotation ‚ú® ‚úÖ   EnableKey ‚ú® ‚úÖ   EnableKeyRotation ‚úÖ   Encrypt ‚ú® ‚úÖ   GenerateDataKey ‚ú® ‚úÖ   GenerateDataKeyWithoutPlaintext ‚úÖ   GenerateRandom ‚úÖ   GetKeyPolicy ‚ú® ‚úÖ   GetKeyRotationStatus ‚ú® ‚úÖ   GetParametersForImport ‚ú® ‚úÖ   GetPublicKey ‚ú® ‚úÖ   ImportKeyMaterial ‚ú® ‚úÖ   ListAliases ‚ú® ‚úÖ   ListGrants ‚ú® ‚úÖ   ListKeyPolicies ‚úÖ   ListKeys ‚ú® ‚úÖ   ListResourceTags ‚ú® ‚úÖ   ListRetirableGrants ‚úÖ   PutKeyPolicy ‚úÖ   ReEncrypt ‚úÖ   ScheduleKeyDeletion ‚ú® ‚úÖ   Sign ‚ú® ‚úÖ   TagResource ‚úÖ   UntagResource ‚úÖ   UpdateAlias ‚úÖ   UpdateKeyDescription ‚úÖ     Show missing     ConnectCustomKeyStore -   CreateCustomKeyStore -   DeleteCustomKeyStore -   DeleteImportedKeyMaterial -   DescribeCustomKeyStores -   DisconnectCustomKeyStore -   GenerateDataKeyPair -   GenerateDataKeyPairWithoutPlaintext -   GenerateMac -   ReplicateKey -   RetireGrant -   RevokeGrant -   UpdateCustomKeyStore -   UpdatePrimaryRegion -   Verify -   VerifyMac -    lakeformation    Operation Implemented     DeregisterResource (Pro)  ‚úÖ   DescribeResource (Pro)  ‚úÖ   GetDataLakeSettings (Pro)  ‚úÖ   GrantPermissions (Pro) ‚ú® ‚úÖ   ListPermissions (Pro) ‚ú® ‚úÖ   ListResources (Pro)  ‚úÖ   PutDataLakeSettings (Pro)  ‚úÖ   RegisterResource (Pro)  ‚úÖ   RevokePermissions (Pro)  ‚úÖ     Show missing     AddLFTagsToResource -   BatchGrantPermissions -   BatchRevokePermissions -   CancelTransaction -   CommitTransaction -   CreateDataCellsFilter -   CreateLFTag -   DeleteDataCellsFilter -   DeleteLFTag -   DeleteObjectsOnCancel -   DescribeTransaction -   ExtendTransaction -   GetEffectivePermissionsForPath -   GetLFTag -   GetQueryState -   GetQueryStatistics -   GetResourceLFTags -   GetTableObjects -   GetTemporaryGluePartitionCredentials -   GetTemporaryGlueTableCredentials -   GetWorkUnitResults -   GetWorkUnits -   ListDataCellsFilter -   ListLFTags -   ListTableStorageOptimizers -   ListTransactions -   RemoveLFTagsFromResource -   SearchDatabasesByLFTags -   SearchTablesByLFTags -   StartQueryPlanning -   StartTransaction -   UpdateLFTag -   UpdateResource -   UpdateTableObjects -   UpdateTableStorageOptimizer -    lambda    Operation Implemented     AddLayerVersionPermission (Pro)  ‚úÖ   AddPermission ‚ú® ‚úÖ   CreateAlias ‚ú® ‚úÖ   CreateCodeSigningConfig ‚ú® ‚úÖ   CreateEventSourceMapping ‚ú® ‚úÖ   CreateFunction ‚ú® ‚úÖ   DeleteAlias ‚úÖ   DeleteCodeSigningConfig ‚ú® ‚úÖ   DeleteEventSourceMapping ‚ú® ‚úÖ   DeleteFunction ‚ú® ‚úÖ   DeleteFunctionCodeSigningConfig ‚ú® ‚úÖ   DeleteFunctionConcurrency ‚ú® ‚úÖ   DeleteFunctionEventInvokeConfig ‚ú® ‚úÖ   DeleteLayerVersion (Pro) ‚ú® ‚úÖ   GetAlias ‚úÖ   GetCodeSigningConfig ‚ú® ‚úÖ   GetEventSourceMapping ‚ú® ‚úÖ   GetFunction ‚ú® ‚úÖ   GetFunctionCodeSigningConfig ‚ú® ‚úÖ   GetFunctionConcurrency ‚ú® ‚úÖ   GetFunctionConfiguration ‚ú® ‚úÖ   GetFunctionEventInvokeConfig ‚ú® ‚úÖ   GetLayerVersion (Pro) ‚ú® ‚úÖ   GetLayerVersionByArn (Pro)  ‚úÖ   GetLayerVersionPolicy (Pro)  ‚úÖ   GetPolicy ‚ú® ‚úÖ   Invoke ‚ú® ‚úÖ   ListAliases ‚ú® ‚úÖ   ListCodeSigningConfigs ‚úÖ   ListEventSourceMappings ‚ú® ‚úÖ   ListFunctions ‚ú® ‚úÖ   ListLayerVersions (Pro) ‚ú® ‚úÖ   ListLayers (Pro) ‚ú® ‚úÖ   ListTags ‚úÖ   ListVersionsByFunction ‚ú® ‚úÖ   PublishLayerVersion (Pro) ‚ú® ‚úÖ   PublishVersion ‚úÖ   PutFunctionCodeSigningConfig ‚ú® ‚úÖ   PutFunctionConcurrency ‚ú® ‚úÖ   PutFunctionEventInvokeConfig ‚ú® ‚úÖ   RemovePermission ‚ú® ‚úÖ   TagResource ‚úÖ   UntagResource ‚úÖ   UpdateAlias ‚úÖ   UpdateCodeSigningConfig ‚ú® ‚úÖ   UpdateEventSourceMapping ‚ú® ‚úÖ   UpdateFunctionCode ‚ú® ‚úÖ   UpdateFunctionConfiguration ‚ú® ‚úÖ   UpdateFunctionEventInvokeConfig ‚ú® ‚úÖ     Show missing     CreateFunctionUrlConfig -   DeleteFunctionUrlConfig -   DeleteProvisionedConcurrencyConfig -   GetAccountSettings -   GetFunctionUrlConfig -   GetProvisionedConcurrencyConfig -   InvokeAsync -   ListFunctionEventInvokeConfigs -   ListFunctionUrlConfigs -   ListFunctionsByCodeSigningConfig -   ListProvisionedConcurrencyConfigs -   PutProvisionedConcurrencyConfig -   RemoveLayerVersionPermission -   UpdateFunctionUrlConfig -    logs    Operation Implemented     CreateExportTask ‚úÖ   CreateLogGroup ‚ú® ‚úÖ   CreateLogStream ‚ú® ‚úÖ   DeleteLogGroup ‚ú® ‚úÖ   DeleteLogStream ‚ú® ‚úÖ   DeleteMetricFilter ‚ú® ‚úÖ   DeleteResourcePolicy ‚úÖ   DeleteRetentionPolicy ‚úÖ   DeleteSubscriptionFilter ‚ú® ‚úÖ   DescribeLogGroups ‚ú® ‚úÖ   DescribeLogStreams ‚ú® ‚úÖ   DescribeMetricFilters ‚ú® ‚úÖ   DescribeResourcePolicies ‚úÖ   DescribeSubscriptionFilters ‚ú® ‚úÖ   FilterLogEvents ‚ú® ‚úÖ   GetLogEvents ‚ú® ‚úÖ   ListTagsLogGroup ‚ú® ‚úÖ   PutLogEvents ‚ú® ‚úÖ   PutMetricFilter ‚ú® ‚úÖ   PutResourcePolicy ‚ú® ‚úÖ   PutRetentionPolicy ‚úÖ   PutSubscriptionFilter ‚ú® ‚úÖ   StartQuery ‚úÖ   TagLogGroup ‚úÖ   UntagLogGroup ‚úÖ     Show missing     AssociateKmsKey -   CancelExportTask -   DeleteDestination -   DeleteQueryDefinition -   DescribeDestinations -   DescribeExportTasks -   DescribeQueries -   DescribeQueryDefinitions -   DisassociateKmsKey -   GetLogGroupFields -   GetLogRecord -   GetQueryResults -   PutDestination -   PutDestinationPolicy -   PutQueryDefinition -   StopQuery -   TestMetricFilter -    mediastore    Operation Implemented     CreateContainer (Pro) ‚ú® ‚úÖ   DeleteContainer (Pro) ‚ú® ‚úÖ   DescribeContainer (Pro) ‚ú® ‚úÖ   ListContainers (Pro) ‚ú® ‚úÖ     Show missing     DeleteContainerPolicy -   DeleteCorsPolicy -   DeleteLifecyclePolicy -   DeleteMetricPolicy -   GetContainerPolicy -   GetCorsPolicy -   GetLifecyclePolicy -   GetMetricPolicy -   ListTagsForResource -   PutContainerPolicy -   PutCorsPolicy -   PutLifecyclePolicy -   PutMetricPolicy -   StartAccessLogging -   StopAccessLogging -   TagResource -   UntagResource -    mediastore-data    Operation Implemented     DescribeObject ‚ú® ‚úÖ     Show missing     DeleteObject -   GetObject -   ListItems -   PutObject -    mwaa    Operation Implemented     CreateEnvironment (Pro)  ‚úÖ   DeleteEnvironment (Pro)  ‚úÖ   GetEnvironment (Pro)  ‚úÖ   ListEnvironments (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro)  ‚úÖ   TagResource (Pro)  ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateEnvironment (Pro)  ‚úÖ     Show missing     CreateCliToken -   CreateWebLoginToken -   PublishMetrics -    neptune    Operation Implemented     CopyDBClusterSnapshot (Pro)  ‚úÖ   CreateDBCluster (Pro)  ‚úÖ   CreateDBClusterEndpoint (Pro)  ‚úÖ   CreateDBClusterParameterGroup (Pro)  ‚úÖ   CreateDBClusterSnapshot (Pro)  ‚úÖ   CreateDBInstance (Pro)  ‚úÖ   CreateDBParameterGroup (Pro)  ‚úÖ   CreateDBSubnetGroup (Pro)  ‚úÖ   CreateEventSubscription (Pro)  ‚úÖ   DeleteDBCluster (Pro)  ‚úÖ   DeleteDBClusterEndpoint (Pro)  ‚úÖ   DeleteDBClusterParameterGroup (Pro)  ‚úÖ   DeleteDBClusterSnapshot (Pro)  ‚úÖ   DeleteDBInstance (Pro)  ‚úÖ   DeleteDBParameterGroup (Pro)  ‚úÖ   DeleteDBSubnetGroup (Pro)  ‚úÖ   DeleteEventSubscription (Pro)  ‚úÖ   DescribeDBClusterEndpoints (Pro)  ‚úÖ   DescribeDBClusterParameterGroups (Pro)  ‚úÖ   DescribeDBClusterParameters (Pro)  ‚úÖ   DescribeDBClusterSnapshots (Pro)  ‚úÖ   DescribeDBClusters (Pro)  ‚úÖ   DescribeDBEngineVersions (Pro)  ‚úÖ   DescribeDBInstances (Pro)  ‚úÖ   DescribeDBParameterGroups (Pro)  ‚úÖ   DescribeDBParameters (Pro)  ‚úÖ   DescribeDBSubnetGroups (Pro)  ‚úÖ   DescribeEventSubscriptions (Pro)  ‚úÖ   DescribeGlobalClusters (Pro)  ‚úÖ   ModifyDBCluster (Pro)  ‚úÖ   ModifyDBClusterEndpoint (Pro)  ‚úÖ   ModifyDBClusterParameterGroup (Pro)  ‚úÖ   ModifyDBInstance (Pro)  ‚úÖ   ModifyDBParameterGroup (Pro)  ‚úÖ   ModifyDBSubnetGroup (Pro)  ‚úÖ   RebootDBInstance (Pro)  ‚úÖ   ResetDBClusterParameterGroup (Pro)  ‚úÖ   StartDBCluster (Pro)  ‚úÖ   StopDBCluster (Pro)  ‚úÖ     Show missing     AddRoleToDBCluster -   AddSourceIdentifierToSubscription -   AddTagsToResource -   ApplyPendingMaintenanceAction -   CopyDBClusterParameterGroup -   CopyDBParameterGroup -   CreateGlobalCluster -   DeleteGlobalCluster -   DescribeDBClusterSnapshotAttributes -   DescribeEngineDefaultClusterParameters -   DescribeEngineDefaultParameters -   DescribeEventCategories -   DescribeEvents -   DescribeOrderableDBInstanceOptions -   DescribePendingMaintenanceActions -   DescribeValidDBInstanceModifications -   FailoverDBCluster -   FailoverGlobalCluster -   ListTagsForResource -   ModifyDBClusterSnapshotAttribute -   ModifyEventSubscription -   ModifyGlobalCluster -   PromoteReadReplicaDBCluster -   RemoveFromGlobalCluster -   RemoveRoleFromDBCluster -   RemoveSourceIdentifierFromSubscription -   RemoveTagsFromResource -   ResetDBParameterGroup -   RestoreDBClusterFromSnapshot -   RestoreDBClusterToPointInTime -    opensearch    Operation Implemented     CreateDomain ‚ú® ‚úÖ   DeleteDomain ‚ú® ‚úÖ   DescribeDomain ‚ú® ‚úÖ   DescribeDomainConfig ‚ú® ‚úÖ   DescribeDomains ‚ú® ‚úÖ   GetCompatibleVersions ‚ú® ‚úÖ   ListDomainNames ‚ú® ‚úÖ   ListVersions ‚ú® ‚úÖ   UpdateDomainConfig ‚ú® ‚úÖ     Show missing     AcceptInboundConnection -   AddTags -   AssociatePackage -   CancelServiceSoftwareUpdate -   CreateOutboundConnection -   CreatePackage -   DeleteInboundConnection -   DeleteOutboundConnection -   DeletePackage -   DescribeDomainAutoTunes -   DescribeDomainChangeProgress -   DescribeInboundConnections -   DescribeInstanceTypeLimits -   DescribeOutboundConnections -   DescribePackages -   DescribeReservedInstanceOfferings -   DescribeReservedInstances -   DissociatePackage -   GetPackageVersionHistory -   GetUpgradeHistory -   GetUpgradeStatus -   ListDomainsForPackage -   ListInstanceTypeDetails -   ListPackagesForDomain -   ListTags -   PurchaseReservedInstanceOffering -   RejectInboundConnection -   RemoveTags -   StartServiceSoftwareUpdate -   UpdatePackage -   UpgradeDomain -    organizations    Operation Implemented     AttachPolicy (Pro)  ‚úÖ   CloseAccount (Pro)  ‚úÖ   CreateAccount (Pro) ‚ú® ‚úÖ   CreateOrganization (Pro) ‚ú® ‚úÖ   CreateOrganizationalUnit (Pro)  ‚úÖ   CreatePolicy (Pro)  ‚úÖ   DeleteOrganization (Pro) ‚ú® ‚úÖ   DeletePolicy (Pro)  ‚úÖ   DeregisterDelegatedAdministrator (Pro)  ‚úÖ   DescribeAccount (Pro) ‚ú® ‚úÖ   DescribeCreateAccountStatus (Pro)  ‚úÖ   DescribeOrganization (Pro) ‚ú® ‚úÖ   DescribeOrganizationalUnit (Pro)  ‚úÖ   DescribePolicy (Pro)  ‚úÖ   DetachPolicy (Pro)  ‚úÖ   DisableAWSServiceAccess (Pro)  ‚úÖ   DisablePolicyType (Pro)  ‚úÖ   EnableAWSServiceAccess (Pro)  ‚úÖ   EnablePolicyType (Pro)  ‚úÖ   ListAWSServiceAccessForOrganization (Pro)  ‚úÖ   ListAccounts (Pro)  ‚úÖ   ListAccountsForParent (Pro)  ‚úÖ   ListChildren (Pro)  ‚úÖ   ListDelegatedAdministrators (Pro)  ‚úÖ   ListDelegatedServicesForAccount (Pro)  ‚úÖ   ListOrganizationalUnitsForParent (Pro)  ‚úÖ   ListParents (Pro)  ‚úÖ   ListPolicies (Pro)  ‚úÖ   ListPoliciesForTarget (Pro)  ‚úÖ   ListRoots (Pro)  ‚úÖ   ListTagsForResource (Pro)  ‚úÖ   ListTargetsForPolicy (Pro)  ‚úÖ   MoveAccount (Pro)  ‚úÖ   RegisterDelegatedAdministrator (Pro)  ‚úÖ   RemoveAccountFromOrganization (Pro)  ‚úÖ   TagResource (Pro)  ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateOrganizationalUnit (Pro)  ‚úÖ   UpdatePolicy (Pro)  ‚úÖ     Show missing     AcceptHandshake -   CancelHandshake -   CreateGovCloudAccount -   DeclineHandshake -   DeleteOrganizationalUnit -   DescribeEffectivePolicy -   DescribeHandshake -   EnableAllFeatures -   InviteAccountToOrganization -   LeaveOrganization -   ListCreateAccountStatus -   ListHandshakesForAccount -   ListHandshakesForOrganization -    qldb    Operation Implemented     CreateLedger (Pro) ‚ú® ‚úÖ   DeleteLedger (Pro) ‚ú® ‚úÖ   DescribeJournalKinesisStream (Pro)  ‚úÖ   DescribeLedger (Pro) ‚ú® ‚úÖ   ListLedgers (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   TagResource (Pro)  ‚úÖ   UntagResource (Pro)  ‚úÖ   UpdateLedger (Pro) ‚ú® ‚úÖ     Show missing     CancelJournalKinesisStream -   DescribeJournalS3Export -   ExportJournalToS3 -   GetBlock -   GetDigest -   GetRevision -   ListJournalKinesisStreamsForLedger -   ListJournalS3Exports -   ListJournalS3ExportsForLedger -   StreamJournalToKinesis -   UpdateLedgerPermissionsMode -    qldb-session    Operation Implemented     SendCommand (Pro) ‚ú® ‚úÖ    rds    Operation Implemented     AuthorizeDBSecurityGroupIngress (Pro)  ‚úÖ   CancelExportTask (Pro)  ‚úÖ   CopyDBClusterSnapshot (Pro)  ‚úÖ   CopyDBSnapshot (Pro)  ‚úÖ   CreateDBCluster (Pro) ‚ú® ‚úÖ   CreateDBClusterEndpoint (Pro) ‚ú® ‚úÖ   CreateDBClusterParameterGroup (Pro) ‚ú® ‚úÖ   CreateDBClusterSnapshot (Pro) ‚ú® ‚úÖ   CreateDBInstance (Pro) ‚ú® ‚úÖ   CreateDBInstanceReadReplica (Pro)  ‚úÖ   CreateDBParameterGroup (Pro) ‚ú® ‚úÖ   CreateDBProxy (Pro) ‚ú® ‚úÖ   CreateDBSecurityGroup (Pro)  ‚úÖ   CreateDBSnapshot (Pro) ‚ú® ‚úÖ   CreateDBSubnetGroup (Pro) ‚ú® ‚úÖ   CreateEventSubscription (Pro)  ‚úÖ   CreateOptionGroup (Pro)  ‚úÖ   DeleteDBCluster (Pro) ‚ú® ‚úÖ   DeleteDBClusterEndpoint (Pro) ‚ú® ‚úÖ   DeleteDBClusterParameterGroup (Pro) ‚ú® ‚úÖ   DeleteDBClusterSnapshot (Pro) ‚ú® ‚úÖ   DeleteDBInstance (Pro) ‚ú® ‚úÖ   DeleteDBParameterGroup (Pro) ‚ú® ‚úÖ   DeleteDBProxy (Pro) ‚ú® ‚úÖ   DeleteDBSecurityGroup (Pro)  ‚úÖ   DeleteDBSnapshot (Pro)  ‚úÖ   DeleteDBSubnetGroup (Pro) ‚ú® ‚úÖ   DeleteEventSubscription (Pro)  ‚úÖ   DeleteOptionGroup (Pro)  ‚úÖ   DeregisterDBProxyTargets (Pro) ‚ú® ‚úÖ   DescribeCertificates (Pro)  ‚úÖ   DescribeDBClusterEndpoints (Pro) ‚ú® ‚úÖ   DescribeDBClusterParameterGroups (Pro) ‚ú® ‚úÖ   DescribeDBClusterParameters (Pro) ‚ú® ‚úÖ   DescribeDBClusterSnapshots (Pro) ‚ú® ‚úÖ   DescribeDBClusters (Pro) ‚ú® ‚úÖ   DescribeDBEngineVersions (Pro) ‚ú® ‚úÖ   DescribeDBInstances (Pro) ‚ú® ‚úÖ   DescribeDBParameterGroups (Pro) ‚ú® ‚úÖ   DescribeDBParameters (Pro) ‚ú® ‚úÖ   DescribeDBProxies (Pro) ‚ú® ‚úÖ   DescribeDBProxyTargets (Pro) ‚ú® ‚úÖ   DescribeDBSecurityGroups (Pro)  ‚úÖ   DescribeDBSnapshots (Pro) ‚ú® ‚úÖ   DescribeDBSubnetGroups (Pro) ‚ú® ‚úÖ   DescribeEventSubscriptions (Pro)  ‚úÖ   DescribeExportTasks (Pro)  ‚úÖ   DescribeGlobalClusters (Pro)  ‚úÖ   DescribeOptionGroupOptions (Pro)  ‚úÖ   DescribeOptionGroups (Pro)  ‚úÖ   ModifyCertificates (Pro)  ‚úÖ   ModifyCurrentDBClusterCapacity (Pro)  ‚úÖ   ModifyDBCluster (Pro) ‚ú® ‚úÖ   ModifyDBClusterEndpoint (Pro) ‚ú® ‚úÖ   ModifyDBClusterParameterGroup (Pro) ‚ú® ‚úÖ   ModifyDBInstance (Pro) ‚ú® ‚úÖ   ModifyDBParameterGroup (Pro) ‚ú® ‚úÖ   ModifyDBSubnetGroup (Pro)  ‚úÖ   ModifyOptionGroup (Pro)  ‚úÖ   RebootDBInstance (Pro)  ‚úÖ   RegisterDBProxyTargets (Pro) ‚ú® ‚úÖ   ResetDBClusterParameterGroup (Pro)  ‚úÖ   StartDBCluster (Pro)  ‚úÖ   StartDBInstance (Pro)  ‚úÖ   StopDBCluster (Pro)  ‚úÖ   StopDBInstance (Pro)  ‚úÖ     Show missing     AddRoleToDBCluster -   AddRoleToDBInstance -   AddSourceIdentifierToSubscription -   AddTagsToResource -   ApplyPendingMaintenanceAction -   BacktrackDBCluster -   CopyDBClusterParameterGroup -   CopyDBParameterGroup -   CopyOptionGroup -   CreateCustomDBEngineVersion -   CreateDBProxyEndpoint -   CreateGlobalCluster -   DeleteCustomDBEngineVersion -   DeleteDBInstanceAutomatedBackup -   DeleteDBProxyEndpoint -   DeleteGlobalCluster -   DescribeAccountAttributes -   DescribeDBClusterBacktracks -   DescribeDBClusterSnapshotAttributes -   DescribeDBInstanceAutomatedBackups -   DescribeDBLogFiles -   DescribeDBProxyEndpoints -   DescribeDBProxyTargetGroups -   DescribeDBSnapshotAttributes -   DescribeEngineDefaultClusterParameters -   DescribeEngineDefaultParameters -   DescribeEventCategories -   DescribeEvents -   DescribeOrderableDBInstanceOptions -   DescribePendingMaintenanceActions -   DescribeReservedDBInstances -   DescribeReservedDBInstancesOfferings -   DescribeSourceRegions -   DescribeValidDBInstanceModifications -   DownloadDBLogFilePortion -   FailoverDBCluster -   FailoverGlobalCluster -   ListTagsForResource -   ModifyCustomDBEngineVersion -   ModifyDBClusterSnapshotAttribute -   ModifyDBProxy -   ModifyDBProxyEndpoint -   ModifyDBProxyTargetGroup -   ModifyDBSnapshot -   ModifyDBSnapshotAttribute -   ModifyEventSubscription -   ModifyGlobalCluster -   PromoteReadReplica -   PromoteReadReplicaDBCluster -   PurchaseReservedDBInstancesOffering -   RebootDBCluster -   RemoveFromGlobalCluster -   RemoveRoleFromDBCluster -   RemoveRoleFromDBInstance -   RemoveSourceIdentifierFromSubscription -   RemoveTagsFromResource -   ResetDBParameterGroup -   RestoreDBClusterFromS3 -   RestoreDBClusterFromSnapshot -   RestoreDBClusterToPointInTime -   RestoreDBInstanceFromDBSnapshot -   RestoreDBInstanceFromS3 -   RestoreDBInstanceToPointInTime -   RevokeDBSecurityGroupIngress -   StartActivityStream -   StartDBInstanceAutomatedBackupsReplication -   StartExportTask -   StopActivityStream -   StopDBInstanceAutomatedBackupsReplication -    rds-data    Operation Implemented     BeginTransaction (Pro) ‚ú® ‚úÖ   CommitTransaction (Pro) ‚ú® ‚úÖ   ExecuteSql (Pro) ‚ú® ‚úÖ   ExecuteStatement (Pro) ‚ú® ‚úÖ     Show missing     BatchExecuteStatement -   RollbackTransaction -    redshift    Operation Implemented     AuthorizeClusterSecurityGroupIngress ‚úÖ   CreateCluster ‚ú® ‚úÖ   CreateClusterParameterGroup ‚ú® ‚úÖ   CreateClusterSecurityGroup ‚úÖ   CreateClusterSnapshot ‚úÖ   CreateClusterSubnetGroup ‚úÖ   CreateSnapshotCopyGrant ‚úÖ   CreateTags ‚úÖ   DeleteCluster ‚ú® ‚úÖ   DeleteClusterParameterGroup ‚úÖ   DeleteClusterSecurityGroup ‚úÖ   DeleteClusterSnapshot ‚úÖ   DeleteClusterSubnetGroup ‚úÖ   DeleteSnapshotCopyGrant ‚úÖ   DeleteTags ‚úÖ   DescribeClusterParameterGroups ‚ú® ‚úÖ   DescribeClusterParameters (Pro) ‚ú® ‚úÖ   DescribeClusterSecurityGroups ‚úÖ   DescribeClusterSnapshots ‚úÖ   DescribeClusterSubnetGroups ‚úÖ   DescribeClusters ‚ú® ‚úÖ   DescribeDefaultClusterParameters (Pro) ‚ú® ‚úÖ   DescribeSnapshotCopyGrants ‚úÖ   DescribeTags ‚úÖ   GetClusterCredentials ‚úÖ   ModifyCluster ‚úÖ   PauseCluster ‚úÖ   RestoreFromClusterSnapshot ‚úÖ   ResumeCluster ‚úÖ     Show missing     AcceptReservedNodeExchange -   AddPartner -   AssociateDataShareConsumer -   AuthorizeDataShare -   AuthorizeEndpointAccess -   AuthorizeSnapshotAccess -   BatchDeleteClusterSnapshots -   BatchModifyClusterSnapshots -   CancelResize -   CopyClusterSnapshot -   CreateAuthenticationProfile -   CreateEndpointAccess -   CreateEventSubscription -   CreateHsmClientCertificate -   CreateHsmConfiguration -   CreateScheduledAction -   CreateSnapshotSchedule -   CreateUsageLimit -   DeauthorizeDataShare -   DeleteAuthenticationProfile -   DeleteEndpointAccess -   DeleteEventSubscription -   DeleteHsmClientCertificate -   DeleteHsmConfiguration -   DeletePartner -   DeleteScheduledAction -   DeleteSnapshotSchedule -   DeleteUsageLimit -   DescribeAccountAttributes -   DescribeAuthenticationProfiles -   DescribeClusterDbRevisions -   DescribeClusterTracks -   DescribeClusterVersions -   DescribeDataShares -   DescribeDataSharesForConsumer -   DescribeDataSharesForProducer -   DescribeEndpointAccess -   DescribeEndpointAuthorization -   DescribeEventCategories -   DescribeEventSubscriptions -   DescribeEvents -   DescribeHsmClientCertificates -   DescribeHsmConfigurations -   DescribeLoggingStatus -   DescribeNodeConfigurationOptions -   DescribeOrderableClusterOptions -   DescribePartners -   DescribeReservedNodeExchangeStatus -   DescribeReservedNodeOfferings -   DescribeReservedNodes -   DescribeResize -   DescribeScheduledActions -   DescribeSnapshotSchedules -   DescribeStorage -   DescribeTableRestoreStatus -   DescribeUsageLimits -   DisableLogging -   DisableSnapshotCopy -   DisassociateDataShareConsumer -   EnableLogging -   EnableSnapshotCopy -   GetClusterCredentialsWithIAM -   GetReservedNodeExchangeConfigurationOptions -   GetReservedNodeExchangeOfferings -   ModifyAquaConfiguration -   ModifyAuthenticationProfile -   ModifyClusterDbRevision -   ModifyClusterIamRoles -   ModifyClusterMaintenance -   ModifyClusterParameterGroup -   ModifyClusterSnapshot -   ModifyClusterSnapshotSchedule -   ModifyClusterSubnetGroup -   ModifyEndpointAccess -   ModifyEventSubscription -   ModifyScheduledAction -   ModifySnapshotCopyRetentionPeriod -   ModifySnapshotSchedule -   ModifyUsageLimit -   PurchaseReservedNodeOffering -   RebootCluster -   RejectDataShare -   ResetClusterParameterGroup -   ResizeCluster -   RestoreTableFromClusterSnapshot -   RevokeClusterSecurityGroupIngress -   RevokeEndpointAccess -   RevokeSnapshotAccess -   RotateEncryptionKey -   UpdatePartnerStatus -    redshift-data    Operation Implemented     DescribeStatement (Pro) ‚ú® ‚úÖ   ExecuteStatement (Pro) ‚ú® ‚úÖ   GetStatementResult (Pro) ‚ú® ‚úÖ     Show missing     BatchExecuteStatement -   CancelStatement -   DescribeTable -   ListDatabases -   ListSchemas -   ListStatements -   ListTables -    resource-groups    Operation Implemented     ListGroups ‚ú® ‚úÖ     Show missing     CreateGroup -   DeleteGroup -   GetGroup -   GetGroupConfiguration -   GetGroupQuery -   GetTags -   GroupResources -   ListGroupResources -   PutGroupConfiguration -   SearchResources -   Tag -   UngroupResources -   Untag -   UpdateGroup -   UpdateGroupQuery -    resourcegroupstaggingapi    Operation Implemented     GetResources ‚ú® ‚úÖ   GetTagKeys ‚úÖ   GetTagValues ‚úÖ     Show missing     DescribeReportCreation -   GetComplianceSummary -   StartReportCreation -   TagResources -   UntagResources -    route53    Operation Implemented     AssociateVPCWithHostedZone ‚ú® ‚úÖ   ChangeResourceRecordSets ‚ú® ‚úÖ   ChangeTagsForResource ‚ú® ‚úÖ   CreateHealthCheck ‚ú® ‚úÖ   CreateHostedZone ‚ú® ‚úÖ   CreateQueryLoggingConfig ‚úÖ   CreateReusableDelegationSet ‚ú® ‚úÖ   DeleteHealthCheck ‚ú® ‚úÖ   DeleteHostedZone ‚ú® ‚úÖ   DeleteQueryLoggingConfig ‚úÖ   DeleteReusableDelegationSet ‚ú® ‚úÖ   DisassociateVPCFromHostedZone ‚ú® ‚úÖ   GetChange ‚ú® ‚úÖ   GetDNSSEC ‚úÖ   GetHealthCheck ‚ú® ‚úÖ   GetHostedZone ‚ú® ‚úÖ   GetHostedZoneCount ‚úÖ   GetQueryLoggingConfig ‚úÖ   GetReusableDelegationSet ‚ú® ‚úÖ   ListHealthChecks ‚úÖ   ListHostedZones ‚ú® ‚úÖ   ListHostedZonesByName ‚ú® ‚úÖ   ListHostedZonesByVPC ‚ú® ‚úÖ   ListQueryLoggingConfigs ‚úÖ   ListResourceRecordSets ‚ú® ‚úÖ   ListReusableDelegationSets ‚ú® ‚úÖ   ListTagsForResource ‚ú® ‚úÖ   UpdateHealthCheck ‚úÖ   UpdateHostedZoneComment ‚úÖ     Show missing     ActivateKeySigningKey -   ChangeCidrCollection -   CreateCidrCollection -   CreateKeySigningKey -   CreateTrafficPolicy -   CreateTrafficPolicyInstance -   CreateTrafficPolicyVersion -   CreateVPCAssociationAuthorization -   DeactivateKeySigningKey -   DeleteCidrCollection -   DeleteKeySigningKey -   DeleteTrafficPolicy -   DeleteTrafficPolicyInstance -   DeleteVPCAssociationAuthorization -   DisableHostedZoneDNSSEC -   EnableHostedZoneDNSSEC -   GetAccountLimit -   GetCheckerIpRanges -   GetGeoLocation -   GetHealthCheckCount -   GetHealthCheckLastFailureReason -   GetHealthCheckStatus -   GetHostedZoneLimit -   GetReusableDelegationSetLimit -   GetTrafficPolicy -   GetTrafficPolicyInstance -   GetTrafficPolicyInstanceCount -   ListCidrBlocks -   ListCidrCollections -   ListCidrLocations -   ListGeoLocations -   ListTagsForResources -   ListTrafficPolicies -   ListTrafficPolicyInstances -   ListTrafficPolicyInstancesByHostedZone -   ListTrafficPolicyInstancesByPolicy -   ListTrafficPolicyVersions -   ListVPCAssociationAuthorizations -   TestDNSAnswer -   UpdateTrafficPolicyComment -   UpdateTrafficPolicyInstance -    route53resolver    Operation Implemented     AssociateResolverRule ‚úÖ   CreateFirewallDomainList ‚úÖ   CreateFirewallRule ‚úÖ   CreateFirewallRuleGroup ‚úÖ   CreateResolverEndpoint ‚ú® ‚úÖ   CreateResolverRule ‚úÖ   DeleteFirewallDomainList ‚úÖ   DeleteFirewallRule ‚úÖ   DeleteFirewallRuleGroup ‚úÖ   DeleteResolverEndpoint ‚úÖ   DeleteResolverRule ‚úÖ   DisassociateResolverRule ‚úÖ   GetFirewallDomainList ‚úÖ   GetFirewallRuleGroup ‚úÖ   GetResolverEndpoint ‚úÖ   GetResolverRule ‚úÖ   GetResolverRuleAssociation ‚úÖ   ListFirewallDomains ‚úÖ   ListFirewallRuleGroups ‚úÖ   ListFirewallRules ‚úÖ   ListResolverEndpointIpAddresses ‚úÖ   ListResolverEndpoints ‚úÖ   ListResolverRuleAssociations ‚úÖ   ListResolverRules ‚úÖ   ListTagsForResource ‚úÖ   TagResource ‚úÖ   UntagResource ‚úÖ   UpdateFirewallDomains ‚úÖ   UpdateFirewallRule ‚úÖ   UpdateResolverEndpoint ‚úÖ     Show missing     AssociateFirewallRuleGroup -   AssociateResolverEndpointIpAddress -   AssociateResolverQueryLogConfig -   CreateResolverQueryLogConfig -   DeleteResolverQueryLogConfig -   DisassociateFirewallRuleGroup -   DisassociateResolverEndpointIpAddress -   DisassociateResolverQueryLogConfig -   GetFirewallConfig -   GetFirewallRuleGroupAssociation -   GetFirewallRuleGroupPolicy -   GetResolverConfig -   GetResolverDnssecConfig -   GetResolverQueryLogConfig -   GetResolverQueryLogConfigAssociation -   GetResolverQueryLogConfigPolicy -   GetResolverRulePolicy -   ImportFirewallDomains -   ListFirewallConfigs -   ListFirewallDomainLists -   ListFirewallRuleGroupAssociations -   ListResolverConfigs -   ListResolverDnssecConfigs -   ListResolverQueryLogConfigAssociations -   ListResolverQueryLogConfigs -   PutFirewallRuleGroupPolicy -   PutResolverQueryLogConfigPolicy -   PutResolverRulePolicy -   UpdateFirewallConfig -   UpdateFirewallRuleGroupAssociation -   UpdateResolverConfig -   UpdateResolverDnssecConfig -   UpdateResolverRule -    s3    Operation Implemented     AbortMultipartUpload ‚úÖ   CompleteMultipartUpload ‚ú® ‚úÖ   CopyObject ‚ú® ‚úÖ   CreateBucket ‚ú® ‚úÖ   CreateMultipartUpload ‚ú® ‚úÖ   DeleteBucket ‚ú® ‚úÖ   DeleteBucketAnalyticsConfiguration ‚úÖ   DeleteBucketEncryption ‚úÖ   DeleteBucketIntelligentTieringConfiguration ‚úÖ   DeleteBucketInventoryConfiguration ‚úÖ   DeleteBucketLifecycle ‚ú® ‚úÖ   DeleteBucketMetricsConfiguration ‚úÖ   DeleteBucketOwnershipControls ‚úÖ   DeleteBucketPolicy ‚ú® ‚úÖ   DeleteBucketReplication ‚úÖ   DeleteBucketTagging ‚úÖ   DeleteBucketWebsite ‚úÖ   DeleteObject ‚ú® ‚úÖ   DeleteObjectTagging ‚ú® ‚úÖ   DeleteObjects ‚ú® ‚úÖ   DeletePublicAccessBlock ‚úÖ   GetBucketAccelerateConfiguration ‚ú® ‚úÖ   GetBucketAcl ‚ú® ‚úÖ   GetBucketAnalyticsConfiguration ‚úÖ   GetBucketEncryption ‚ú® ‚úÖ   GetBucketIntelligentTieringConfiguration ‚úÖ   GetBucketInventoryConfiguration ‚úÖ   GetBucketLifecycle (Pro)  ‚úÖ   GetBucketLifecycleConfiguration ‚ú® ‚úÖ   GetBucketLocation ‚ú® ‚úÖ   GetBucketLogging ‚ú® ‚úÖ   GetBucketMetricsConfiguration ‚úÖ   GetBucketNotification ‚úÖ   GetBucketNotificationConfiguration ‚ú® ‚úÖ   GetBucketOwnershipControls ‚úÖ   GetBucketPolicy ‚ú® ‚úÖ   GetBucketPolicyStatus ‚úÖ   GetBucketTagging ‚ú® ‚úÖ   GetBucketVersioning ‚ú® ‚úÖ   GetBucketWebsite ‚ú® ‚úÖ   GetObject ‚ú® ‚úÖ   GetObjectAcl ‚ú® ‚úÖ   GetObjectAttributes ‚úÖ   GetObjectLegalHold ‚úÖ   GetObjectLockConfiguration ‚ú® ‚úÖ   GetObjectRetention ‚úÖ   GetObjectTagging ‚úÖ   GetObjectTorrent ‚úÖ   GetPublicAccessBlock ‚ú® ‚úÖ   ListBucketAnalyticsConfigurations ‚úÖ   ListBucketIntelligentTieringConfigurations ‚úÖ   ListBucketInventoryConfigurations ‚úÖ   ListBucketMetricsConfigurations ‚úÖ   ListBuckets ‚ú® ‚úÖ   ListMultipartUploads ‚úÖ   ListObjectVersions ‚ú® ‚úÖ   ListObjects ‚ú® ‚úÖ   ListObjectsV2 ‚ú® ‚úÖ   ListParts ‚úÖ   PutBucketAccelerateConfiguration ‚úÖ   PutBucketAcl ‚úÖ   PutBucketAnalyticsConfiguration ‚úÖ   PutBucketCors ‚ú® ‚úÖ   PutBucketEncryption ‚úÖ   PutBucketIntelligentTieringConfiguration ‚úÖ   PutBucketInventoryConfiguration ‚úÖ   PutBucketLifecycle ‚úÖ   PutBucketLifecycleConfiguration ‚ú® ‚úÖ   PutBucketLogging ‚úÖ   PutBucketMetricsConfiguration ‚úÖ   PutBucketNotification ‚úÖ   PutBucketNotificationConfiguration ‚ú® ‚úÖ   PutBucketOwnershipControls ‚úÖ   PutBucketPolicy ‚ú® ‚úÖ   PutBucketReplication ‚úÖ   PutBucketRequestPayment ‚ú® ‚úÖ   PutBucketTagging ‚ú® ‚úÖ   PutBucketVersioning ‚ú® ‚úÖ   PutBucketWebsite ‚ú® ‚úÖ   PutObject ‚ú® ‚úÖ   PutObjectAcl ‚ú® ‚úÖ   PutObjectLegalHold ‚úÖ   PutObjectLockConfiguration ‚úÖ   PutObjectRetention ‚úÖ   PutObjectTagging ‚ú® ‚úÖ   PutPublicAccessBlock ‚úÖ   RestoreObject ‚ú® ‚úÖ   SelectObjectContent ‚ú® ‚úÖ   UploadPart ‚ú® ‚úÖ   UploadPartCopy ‚úÖ   WriteGetObjectResponse ‚úÖ     Show missing     DeleteBucketCors -   GetBucketCors -   GetBucketReplication -   GetBucketRequestPayment -   HeadBucket -   HeadObject -    s3control    Operation Implemented     CreateAccessPoint ‚úÖ   CreateBucket ‚úÖ   CreateJob ‚úÖ   DeleteAccessPoint ‚úÖ   DeleteAccessPointPolicy ‚úÖ   DeletePublicAccessBlock ‚ú® ‚úÖ   GetAccessPoint ‚úÖ   GetAccessPointPolicy ‚úÖ   GetAccessPointPolicyStatus ‚úÖ   GetPublicAccessBlock ‚ú® ‚úÖ   ListRegionalBuckets ‚úÖ   PutAccessPointPolicy ‚úÖ   PutPublicAccessBlock ‚ú® ‚úÖ   PutStorageLensConfiguration ‚úÖ     Show missing     CreateAccessPointForObjectLambda -   CreateMultiRegionAccessPoint -   DeleteAccessPointForObjectLambda -   DeleteAccessPointPolicyForObjectLambda -   DeleteBucket -   DeleteBucketLifecycleConfiguration -   DeleteBucketPolicy -   DeleteBucketTagging -   DeleteJobTagging -   DeleteMultiRegionAccessPoint -   DeleteStorageLensConfiguration -   DeleteStorageLensConfigurationTagging -   DescribeJob -   DescribeMultiRegionAccessPointOperation -   GetAccessPointConfigurationForObjectLambda -   GetAccessPointForObjectLambda -   GetAccessPointPolicyForObjectLambda -   GetAccessPointPolicyStatusForObjectLambda -   GetBucket -   GetBucketLifecycleConfiguration -   GetBucketPolicy -   GetBucketTagging -   GetJobTagging -   GetMultiRegionAccessPoint -   GetMultiRegionAccessPointPolicy -   GetMultiRegionAccessPointPolicyStatus -   GetStorageLensConfiguration -   GetStorageLensConfigurationTagging -   ListAccessPoints -   ListAccessPointsForObjectLambda -   ListJobs -   ListMultiRegionAccessPoints -   ListStorageLensConfigurations -   PutAccessPointConfigurationForObjectLambda -   PutAccessPointPolicyForObjectLambda -   PutBucketLifecycleConfiguration -   PutBucketPolicy -   PutBucketTagging -   PutJobTagging -   PutMultiRegionAccessPointPolicy -   PutStorageLensConfigurationTagging -   UpdateJobPriority -   UpdateJobStatus -    sagemaker    Operation Implemented     AssociateTrialComponent (Pro)  ‚úÖ   CreateEndpoint (Pro)  ‚úÖ   CreateEndpointConfig (Pro)  ‚úÖ   CreateExperiment (Pro)  ‚úÖ   CreateModel (Pro) ‚ú® ‚úÖ   CreateNotebookInstance (Pro)  ‚úÖ   CreateNotebookInstanceLifecycleConfig (Pro)  ‚úÖ   CreateProcessingJob (Pro)  ‚úÖ   CreateTrainingJob (Pro)  ‚úÖ   CreateTrial (Pro)  ‚úÖ   CreateTrialComponent (Pro)  ‚úÖ   DeleteEndpoint (Pro)  ‚úÖ   DeleteEndpointConfig (Pro)  ‚úÖ   DeleteExperiment (Pro)  ‚úÖ   DeleteModel (Pro)  ‚úÖ   DeleteNotebookInstance (Pro)  ‚úÖ   DeleteNotebookInstanceLifecycleConfig (Pro)  ‚úÖ   DeleteTrial (Pro)  ‚úÖ   DeleteTrialComponent (Pro)  ‚úÖ   DescribeEndpoint (Pro)  ‚úÖ   DescribeEndpointConfig (Pro)  ‚úÖ   DescribeModel (Pro) ‚ú® ‚úÖ   DescribeNotebookInstance (Pro)  ‚úÖ   DescribeNotebookInstanceLifecycleConfig (Pro)  ‚úÖ   DescribeProcessingJob (Pro)  ‚úÖ   DescribeTrainingJob (Pro)  ‚úÖ   DescribeTrial (Pro)  ‚úÖ   DescribeTrialComponent (Pro)  ‚úÖ   DisassociateTrialComponent (Pro)  ‚úÖ   ListExperiments (Pro)  ‚úÖ   ListProcessingJobs (Pro)  ‚úÖ   ListTags (Pro)  ‚úÖ   ListTrainingJobs (Pro)  ‚úÖ   ListTrialComponents (Pro)  ‚úÖ   ListTrials (Pro)  ‚úÖ   Search (Pro)  ‚úÖ   StartNotebookInstance (Pro)  ‚úÖ   StopNotebookInstance (Pro)  ‚úÖ   UpdateEndpointWeightsAndCapacities (Pro)  ‚úÖ     Show missing     AddAssociation -   AddTags -   BatchDescribeModelPackage -   CreateAction -   CreateAlgorithm -   CreateApp -   CreateAppImageConfig -   CreateArtifact -   CreateAutoMLJob -   CreateCodeRepository -   CreateCompilationJob -   CreateContext -   CreateDataQualityJobDefinition -   CreateDeviceFleet -   CreateDomain -   CreateEdgePackagingJob -   CreateFeatureGroup -   CreateFlowDefinition -   CreateHumanTaskUi -   CreateHyperParameterTuningJob -   CreateImage -   CreateImageVersion -   CreateInferenceRecommendationsJob -   CreateLabelingJob -   CreateModelBiasJobDefinition -   CreateModelExplainabilityJobDefinition -   CreateModelPackage -   CreateModelPackageGroup -   CreateModelQualityJobDefinition -   CreateMonitoringSchedule -   CreatePipeline -   CreatePresignedDomainUrl -   CreatePresignedNotebookInstanceUrl -   CreateProject -   CreateStudioLifecycleConfig -   CreateTransformJob -   CreateUserProfile -   CreateWorkforce -   CreateWorkteam -   DeleteAction -   DeleteAlgorithm -   DeleteApp -   DeleteAppImageConfig -   DeleteArtifact -   DeleteAssociation -   DeleteCodeRepository -   DeleteContext -   DeleteDataQualityJobDefinition -   DeleteDeviceFleet -   DeleteDomain -   DeleteFeatureGroup -   DeleteFlowDefinition -   DeleteHumanTaskUi -   DeleteImage -   DeleteImageVersion -   DeleteModelBiasJobDefinition -   DeleteModelExplainabilityJobDefinition -   DeleteModelPackage -   DeleteModelPackageGroup -   DeleteModelPackageGroupPolicy -   DeleteModelQualityJobDefinition -   DeleteMonitoringSchedule -   DeletePipeline -   DeleteProject -   DeleteStudioLifecycleConfig -   DeleteTags -   DeleteUserProfile -   DeleteWorkforce -   DeleteWorkteam -   DeregisterDevices -   DescribeAction -   DescribeAlgorithm -   DescribeApp -   DescribeAppImageConfig -   DescribeArtifact -   DescribeAutoMLJob -   DescribeCodeRepository -   DescribeCompilationJob -   DescribeContext -   DescribeDataQualityJobDefinition -   DescribeDevice -   DescribeDeviceFleet -   DescribeDomain -   DescribeEdgePackagingJob -   DescribeExperiment -   DescribeFeatureGroup -   DescribeFeatureMetadata -   DescribeFlowDefinition -   DescribeHumanTaskUi -   DescribeHyperParameterTuningJob -   DescribeImage -   DescribeImageVersion -   DescribeInferenceRecommendationsJob -   DescribeLabelingJob -   DescribeLineageGroup -   DescribeModelBiasJobDefinition -   DescribeModelExplainabilityJobDefinition -   DescribeModelPackage -   DescribeModelPackageGroup -   DescribeModelQualityJobDefinition -   DescribeMonitoringSchedule -   DescribePipeline -   DescribePipelineDefinitionForExecution -   DescribePipelineExecution -   DescribeProject -   DescribeStudioLifecycleConfig -   DescribeSubscribedWorkteam -   DescribeTransformJob -   DescribeUserProfile -   DescribeWorkforce -   DescribeWorkteam -   DisableSagemakerServicecatalogPortfolio -   EnableSagemakerServicecatalogPortfolio -   GetDeviceFleetReport -   GetLineageGroupPolicy -   GetModelPackageGroupPolicy -   GetSagemakerServicecatalogPortfolioStatus -   GetSearchSuggestions -   ListActions -   ListAlgorithms -   ListAppImageConfigs -   ListApps -   ListArtifacts -   ListAssociations -   ListAutoMLJobs -   ListCandidatesForAutoMLJob -   ListCodeRepositories -   ListCompilationJobs -   ListContexts -   ListDataQualityJobDefinitions -   ListDeviceFleets -   ListDevices -   ListDomains -   ListEdgePackagingJobs -   ListEndpointConfigs -   ListEndpoints -   ListFeatureGroups -   ListFlowDefinitions -   ListHumanTaskUis -   ListHyperParameterTuningJobs -   ListImageVersions -   ListImages -   ListInferenceRecommendationsJobs -   ListLabelingJobs -   ListLabelingJobsForWorkteam -   ListLineageGroups -   ListModelBiasJobDefinitions -   ListModelExplainabilityJobDefinitions -   ListModelMetadata -   ListModelPackageGroups -   ListModelPackages -   ListModelQualityJobDefinitions -   ListModels -   ListMonitoringExecutions -   ListMonitoringSchedules -   ListNotebookInstanceLifecycleConfigs -   ListNotebookInstances -   ListPipelineExecutionSteps -   ListPipelineExecutions -   ListPipelineParametersForExecution -   ListPipelines -   ListProjects -   ListStudioLifecycleConfigs -   ListSubscribedWorkteams -   ListTrainingJobsForHyperParameterTuningJob -   ListTransformJobs -   ListUserProfiles -   ListWorkforces -   ListWorkteams -   PutModelPackageGroupPolicy -   QueryLineage -   RegisterDevices -   RenderUiTemplate -   RetryPipelineExecution -   SendPipelineExecutionStepFailure -   SendPipelineExecutionStepSuccess -   StartMonitoringSchedule -   StartPipelineExecution -   StopAutoMLJob -   StopCompilationJob -   StopEdgePackagingJob -   StopHyperParameterTuningJob -   StopInferenceRecommendationsJob -   StopLabelingJob -   StopMonitoringSchedule -   StopPipelineExecution -   StopProcessingJob -   StopTrainingJob -   StopTransformJob -   UpdateAction -   UpdateAppImageConfig -   UpdateArtifact -   UpdateCodeRepository -   UpdateContext -   UpdateDeviceFleet -   UpdateDevices -   UpdateDomain -   UpdateEndpoint -   UpdateExperiment -   UpdateFeatureGroup -   UpdateFeatureMetadata -   UpdateImage -   UpdateModelPackage -   UpdateMonitoringSchedule -   UpdateNotebookInstance -   UpdateNotebookInstanceLifecycleConfig -   UpdatePipeline -   UpdatePipelineExecution -   UpdateProject -   UpdateTrainingJob -   UpdateTrial -   UpdateTrialComponent -   UpdateUserProfile -   UpdateWorkforce -   UpdateWorkteam -    secretsmanager    Operation Implemented     CreateSecret ‚ú® ‚úÖ   DeleteSecret ‚ú® ‚úÖ   DescribeSecret ‚ú® ‚úÖ   GetRandomPassword ‚ú® ‚úÖ   GetSecretValue ‚ú® ‚úÖ   PutSecretValue ‚ú® ‚úÖ   RestoreSecret ‚úÖ   TagResource ‚ú® ‚úÖ   UntagResource ‚ú® ‚úÖ   UpdateSecret ‚ú® ‚úÖ   UpdateSecretVersionStage ‚ú® ‚úÖ     Show missing     CancelRotateSecret -   DeleteResourcePolicy -   GetResourcePolicy -   ListSecretVersionIds -   ListSecrets -   PutResourcePolicy -   RemoveRegionsFromReplication -   ReplicateSecretToRegions -   RotateSecret -   StopReplicationToReplica -   ValidateResourcePolicy -    serverlessrepo    Operation Implemented     CreateApplication (Pro) ‚ú® ‚úÖ   CreateApplicationVersion (Pro) ‚ú® ‚úÖ   CreateCloudFormationChangeSet (Pro) ‚ú® ‚úÖ   CreateCloudFormationTemplate (Pro) ‚ú® ‚úÖ   DeleteApplication (Pro) ‚ú® ‚úÖ   GetCloudFormationTemplate (Pro) ‚ú® ‚úÖ   ListApplicationVersions (Pro) ‚ú® ‚úÖ   ListApplications (Pro) ‚ú® ‚úÖ     Show missing     GetApplication -   GetApplicationPolicy -   ListApplicationDependencies -   PutApplicationPolicy -   UnshareApplication -   UpdateApplication -    servicediscovery    Operation Implemented     CreateHttpNamespace (Pro) ‚ú® ‚úÖ   CreatePrivateDnsNamespace (Pro) ‚ú® ‚úÖ   CreatePublicDnsNamespace (Pro) ‚ú® ‚úÖ   CreateService (Pro) ‚ú® ‚úÖ   DeleteNamespace (Pro) ‚ú® ‚úÖ   DeleteService (Pro) ‚ú® ‚úÖ   DeregisterInstance (Pro) ‚ú® ‚úÖ   GetInstance (Pro) ‚ú® ‚úÖ   GetNamespace (Pro) ‚ú® ‚úÖ   GetOperation (Pro) ‚ú® ‚úÖ   GetService (Pro) ‚ú® ‚úÖ   ListInstances (Pro) ‚ú® ‚úÖ   ListNamespaces (Pro) ‚ú® ‚úÖ   ListServices (Pro) ‚ú® ‚úÖ   ListTagsForResource (Pro) ‚ú® ‚úÖ   RegisterInstance (Pro) ‚ú® ‚úÖ   TagResource (Pro) ‚ú® ‚úÖ   UntagResource (Pro) ‚ú® ‚úÖ     Show missing     DiscoverInstances -   GetInstancesHealthStatus -   ListOperations -   UpdateHttpNamespace -   UpdateInstanceCustomHealthStatus -   UpdatePrivateDnsNamespace -   UpdatePublicDnsNamespace -   UpdateService -    ses    Operation Implemented     CreateConfigurationSet ‚úÖ   CreateConfigurationSetEventDestination ‚úÖ   CreateReceiptRule ‚ú® ‚úÖ   CreateReceiptRuleSet ‚ú® ‚úÖ   CreateTemplate ‚ú® ‚úÖ   DeleteReceiptRule (Pro) ‚ú® ‚úÖ   DeleteReceiptRuleSet (Pro) ‚ú® ‚úÖ   DeleteTemplate ‚ú® ‚úÖ   DescribeActiveReceiptRuleSet (Pro) ‚ú® ‚úÖ   DescribeReceiptRule ‚ú® ‚úÖ   DescribeReceiptRuleSet ‚ú® ‚úÖ   GetIdentityMailFromDomainAttributes ‚úÖ   GetIdentityNotificationAttributes ‚úÖ   GetIdentityVerificationAttributes ‚ú® ‚úÖ   GetSendQuota ‚úÖ   GetSendStatistics ‚úÖ   GetTemplate ‚úÖ   ListIdentities ‚úÖ   ListReceiptRuleSets (Pro) ‚ú® ‚úÖ   ListTemplates ‚ú® ‚úÖ   ListVerifiedEmailAddresses ‚úÖ   SetActiveReceiptRuleSet (Pro) ‚ú® ‚úÖ   SetIdentityFeedbackForwardingEnabled ‚úÖ   SetIdentityMailFromDomain ‚úÖ   SetIdentityNotificationTopic ‚úÖ   TestRenderTemplate ‚úÖ   UpdateReceiptRule ‚úÖ   UpdateTemplate ‚úÖ   VerifyDomainDkim ‚úÖ   VerifyDomainIdentity ‚úÖ   VerifyEmailAddress ‚ú® ‚úÖ   VerifyEmailIdentity ‚ú® ‚úÖ     Show missing     CloneReceiptRuleSet -   CreateConfigurationSetTrackingOptions -   CreateCustomVerificationEmailTemplate -   CreateReceiptFilter -   DeleteConfigurationSet -   DeleteConfigurationSetEventDestination -   DeleteConfigurationSetTrackingOptions -   DeleteCustomVerificationEmailTemplate -   DeleteIdentity -   DeleteIdentityPolicy -   DeleteReceiptFilter -   DeleteVerifiedEmailAddress -   DescribeConfigurationSet -   GetAccountSendingEnabled -   GetCustomVerificationEmailTemplate -   GetIdentityDkimAttributes -   GetIdentityPolicies -   ListConfigurationSets -   ListCustomVerificationEmailTemplates -   ListIdentityPolicies -   ListReceiptFilters -   PutConfigurationSetDeliveryOptions -   PutIdentityPolicy -   ReorderReceiptRuleSet -   SendBounce -   SendBulkTemplatedEmail -   SendCustomVerificationEmail -   SendEmail -   SendRawEmail -   SendTemplatedEmail -   SetIdentityDkimEnabled -   SetIdentityHeadersInNotificationsEnabled -   SetReceiptRulePosition -   UpdateAccountSendingEnabled -   UpdateConfigurationSetEventDestination -   UpdateConfigurationSetReputationMetricsEnabled -   UpdateConfigurationSetSendingEnabled -   UpdateConfigurationSetTrackingOptions -   UpdateCustomVerificationEmailTemplate -    sesv2    Operation Implemented     CreateEmailIdentity (Pro) ‚ú® ‚úÖ   CreateEmailTemplate (Pro) ‚ú® ‚úÖ   DeleteEmailIdentity (Pro) ‚ú® ‚úÖ   DeleteEmailTemplate (Pro)  ‚úÖ   GetEmailIdentity (Pro) ‚ú® ‚úÖ   ListEmailIdentities (Pro) ‚ú® ‚úÖ   ListEmailTemplates (Pro)  ‚úÖ   SendEmail (Pro) ‚ú® ‚úÖ     Show missing     CreateConfigurationSet -   CreateConfigurationSetEventDestination -   CreateContact -   CreateContactList -   CreateCustomVerificationEmailTemplate -   CreateDedicatedIpPool -   CreateDeliverabilityTestReport -   CreateEmailIdentityPolicy -   CreateImportJob -   DeleteConfigurationSet -   DeleteConfigurationSetEventDestination -   DeleteContact -   DeleteContactList -   DeleteCustomVerificationEmailTemplate -   DeleteDedicatedIpPool -   DeleteEmailIdentityPolicy -   DeleteSuppressedDestination -   GetAccount -   GetBlacklistReports -   GetConfigurationSet -   GetConfigurationSetEventDestinations -   GetContact -   GetContactList -   GetCustomVerificationEmailTemplate -   GetDedicatedIp -   GetDedicatedIps -   GetDeliverabilityDashboardOptions -   GetDeliverabilityTestReport -   GetDomainDeliverabilityCampaign -   GetDomainStatisticsReport -   GetEmailIdentityPolicies -   GetEmailTemplate -   GetImportJob -   GetSuppressedDestination -   ListConfigurationSets -   ListContactLists -   ListContacts -   ListCustomVerificationEmailTemplates -   ListDedicatedIpPools -   ListDeliverabilityTestReports -   ListDomainDeliverabilityCampaigns -   ListImportJobs -   ListSuppressedDestinations -   ListTagsForResource -   PutAccountDedicatedIpWarmupAttributes -   PutAccountDetails -   PutAccountSendingAttributes -   PutAccountSuppressionAttributes -   PutConfigurationSetDeliveryOptions -   PutConfigurationSetReputationOptions -   PutConfigurationSetSendingOptions -   PutConfigurationSetSuppressionOptions -   PutConfigurationSetTrackingOptions -   PutDedicatedIpInPool -   PutDedicatedIpWarmupAttributes -   PutDeliverabilityDashboardOption -   PutEmailIdentityConfigurationSetAttributes -   PutEmailIdentityDkimAttributes -   PutEmailIdentityDkimSigningAttributes -   PutEmailIdentityFeedbackAttributes -   PutEmailIdentityMailFromAttributes -   PutSuppressedDestination -   SendBulkEmail -   SendCustomVerificationEmail -   TagResource -   TestRenderEmailTemplate -   UntagResource -   UpdateConfigurationSetEventDestination -   UpdateContact -   UpdateContactList -   UpdateCustomVerificationEmailTemplate -   UpdateEmailIdentityPolicy -   UpdateEmailTemplate -    sns    Operation Implemented     AddPermission ‚úÖ   CheckIfPhoneNumberIsOptedOut ‚úÖ   ConfirmSubscription ‚ú® ‚úÖ   CreatePlatformApplication ‚ú® ‚úÖ   CreatePlatformEndpoint ‚ú® ‚úÖ   CreateTopic ‚ú® ‚úÖ   DeleteEndpoint ‚ú® ‚úÖ   DeleteTopic ‚ú® ‚úÖ   GetEndpointAttributes ‚ú® ‚úÖ   GetPlatformApplicationAttributes ‚úÖ   GetSMSAttributes ‚úÖ   GetSubscriptionAttributes ‚ú® ‚úÖ   GetTopicAttributes ‚ú® ‚úÖ   ListEndpointsByPlatformApplication ‚úÖ   ListPhoneNumbersOptedOut ‚úÖ   ListPlatformApplications ‚ú® ‚úÖ   ListSubscriptionsByTopic ‚ú® ‚úÖ   ListTagsForResource ‚ú® ‚úÖ   OptInPhoneNumber ‚úÖ   Publish ‚ú® ‚úÖ   PublishBatch ‚ú® ‚úÖ   RemovePermission ‚úÖ   SetEndpointAttributes ‚úÖ   SetPlatformApplicationAttributes ‚úÖ   SetSMSAttributes ‚úÖ   SetSubscriptionAttributes ‚ú® ‚úÖ   SetTopicAttributes ‚ú® ‚úÖ   Subscribe ‚ú® ‚úÖ   TagResource ‚ú® ‚úÖ   Unsubscribe ‚ú® ‚úÖ   UntagResource ‚ú® ‚úÖ     Show missing     CreateSMSSandboxPhoneNumber -   DeletePlatformApplication -   DeleteSMSSandboxPhoneNumber -   GetSMSSandboxAccountStatus -   ListOriginationNumbers -   ListSMSSandboxPhoneNumbers -   ListSubscriptions -   ListTopics -   VerifySMSSandboxPhoneNumber -    sqs    Operation Implemented     AddPermission ‚úÖ   ChangeMessageVisibility ‚ú® ‚úÖ   ChangeMessageVisibilityBatch ‚úÖ   CreateQueue ‚ú® ‚úÖ   DeleteMessage ‚ú® ‚úÖ   DeleteMessageBatch ‚ú® ‚úÖ   DeleteQueue ‚ú® ‚úÖ   GetQueueAttributes ‚ú® ‚úÖ   GetQueueUrl ‚ú® ‚úÖ   ListDeadLetterSourceQueues ‚ú® ‚úÖ   ListQueueTags ‚ú® ‚úÖ   ListQueues ‚ú® ‚úÖ   PurgeQueue ‚ú® ‚úÖ   ReceiveMessage ‚ú® ‚úÖ   RemovePermission ‚úÖ   SendMessage ‚ú® ‚úÖ   SendMessageBatch ‚ú® ‚úÖ   SetQueueAttributes ‚ú® ‚úÖ   TagQueue ‚ú® ‚úÖ   UntagQueue ‚ú® ‚úÖ    ssm    Operation Implemented     AddTagsToResource ‚úÖ   CancelCommand (Pro) ‚ú® ‚úÖ   CreateMaintenanceWindow ‚úÖ   DeleteDocument ‚úÖ   DeleteParameter ‚ú® ‚úÖ   DeleteParameters ‚úÖ   DescribeDocument ‚úÖ   DescribeDocumentPermission ‚úÖ   DescribeInstanceInformation (Pro) ‚ú® ‚úÖ   DescribeMaintenanceWindows ‚úÖ   GetCommandInvocation ‚ú® ‚úÖ   GetDocument ‚úÖ   GetParameter ‚ú® ‚úÖ   GetParameterHistory ‚úÖ   GetParameters ‚ú® ‚úÖ   GetParametersByPath ‚ú® ‚úÖ   LabelParameterVersion ‚ú® ‚úÖ   ListCommandInvocations (Pro)  ‚úÖ   ListCommands ‚úÖ   ListDocuments ‚úÖ   ListTagsForResource ‚úÖ   ModifyDocumentPermission ‚úÖ   PutParameter ‚ú® ‚úÖ   RemoveTagsFromResource ‚úÖ   SendCommand ‚ú® ‚úÖ   UpdateDocument ‚úÖ   UpdateDocumentDefaultVersion ‚úÖ     Show missing     AssociateOpsItemRelatedItem -   CancelMaintenanceWindowExecution -   CreateActivation -   CreateAssociation -   CreateAssociationBatch -   CreateDocument -   CreateOpsItem -   CreateOpsMetadata -   CreatePatchBaseline -   CreateResourceDataSync -   DeleteActivation -   DeleteAssociation -   DeleteInventory -   DeleteMaintenanceWindow -   DeleteOpsMetadata -   DeletePatchBaseline -   DeleteResourceDataSync -   DeregisterManagedInstance -   DeregisterPatchBaselineForPatchGroup -   DeregisterTargetFromMaintenanceWindow -   DeregisterTaskFromMaintenanceWindow -   DescribeActivations -   DescribeAssociation -   DescribeAssociationExecutionTargets -   DescribeAssociationExecutions -   DescribeAutomationExecutions -   DescribeAutomationStepExecutions -   DescribeAvailablePatches -   DescribeEffectiveInstanceAssociations -   DescribeEffectivePatchesForPatchBaseline -   DescribeInstanceAssociationsStatus -   DescribeInstancePatchStates -   DescribeInstancePatchStatesForPatchGroup -   DescribeInstancePatches -   DescribeInventoryDeletions -   DescribeMaintenanceWindowExecutionTaskInvocations -   DescribeMaintenanceWindowExecutionTasks -   DescribeMaintenanceWindowExecutions -   DescribeMaintenanceWindowSchedule -   DescribeMaintenanceWindowTargets -   DescribeMaintenanceWindowTasks -   DescribeMaintenanceWindowsForTarget -   DescribeOpsItems -   DescribeParameters -   DescribePatchBaselines -   DescribePatchGroupState -   DescribePatchGroups -   DescribePatchProperties -   DescribeSessions -   DisassociateOpsItemRelatedItem -   GetAutomationExecution -   GetCalendarState -   GetConnectionStatus -   GetDefaultPatchBaseline -   GetDeployablePatchSnapshotForInstance -   GetInventory -   GetInventorySchema -   GetMaintenanceWindow -   GetMaintenanceWindowExecution -   GetMaintenanceWindowExecutionTask -   GetMaintenanceWindowExecutionTaskInvocation -   GetMaintenanceWindowTask -   GetOpsItem -   GetOpsMetadata -   GetOpsSummary -   GetPatchBaseline -   GetPatchBaselineForPatchGroup -   GetServiceSetting -   ListAssociationVersions -   ListAssociations -   ListComplianceItems -   ListComplianceSummaries -   ListDocumentMetadataHistory -   ListDocumentVersions -   ListInventoryEntries -   ListOpsItemEvents -   ListOpsItemRelatedItems -   ListOpsMetadata -   ListResourceComplianceSummaries -   ListResourceDataSync -   PutComplianceItems -   PutInventory -   RegisterDefaultPatchBaseline -   RegisterPatchBaselineForPatchGroup -   RegisterTargetWithMaintenanceWindow -   RegisterTaskWithMaintenanceWindow -   ResetServiceSetting -   ResumeSession -   SendAutomationSignal -   StartAssociationsOnce -   StartAutomationExecution -   StartChangeRequestExecution -   StartSession -   StopAutomationExecution -   TerminateSession -   UnlabelParameterVersion -   UpdateAssociation -   UpdateAssociationStatus -   UpdateDocumentMetadata -   UpdateMaintenanceWindow -   UpdateMaintenanceWindowTarget -   UpdateMaintenanceWindowTask -   UpdateManagedInstanceRole -   UpdateOpsItem -   UpdateOpsMetadata -   UpdatePatchBaseline -   UpdateResourceDataSync -   UpdateServiceSetting -    stepfunctions    Operation Implemented     CreateActivity ‚ú® ‚úÖ   CreateStateMachine ‚ú® ‚úÖ   DeleteActivity ‚ú® ‚úÖ   DeleteStateMachine ‚ú® ‚úÖ   DescribeActivity ‚ú® ‚úÖ   DescribeExecution ‚ú® ‚úÖ   DescribeStateMachine ‚ú® ‚úÖ   DescribeStateMachineForExecution ‚ú® ‚úÖ   GetActivityTask ‚úÖ   GetExecutionHistory ‚ú® ‚úÖ   ListActivities ‚ú® ‚úÖ   ListExecutions ‚ú® ‚úÖ   ListStateMachines ‚ú® ‚úÖ   ListTagsForResource ‚úÖ   SendTaskFailure ‚úÖ   SendTaskHeartbeat ‚úÖ   SendTaskSuccess ‚úÖ   StartExecution ‚ú® ‚úÖ   StopExecution ‚úÖ   TagResource ‚úÖ   UntagResource ‚úÖ   UpdateStateMachine ‚ú® ‚úÖ     Show missing     StartSyncExecution -    sts    Operation Implemented     AssumeRole ‚ú® ‚úÖ   AssumeRoleWithWebIdentity ‚ú® ‚úÖ   GetCallerIdentity ‚ú® ‚úÖ   GetFederationToken ‚ú® ‚úÖ   GetSessionToken ‚ú® ‚úÖ     Show missing     AssumeRoleWithSAML -   DecodeAuthorizationMessage -   GetAccessKeyInfo -    support    Operation Implemented     CreateCase ‚ú® ‚úÖ   DescribeCases ‚ú® ‚úÖ   DescribeTrustedAdvisorChecks ‚úÖ   RefreshTrustedAdvisorCheck ‚úÖ     Show missing     AddAttachmentsToSet -   AddCommunicationToCase -   DescribeAttachment -   DescribeCommunications -   DescribeServices -   DescribeSeverityLevels -   DescribeTrustedAdvisorCheckRefreshStatuses -   DescribeTrustedAdvisorCheckResult -   DescribeTrustedAdvisorCheckSummaries -   ResolveCase -    swf    Operation Implemented     CountPendingActivityTasks ‚úÖ   CountPendingDecisionTasks ‚úÖ   DeprecateActivityType ‚úÖ   DeprecateDomain ‚úÖ   DeprecateWorkflowType ‚úÖ   DescribeActivityType ‚úÖ   DescribeDomain ‚úÖ   DescribeWorkflowExecution ‚úÖ   DescribeWorkflowType ‚úÖ   GetWorkflowExecutionHistory ‚ú® ‚úÖ   ListActivityTypes ‚úÖ   ListClosedWorkflowExecutions ‚úÖ   ListDomains ‚úÖ   ListOpenWorkflowExecutions ‚úÖ   ListWorkflowTypes ‚ú® ‚úÖ   PollForActivityTask ‚ú® ‚úÖ   PollForDecisionTask ‚ú® ‚úÖ   RecordActivityTaskHeartbeat ‚úÖ   RegisterActivityType ‚ú® ‚úÖ   RegisterDomain ‚ú® ‚úÖ   RegisterWorkflowType ‚ú® ‚úÖ   RespondActivityTaskCompleted ‚ú® ‚úÖ   RespondActivityTaskFailed ‚úÖ   RespondDecisionTaskCompleted ‚ú® ‚úÖ   SignalWorkflowExecution ‚úÖ   StartWorkflowExecution ‚ú® ‚úÖ   TerminateWorkflowExecution ‚úÖ   UndeprecateActivityType ‚úÖ   UndeprecateDomain ‚úÖ   UndeprecateWorkflowType ‚úÖ     Show missing     CountClosedWorkflowExecutions -   CountOpenWorkflowExecutions -   ListTagsForResource -   RequestCancelWorkflowExecution -   RespondActivityTaskCanceled -   TagResource -   UntagResource -    timestream-query    Operation Implemented     Query (Pro) ‚ú® ‚úÖ     Show missing     CancelQuery -   CreateScheduledQuery -   DeleteScheduledQuery -   DescribeEndpoints -   DescribeScheduledQuery -   ExecuteScheduledQuery -   ListScheduledQueries -   ListTagsForResource -   PrepareQuery -   TagResource -   UntagResource -   UpdateScheduledQuery -    timestream-write    Operation Implemented     CreateDatabase (Pro) ‚ú® ‚úÖ   CreateTable (Pro) ‚ú® ‚úÖ   DeleteDatabase (Pro) ‚ú® ‚úÖ   DeleteTable (Pro) ‚ú® ‚úÖ   DescribeDatabase (Pro) ‚ú® ‚úÖ   DescribeTable (Pro) ‚ú® ‚úÖ   ListDatabases (Pro) ‚ú® ‚úÖ   ListTables (Pro) ‚ú® ‚úÖ   WriteRecords (Pro) ‚ú® ‚úÖ     Show missing     DescribeEndpoints -   ListTagsForResource -   TagResource -   UntagResource -   UpdateDatabase -   UpdateTable -    transfer    Operation Implemented     CreateUser (Pro) ‚ú® ‚úÖ   DeleteServer (Pro) ‚ú® ‚úÖ   DeleteSshPublicKey (Pro) ‚ú® ‚úÖ   DeleteUser (Pro) ‚ú® ‚úÖ   DescribeServer (Pro) ‚ú® ‚úÖ   DescribeUser (Pro) ‚ú® ‚úÖ   ImportSshPublicKey (Pro) ‚ú® ‚úÖ   ListServers (Pro)  ‚úÖ   ListUsers (Pro) ‚ú® ‚úÖ   UpdateUser (Pro) ‚ú® ‚úÖ     Show missing     CreateAccess -   CreateServer -   CreateWorkflow -   DeleteAccess -   DeleteWorkflow -   DescribeAccess -   DescribeExecution -   DescribeSecurityPolicy -   DescribeWorkflow -   ListAccesses -   ListExecutions -   ListSecurityPolicies -   ListTagsForResource -   ListWorkflows -   SendWorkflowStepState -   StartServer -   StopServer -   TagResource -   TestIdentityProvider -   UntagResource -   UpdateAccess -   UpdateServer -    xray    Operation Implemented     BatchGetTraces (Pro)  ‚úÖ   CreateSamplingRule (Pro) ‚ú® ‚úÖ   DeleteSamplingRule (Pro) ‚ú® ‚úÖ   GetSamplingRules (Pro) ‚ú® ‚úÖ   GetServiceGraph (Pro)  ‚úÖ   GetTraceGraph (Pro)  ‚úÖ   GetTraceSummaries (Pro) ‚ú® ‚úÖ   PutTelemetryRecords (Pro) ‚ú® ‚úÖ   PutTraceSegments (Pro) ‚ú® ‚úÖ   UpdateSamplingRule (Pro) ‚ú® ‚úÖ     Show missing     CreateGroup -   DeleteGroup -   GetEncryptionConfig -   GetGroup -   GetGroups -   GetInsight -   GetInsightEvents -   GetInsightImpactGraph -   GetInsightSummaries -   GetSamplingStatisticSummaries -   GetSamplingTargets -   GetTimeSeriesServiceStatistics -   ListTagsForResource -   PutEncryptionConfig -   TagResource -   UntagResource -   UpdateGroup -    Misc Endpoints marked with ‚ú® are covered by our integration test suite.\n","categories":"","description":"Overview of the implemented AWS APIs in LocalStack\n","excerpt":"Overview of the implemented AWS APIs in LocalStack\n","ref":"/localstack/coverage/","tags":"","title":"LocalStack Coverage"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/jvm/","tags":"","title":"jvm"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/kotlin/","tags":"","title":"kotlin"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/localstack-community/","tags":"","title":"LocalStack Community"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/localstack-pro/","tags":"","title":"LocalStack Pro"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/serverless-framework/","tags":"","title":"serverless-framework"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/spring/","tags":"","title":"spring"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/spring-cloud/","tags":"","title":"spring-cloud"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/spring-cloud-function/","tags":"","title":"spring-cloud-function"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"Overview The AWS SDK for .NET, like other AWS SDKs, lets you set the endpoint when creating resource clients, which is the preferred way of integrating the .NET SDK with LocalStack.\nExample Here is an example of how to create an LambdaClient with the endpoint set to LocalStack.\nvar lambdaClient = new AmazonLambdaClient(new AmazonLambdaConfig() { ServiceURL = \"http://localhost:4566\" }); If you want to specify a region and credentials when creating the client, please set them as AuthenticationRegion and BasicAWSCredentials, like in this example:\nvar lambdaClient = new AmazonLambdaClient(new BasicAWSCredentials(\"temp\", \"temp\"), new AmazonLambdaConfig() { ServiceURL = \"http://localhost:4566\", AuthenticationRegion = \"eu-west-1\" });  Make sure you are setting the AuthenticationRegion and not the RegionEndpoint. Setting the RegionEndpoint to a constant like RegionEndpoint.EUWest1 will override the ServiceURL, and your request will end up against AWS.  Resources  AWS SDK for .NET Official repository of the AWS SDK for .NET  ","categories":"","description":"How to use the .NET AWS SDK with LocalStack.\n","excerpt":"How to use the .NET AWS SDK with LocalStack.\n","ref":"/integrations/sdks/dotnet/","tags":["sdk"],"title":".NET"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/account-id/","tags":"","title":"account-id"},{"body":"Details coming soon.\n","categories":["LocalStack Pro","Stub"],"description":"Amplify\n","excerpt":"Amplify\n","ref":"/aws/amplify/","tags":"","title":"Amplify"},{"body":"The Pro version has support for API Gateway V2 (in addition to V1), which allows for creation of local HTTP as well as WebSocket APIs - for long-lived connections and bi-directional communication between the API and your clients.\nAccessing HTTP APIs via local domain name For example, the following Serverless configuration illustrates two Lambda functions (serviceV1 and serviceV2) connected to an API Gateway v1 (http event) and an API Gateway v2 endpoint (httpApi event), respectively:\n...plugins:- serverless-localstackcustom:localstack:stages:[local]functions:serviceV1:handler:handler.handlerevents:- http:# for API GW v1 integrationmethod:POSTpath:/my/path1serviceV2:handler:handler.handlerevents:- httpApi:# for API GW v2 integrationmethod:POSTpath:/my/path2Once deployed, the API Gateway endpoints above can be accessed via the LocalStack edge port (4566 by default).\nThere are two alternative URL formats for accessing the APIs (for both, v1 and v2 APIs). The recommended format is to use the following URL syntax with an execute-api hostname:\nhttp://\u003capiId.execute-api.localhost.localstack.cloud:4566/\u003cstageId/\u003cpath  Assuming the ID of the deployed HTTP/REST API is 0v1p6q6, the invocation URL would be:\nhttp://0v1p6q6.execute-api.localhost.localstack.cloud:4566/local/my/path2 The alternative format (sometimes used, e.g., in case of local DNS issues) is an endpoint with the predefined path marker _user_request_:\nhttp://localhost:4566/restapis/\u003capiId/\u003cstageId/_user_request_/\u003cpath  ‚Ä¶ which for the example above would result in:\nhttp://localhost:4566/restapis/0v1p6q6/local/_user_request_/my/path1  Please note that the URLs above include the name of the API Gateway stage (local) - adding the stage is required for API Gateway v1 APIs, but optional for API Gateway v2 APIs (in case they include the wildcard $default stage). In other words, for v2 the URL http://0v1p6q6.execute-api.localhost.localstack.cloud:4566/my/path1 should also work.  WebSocket APIs To illustrate the use of WebSockets, assume we define the following Serverless configuration:\n...plugins:- serverless-localstackfunctions:actionHandler:handler:handler.handlerevents:- websocket:route:test-actionUpon deployment of the Serverless project, a new API Gateway V2 endpoint will be created in LocalStack. The awslocal CLI can be used to get the list of APIs, which should contain the WebSocket endpoint, e.g., ws://localhost:4510 in the example below:\n$ awslocal apigatewayv2 get-apis { \"Items\": [{ \"ApiEndpoint\": \"ws://localhost:4510\", \"ApiId\": \"129ca37e\", ... }] } Assuming your project contains a simple Lambda handler.js like this:\nmodule.exports.handler = function(event, context, callback) { callback(null, event); }; ‚Ä¶ then sending a message to the WebSocket at ws://localhost:4510 will result in the same message getting returned as a response on the same WebSocket.\nA backend service can push data to the connection using the Amazon API Gateway Management API. In LocalStack, it looks like this (make sure to replace \u003cconnectionId\u003e with your WebSocket connection ID):\n$ awslocal apigatewaymanagementapi post-to-connection --connection-id '\u003cconnectionId\u003e' --data '{\"msg\": \"Hi\"}' For a simple, self-contained example please refer to this Github repository.\n","categories":["LocalStack Pro"],"description":"API Gateway V2\n","excerpt":"API Gateway V2\n","ref":"/aws/apigatewayv2/","tags":"","title":"API Gateway V2"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/apple/","tags":"","title":"apple"},{"body":"Basic support for AppSync is included in LocalStack Pro. The local AppSync API allows you to spin up local GraphQL APIs and directly expose your data sources (e.g., DynamoDB tables) to external clients.\nFor example, you can create a DynamoDB table \"posts\" with a key attribute id, and define a GraphQL schema in a file schema.graphql like this:\nschema { query: Query } type Query { getPosts: [Post!]! } type Post { id: DDBString! } type DDBString { S: String! } ‚Ä¶ and then use the AppSync API (or CloudFormation) to create the following entities:\n a GraphQL API a data source of type AMAZON_DYNAMODB that references the \"posts\" DynamoDB table a request mapping template with a content like this:  { \"version\" : \"2017-02-28\", \"operation\" : \"Scan\" } a response mapping template with a content like this:  $util.toJson($context.result[\"Items\"]) Once things have been wired up properly, and assuming the ID of your GraphQL API is \"api123\", you should be able to run the following GraphQL query to retrieve all items from the \"posts\" DynamoDB table: $ curl -d '{\"query\":\"query {getPosts{id{S}}}\"}' http://localhost:4605/graphql/api123\nFor more details, please refer to the self-contained sample published in this Github repository.\nCustom GraphQL API IDs It is possible to use a predefined ID when creating GraphQL APIs by setting the tag _custom_id_. For example:\n$ awslocal appsync create-graphql-api --name my-api --authentication-type API_KEY --tags _custom_id_=faceb00c { \"graphqlApi\": { \"name\": \"my-api\", \"apiId\": \"faceb00c\", \"authenticationType\": \"API_KEY\", \"arn\": \"arn:aws:appsync:us-east-1:000000000000:apis/my-api\", \"uris\": { \"GRAPHQL\": \"http://localhost:4566/graphql/faceb00c\", \"REALTIME\": \"ws://localhost:4510/graphql/faceb00c\" }, \"tags\": { \"_custom_id_\": \"faceb00c\" } } } GraphQL Endpoints There are three configurable strategies that govern how GraphQL API endpoints are created. The strategy can be configured via the GRAPHQL_ENDPOINT_STRATEGY environment variable.\n   Value Format Description     domain \u003capi-id\u003e.appsync-api.localhost.localstack.cloud:4566 This will be the default strategy in the future that uses the localhost.localstack.cloud domain to route to your localhost   path localhost:4566/appsync-api/\u003capi-id\u003e/graphql An alternative that can be useful if you cannot resolve LocalStack‚Äôs localhost domain   legacy localhost:4566/graphql/\u003capi-id\u003e The old shape of the endpoint, which is currently the default but will be phased out    ","categories":["LocalStack Pro"],"description":"AppSync\n","excerpt":"AppSync\n","ref":"/aws/appsync/","tags":"","title":"AppSync"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/architect/","tags":"","title":"architect"},{"body":"LocalStack Pro ships with built-in support for Athena, Amazon‚Äôs serverless data warehouse and analytics platform. Athena uses Presto under the covers, and your Athena instance will be automatically configured with a Hive metastore that connects seamlessly to the LocalStack S3 API. That is, you can easily connect your local S3 buckets and query data directly from S3 via the powerful Athena query API.\nThe following commands illustrate how to use Athena from the command line (assuming you have awslocal installed):\n$ awslocal athena start-query-execution --query-string 'SELECT 1, 2, 3' { \"QueryExecutionId\": \"c9f453ad\" } $ awslocal athena list-query-executions { \"QueryExecutionIds\": [ \"c9f453ad\" ] } $ awslocal athena get-query-results --query-execution-id c9f453ad { \"ResultSet\": { \"Rows\": [ { \"Data\": [ { \"VarCharValue\": \"_col0\" }, { \"VarCharValue\": \"_col1\" }, { \"VarCharValue\": \"_col2\" } ] }, { \"Data\": [ { \"VarCharValue\": \"1\" }, { \"VarCharValue\": \"2\" }, { \"VarCharValue\": \"3\" } ] } ], \"ResultSetMetadata\": { \"ColumnInfo\": [ { \"Name\": \"_col0\", \"Type\": \"integer\" }, { \"Name\": \"_col1\", \"Type\": \"integer\" }, { \"Name\": \"_col2\", \"Type\": \"integer\" } ] } }, \"UpdateCount\": 0 } Note: In order to use the Athena API, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.5GB which includes Presto, Hive and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you‚Äôre on a decent internet connection when pulling the dependencies for the first time.  ","categories":["LocalStack Pro"],"description":"Athena\n","excerpt":"Athena\n","ref":"/aws/athena/","tags":"","title":"Athena"},{"body":"The Backup API allows to manage backup plans, to create scheduled or on-demand backups of certain resource types like DynamoDB tables or RDS databases. Details following soon‚Ä¶\n","categories":["LocalStack Pro","Stub"],"description":"Backup\n","excerpt":"Backup\n","ref":"/aws/backup/","tags":"","title":"Backup"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/cdk/","tags":"","title":"cdk"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/chalice/","tags":"","title":"chalice"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/ci/","tags":"","title":"ci"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/cli/","tags":"","title":"CLI"},{"body":"Overview AWS CloudFormation is AWS‚Äôs primary Infrastructure-as-Code (IaC) service. It is used to declaratively define your architecture on the AWS cloud, including resources such as S3 Buckets, Lambda Functions, and much more.\nCloudFormation Stack templates are written in either YAML or JSON and can be written manually or generated by higher-level tools such as AWS CDK, AWS SAM, Pulumi or Serverless Framework.\nQuickstart In this quickstart guide we will deploy a simple CloudFormation stack consisting of a single S3 Bucket.\nPrerequisites Make sure you‚Äôve set up awslocal and that you have a running LocalStack instance.\nDeploy a CloudFormation Stack to LocalStack YAML  JSON   Resources:LocalBucket:Type:AWS::S3::BucketProperties:BucketName:cfn-quickstart-bucket { \"Resources\": { \"LocalBucket\": { \"Type\": \"AWS::S3::Bucket\", \"Properties\": { \"BucketName\": \"cfn-quickstart-bucket\" } } } }  Use this code snippet and save the content in either cfn-quickstart-stack.yaml or cfn-quickstart-stack.json respectively.\n# Deploy the bucket on LocalStack # The template file (ending with .yaml or .json) should contain the stack content from above awslocal cloudformation deploy --stack-name cfn-quickstart-stack --template-file \"./cfn-quickstart-stack.yaml\" # Verify the bucket was created successfully # The output should include a bucket with the name cfn-quickstart-bucket awslocal s3api list-buckets # Delete the stack (this will also delete the bucket) awslocal cloudformation delete-stack --stack-name cfn-quickstart-stack Check out the official AWS CloudFormation User Guide for a general introduction to CloudFormation concepts and a more comprehensive introduction on how to write CloudFormation templates.\nSupport We are constantly improving our feature coverage for CloudFormation, with new resource types getting added on an ongoing basis. Your feature requests help us prioritize which resources we need to prioritize, so please feel free to open a new GitHub issue or add a thumbs up to an existing issue.\nFeatures    Feature Support     Parameters Partial   Dynamic References -   Rules -   Mappings Full   Conditions Full   Transform Partial (Only for AWS::Serverless-2016-10-31)   Outputs Full   Custom resources Partial   Drift detection -   Importing Resources -   Change sets Full   Nested stacks Partial   StackSets Partial    In general UPDATE support for resources is currently limited. Prefer re-creating a stack rather than updating an existing one.\nResources (Community Edition)    Resource Create Delete Update     AWS::ApiGateway::Account - - -   AWS::ApiGateway::ApiKey ‚úÖ - -   AWS::ApiGateway::BasePathMapping ‚úÖ - -   AWS::ApiGateway::Deployment ‚úÖ - -   AWS::ApiGateway::DomainName ‚úÖ - -   AWS::ApiGateway::GatewayResponse ‚úÖ - -   AWS::ApiGateway::Method ‚úÖ - ‚úÖ   AWS::ApiGateway::Model ‚úÖ - -   AWS::ApiGateway::RequestValidator ‚úÖ ‚úÖ -   AWS::ApiGateway::Resource ‚úÖ - -   AWS::ApiGateway::RestApi ‚úÖ ‚úÖ -   AWS::ApiGateway::Stage ‚úÖ - -   AWS::ApiGateway::UsagePlan ‚úÖ - -   AWS::ApiGateway::UsagePlanKey ‚úÖ - -   AWS::CDK::Metadata - - -   AWS::CertificateManager::Certificate ‚úÖ ‚úÖ -   AWS::CloudFormation::Stack ‚úÖ - -   AWS::CloudWatch::Alarm ‚úÖ ‚úÖ -   AWS::CloudWatch::CompositeAlarm ‚úÖ ‚úÖ -   AWS::DynamoDB::Table ‚úÖ ‚úÖ -   AWS::EC2::Instance ‚úÖ ‚úÖ ‚úÖ   AWS::EC2::InternetGateway ‚úÖ - -   AWS::EC2::NatGateway ‚úÖ ‚úÖ -   AWS::EC2::Route ‚úÖ ‚úÖ -   AWS::EC2::RouteTable ‚úÖ ‚úÖ -   AWS::EC2::SecurityGroup ‚úÖ ‚úÖ -   AWS::EC2::Subnet ‚úÖ ‚úÖ -   AWS::EC2::SubnetRouteTableAssociation ‚úÖ ‚úÖ -   AWS::EC2::VPC ‚úÖ ‚úÖ -   AWS::EC2::VPCGatewayAttachment ‚úÖ - -   AWS::ECR::Repository ‚úÖ ‚úÖ -   AWS::Elasticsearch::Domain ‚úÖ ‚úÖ -   AWS::Events::Connection ‚úÖ ‚úÖ -   AWS::Events::EventBus ‚úÖ ‚úÖ -   AWS::Events::EventBusPolicy ‚úÖ ‚úÖ -   AWS::Events::Rule ‚úÖ ‚úÖ -   AWS::IAM::Group ‚úÖ ‚úÖ -   AWS::IAM::InstanceProfile ‚úÖ ‚úÖ -   AWS::IAM::ManagedPolicy ‚úÖ - -   AWS::IAM::Policy ‚úÖ ‚úÖ -   AWS::IAM::Role ‚úÖ ‚úÖ ‚úÖ   AWS::IAM::ServiceLinkedRole ‚úÖ ‚úÖ -   AWS::IAM::User ‚úÖ ‚úÖ -   AWS::KMS::Alias ‚úÖ ‚úÖ -   AWS::KMS::Key ‚úÖ ‚úÖ -   AWS::Kinesis::Stream ‚úÖ ‚úÖ -   AWS::Kinesis::StreamConsumer ‚úÖ ‚úÖ -   AWS::KinesisFirehose::DeliveryStream ‚úÖ ‚úÖ -   AWS::Lambda::EventInvokeConfig ‚úÖ ‚úÖ -   AWS::Lambda::EventSourceMapping ‚úÖ - -   AWS::Lambda::Function ‚úÖ ‚úÖ ‚úÖ   AWS::Lambda::Permission ‚úÖ - -   AWS::Lambda::Version ‚úÖ - -   AWS::Logs::LogGroup ‚úÖ ‚úÖ -   AWS::Logs::LogStream ‚úÖ ‚úÖ -   AWS::Logs::SubscriptionFilter ‚úÖ ‚úÖ -   AWS::OpenSearchService::Domain ‚úÖ ‚úÖ -   AWS::Redshift::Cluster ‚úÖ - -   AWS::ResourceGroups::Group ‚úÖ ‚úÖ -   AWS::Route53::RecordSet ‚úÖ - -   AWS::S3::Bucket ‚úÖ ‚úÖ -   AWS::S3::BucketPolicy ‚úÖ ‚úÖ -   AWS::SNS::Subscription ‚úÖ ‚úÖ -   AWS::SNS::Topic ‚úÖ ‚úÖ -   AWS::SNS::TopicPolicy ‚úÖ ‚úÖ -   AWS::SQS::Queue ‚úÖ ‚úÖ -   AWS::SQS::QueuePolicy ‚úÖ ‚úÖ -   AWS::SSM::Parameter ‚úÖ ‚úÖ -   AWS::SecretsManager::ResourcePolicy ‚úÖ ‚úÖ -   AWS::SecretsManager::RotationSchedule - - -   AWS::SecretsManager::Secret ‚úÖ ‚úÖ -   AWS::SecretsManager::SecretTargetAttachment - - -   AWS::StepFunctions::Activity ‚úÖ ‚úÖ -   AWS::StepFunctions::StateMachine ‚úÖ ‚úÖ ‚úÖ    Resources (Pro / Enterprise Edition) The resources below are only available with a valid Pro license key. When running the Community Edition, any unsupported resources in the stack are ignored and will not get deployed.\n   Resource Create Delete Update     AWS::Amplify::App ‚úÖ - -   AWS::Amplify::Branch ‚úÖ - -   AWS::ApiGateway::Authorizer ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::Api ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::Authorizer ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::Deployment ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::DomainName ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::Integration ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::IntegrationResponse ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::Route ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::RouteResponse ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::Stage ‚úÖ ‚úÖ -   AWS::ApiGatewayV2::VpcLink ‚úÖ ‚úÖ -   AWS::AppSync::ApiKey ‚úÖ - -   AWS::AppSync::DataSource ‚úÖ - -   AWS::AppSync::FunctionConfiguration ‚úÖ - -   AWS::AppSync::GraphQLApi ‚úÖ - -   AWS::AppSync::GraphQLSchema ‚úÖ - -   AWS::AppSync::Resolver ‚úÖ ‚úÖ ‚úÖ   AWS::ApplicationAutoScaling::ScalableTarget ‚úÖ ‚úÖ -   AWS::ApplicationAutoScaling::ScalingPolicy ‚úÖ ‚úÖ -   AWS::Backup::BackupPlan ‚úÖ ‚úÖ -   AWS::CloudFormation::CustomResource ‚úÖ - -   AWS::CloudFront::CloudFrontOriginAccessIdentity ‚úÖ - -   AWS::CloudFront::Distribution ‚úÖ - -   AWS::CloudFront::Function ‚úÖ ‚úÖ -   AWS::CloudFront::OriginRequestPolicy ‚úÖ ‚úÖ -   AWS::CloudTrail::Trail ‚úÖ ‚úÖ -   AWS::Cognito::IdentityPool ‚úÖ ‚úÖ -   AWS::Cognito::IdentityPoolRoleAttachment ‚úÖ - -   AWS::Cognito::UserPool ‚úÖ ‚úÖ -   AWS::Cognito::UserPoolClient ‚úÖ ‚úÖ -   AWS::Cognito::UserPoolDomain ‚úÖ ‚úÖ -   AWS::Cognito::UserPoolGroup ‚úÖ ‚úÖ -   AWS::Cognito::UserPoolIdentityProvider ‚úÖ ‚úÖ -   AWS::DocDB::DBCluster ‚úÖ ‚úÖ -   AWS::DocDB::DBClusterParameterGroup ‚úÖ ‚úÖ -   AWS::DocDB::DBInstance ‚úÖ ‚úÖ -   AWS::DocDB::DBSubnetGroup ‚úÖ ‚úÖ -   AWS::EC2::EIP ‚úÖ ‚úÖ -   AWS::EC2::SecurityGroupEgress ‚úÖ - -   AWS::EC2::SecurityGroupIngress ‚úÖ - -   AWS::EC2::VPCEndpoint ‚úÖ - -   AWS::ECS::Cluster ‚úÖ ‚úÖ -   AWS::ECS::Service ‚úÖ ‚úÖ -   AWS::ECS::TaskDefinition ‚úÖ - -   AWS::ElastiCache::CacheCluster ‚úÖ ‚úÖ -   AWS::ElastiCache::ParameterGroup ‚úÖ ‚úÖ -   AWS::ElastiCache::ReplicationGroup ‚úÖ ‚úÖ -   AWS::ElastiCache::SecurityGroup ‚úÖ ‚úÖ -   AWS::ElastiCache::SubnetGroup ‚úÖ ‚úÖ -   AWS::ElasticLoadBalancingV2::Listener ‚úÖ - -   AWS::ElasticLoadBalancingV2::ListenerRule ‚úÖ - -   AWS::ElasticLoadBalancingV2::LoadBalancer ‚úÖ - -   AWS::ElasticLoadBalancingV2::TargetGroup ‚úÖ - -   AWS::Glue::Classifier ‚úÖ - -   AWS::Glue::Crawler ‚úÖ - -   AWS::Glue::Database ‚úÖ - -   AWS::Glue::Job ‚úÖ - -   AWS::Glue::Table ‚úÖ - -   AWS::Glue::Trigger ‚úÖ - -   AWS::Glue::Workflow ‚úÖ - -   AWS::IoT::Certificate ‚úÖ - -   AWS::IoT::Policy ‚úÖ ‚úÖ -   AWS::IoT::Thing ‚úÖ ‚úÖ -   AWS::IoT::TopicRule ‚úÖ ‚úÖ -   AWS::IoTAnalytics::Channel ‚úÖ ‚úÖ -   AWS::IoTAnalytics::Dataset ‚úÖ ‚úÖ -   AWS::IoTAnalytics::Datastore ‚úÖ ‚úÖ -   AWS::IoTAnalytics::Pipeline ‚úÖ ‚úÖ -   AWS::KinesisAnalytics::Application ‚úÖ - -   AWS::KinesisAnalytics::ApplicationOutput ‚úÖ - -   AWS::Lambda::Alias ‚úÖ - -   AWS::Lambda::LayerVersion ‚úÖ - -   AWS::Lambda::LayerVersionPermission ‚úÖ - -   AWS::MSK::Cluster ‚úÖ ‚úÖ -   AWS::QLDB::Ledger ‚úÖ ‚úÖ -   AWS::RDS::DBCluster ‚úÖ ‚úÖ -   AWS::RDS::DBClusterParameterGroup ‚úÖ ‚úÖ -   AWS::RDS::DBInstance ‚úÖ ‚úÖ -   AWS::RDS::DBParameterGroup ‚úÖ ‚úÖ -   AWS::RDS::DBSubnetGroup ‚úÖ ‚úÖ -   AWS::Redshift::ClusterParameterGroup ‚úÖ ‚úÖ -   AWS::Redshift::ClusterSecurityGroup ‚úÖ ‚úÖ -   AWS::Redshift::ClusterSubnetGroup ‚úÖ ‚úÖ -   AWS::Route53::HostedZone ‚úÖ ‚úÖ -   AWS::SES::ReceiptRule ‚úÖ ‚úÖ -   AWS::SES::ReceiptRuleSet ‚úÖ ‚úÖ -   AWS::SES::Template ‚úÖ ‚úÖ ‚úÖ   AWS::ServiceDiscovery::HttpNamespace ‚úÖ ‚úÖ -   AWS::ServiceDiscovery::PrivateDnsNamespace ‚úÖ ‚úÖ -   AWS::ServiceDiscovery::PublicDnsNamespace ‚úÖ ‚úÖ -   AWS::ServiceDiscovery::Service ‚úÖ ‚úÖ -   AWS::Timestream::Database ‚úÖ ‚úÖ -   AWS::Timestream::Table ‚úÖ ‚úÖ -    ","categories":"","description":"Use AWS CloudFormation with LocalStack\n","excerpt":"Use AWS CloudFormation with LocalStack\n","ref":"/aws/cloudformation/","tags":["cloudformation","infrastructure-as-code"],"title":"CloudFormation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/cloudformation/","tags":"","title":"cloudformation"},{"body":"LocalStack Pro supports creation of local CloudFront distributions, which allows you to transparently access your applications and file artifacts via CloudFront URLs like https://abc123.cloudfront.net.\nFor example, take the following simple example which creates an S3 bucket, puts a small text file hello.txt to the bucket, and then creates a CloudFront distribution which makes the file accessible via a https://abc123.cloudfront.net/hello.txt proxy URL (where abc123 is a placeholder for the real distribution ID):\n$ awslocal s3 mb s3://bucket1 $ echo 'Hello World' \u003e /tmp/hello.txt $ awslocal s3 cp /tmp/hello.txt s3://bucket1/hello.txt --acl public-read $ domain=$(awslocal cloudfront create-distribution \\ --origin-domain-name bucket1.s3.amazonaws.com | jq -r '.Distribution.DomainName') $ curl -k https://$domain/hello.txt Note: In order for CloudFront to be fully functional, your local DNS setup needs to be properly configured. See the section on configuring the local DNS server for details.  Note: In the code example above, the last command (curl https://$domain/hello.txt) may temporarily fail with a warning message Could not resolve host. This is due to the fact that operating systems use different DNS caching strategies, and it may take some time for the CloudFront distribution‚Äôs DNS name (e.g., abc123.cloudfront.net) to become available in the system. Usually after a few retries the command should work, though. Note that a similar behavior can also be observed in the real AWS - CloudFront DNS names can also take up to 10-15 minutes to propagate across the network.  ","categories":["LocalStack Pro"],"description":"CloudFront\n","excerpt":"CloudFront\n","ref":"/aws/cloudfront/","tags":"","title":"CloudFront"},{"body":"The CloudWatch API allows monitoring of AWS resources.\nMetric Alarms Alarms can be used to observe thresholds for data-of-interest, and trigger actions automatically. Please also consult the AWS docs on how alarms are evaluated in general. LocalStack currently supports metric-alarm evaluation with statistic and comparison-operator.\nMetric Alarm Examples Metric alarms evaluate the state, by taking into account the data points of E.g. you can create this alarm: $ awslocal cloudwatch put-metric-alarm \\ --alarm-name my-alarm \\ --metric-name Orders \\ --namespace test \\ --threshold 1 \\ --comparison-operator LessThanThreshold \\ --evaluation-periods 1 \\ --period 30 \\ --statistic Minimum \\ --treat-missing notBreaching\nYou can now in seperate terminal, watch the status of the alarm: $ watch \"awslocal cloudwatch describe-alarms --alarm-names my-alarm | jq '.MetricAlarms[0].StateValue'\"\nAnd then add some data will cause a breach, and set the metric-alarm to state ALARM: $ awslocal cloudwatch put-metric-data --namespace test --metric-data '[{\"MetricName\": \"Orders\", \"Value\": -1}]'\nThe alarm state should change to ALARM after a few seconds, and eventually go back to OK - as we configured to treat missing data points as ‚Äúnot breaching‚Äù.\nMetric Alarm with Action Actions are triggered when the state of the alarm changes. For this you can configure alarm-actions, ok-actions and insufficient-data-actions. Currently, we only support SNS Topics. The topic must be created beforehand.\nHere is an example with an alarm that will send a message to the defined topic once the alarm is in state ALARM. Note that the alarm-actions requires a valid ARN of an existing SNS topic. $ awslocal cloudwatch put-metric-alarm \\ --alarm-name my-alarm \\ --metric-name Orders \\ --namespace test \\ --threshold 50 \\ --comparison-operator GreaterThanThreshold \\ --evaluation-periods 1 \\ --period 300 \\ --statistic Maximum \\ --treat-missing notBreaching \\ --alarm-actions \u003ctopic-arn\u003e\nKnown Limitations:\n Anamoly detection, and extended-statics are not supported unit values are ignored composite-alarms are not evaluated metric-streams are not supported   ","categories":"","description":"","excerpt":"The CloudWatch API allows monitoring of AWS resources.\nMetric Alarms ‚Ä¶","ref":"/aws/cloudwatch/","tags":"","title":"CloudWatch"},{"body":"LocalStack Pro contains basic support for CodeCommit code repositories. The CodeCommit API can be used to create Git repositories, clone these repos to local folders, push commits with changes, etc.\nA simple example has been added in this Github repository. The sample creates an Git repository via the AWS CodeCommit API locally, commits and pushes a test file to the repository, and then checks out the file in a fresh clone of the repository.\nPlease note that CodeCommit is a fairly large API and currently not all methods are supported yet, but we are actively extending the implementation on an ongoing basis.\n","categories":["LocalStack Pro"],"description":"CodeCommit\n","excerpt":"CodeCommit\n","ref":"/aws/codecommit/","tags":"","title":"CodeCommit"},{"body":"The AWS Cognito service enables you to manage authentication and access control for AWS-backed apps and resources.\nLocalStack Pro contains basic support for authentication via Cognito. You can create Cognito user pools, sign up and confirm users, set up Lambda triggers, and use the COGNITO_USER_POOLS authorizer integration with API Gateway.\nNote: By default, local Cognito does not send actual email messages. To enable this feature, you will require an email address and the corresponding SMTP settings. Please refer to the Configuration guide for instructions on how to configure the connection parameters of your SMTP server.\nUser pools and basic authentication flows The following subsections illustrate how you can create a user pool and client, and then sign up and authenticate a new user in the pool.\nCreating a User Pool Just as with AWS, you can create a user pool in LocalStack with the following command: $ awslocal cognito-idp create-user-pool --pool-name test\nThe response should look similar to this:\n\"UserPool\": { \"Id\": \"us-east-1_fd924693e9b04f549f989283123a29c2\", \"Name\": \"test\", \"Policies\": { \"PasswordPolicy\": { \"MinimumLength\": 8, \"RequireUppercase\": true, \"RequireLowercase\": true, \"RequireNumbers\": true, \"RequireSymbols\": true, \"TemporaryPasswordValidityDays\": 7 } }, \"LastModifiedDate\": \"2021-10-06T11:57:21.883Z\", \"CreationDate\": \"2021-10-06T11:57:21.883Z\", \"SchemaAttributes\": [], \"VerificationMessageTemplate\": { \"DefaultEmailOption\": \"CONFIRM_WITH_CODE\" }, \"EmailConfiguration\": { \"EmailSendingAccount\": \"COGNITO_DEFAULT\" }, \"AdminCreateUserConfig\": { \"AllowAdminCreateUserOnly\": false }, \"Arn\": \"arn:aws:cognito-idp:us-east-1:000000000000:userpool/us-east-1_fd924693e9b04f549f989283123a29c2\" } We will need the user pool‚Äôs id for further operations, so save it in a pool_id variable: $ pool_id=\u003cyour-pool-id\u003e\nAlternatively, you can also use a JSON processor like jq to directly extract the necessary information when creating a pool in the first place:\n$ pool_id=$(awslocal cognito-idp create-user-pool --pool-name test | jq -rc \".UserPool.Id\") Adding a Client Now we add a client to our newly created pool. Again, we will also need the ID of the created client for the next step. The complete command for client creation with subsequent ID extraction is therefore:\n$ client_id=$(awslocal cognito-idp create-user-pool-client --user-pool-id $pool_id --client-name test-client | jq -rc \".UserPoolClient.ClientId\") Signing up and confirming a user With these steps already taken, we can now sign up a user: $ awslocal cognito-idp sign-up --client-id $client_id --username example_user --password 12345678 --user-attributes Name=email,Value=\u003cyour.email@address.com\u003e\nThe response should look similar to this:\n{ \"UserConfirmed\": false, \"UserSub\": \"5fdbe1d5-7901-4fee-9d1d-518103789c94\" } After the user is created, a confirmation code is generated. The code is printed in the LocalStack container logs (see below), and can optionally also be sent via email if you have SMTP configured.\nINFO:localstack_ext.services.cognito.cognito_idp_api: Confirmation code for Cognito user example_user: 125796 DEBUG:localstack_ext.bootstrap.email_utils: Sending confirmation code via email to \"your.email@address.com\" We can confirm the user with the activation code, using the following command: $ awslocal cognito-idp confirm-sign-up --client-id $client_id --username example_user --confirmation-code \u003creceived-confirmation-code\u003e\nAs the above command doesn‚Äôt return an answer, we check the pool to see that the request was successful: $ awslocal cognito-idp list-users --user-pool-id $pool_id { \"Users\": [ { \"Username\": \"example_user\", \"Attributes\": [ { \"Name\": \"email\", \"Value\": \"your.email@address.com\" }, { \"Name\": \"sub\", \"Value\": \"5fdbe1d5-7901-4fee-9d1d-518103789c94\" }, { \"Name\": \"cognito:username\", \"Value\": \"example_user\" } ], \"Enabled\": true, \"UserStatus\": \"CONFIRMED\"  } ] }\nJWT token issuer and JSON Web Key Sets (JWKS) endpoints The JWT tokens created by Cognito contain an issuer (iss) attribute that represents the endpoint of the corresponding user pool. The issuer endpoint generally follows this pattern, where \u003cpool_id\u003e is the ID of the Cognito user pool:\nhttp://localhost:4566/\u003cpool_id\u003e Under certain circumstances (depending on your configurations), there may be slight nuances of the issuer URL, like:\nhttps://cognito-idp.localhost.localstack.cloud/\u003cpool_id\u003e You can access the JSON Web Key Sets (JWKS) configuration under the following standardized well-known URL for each user pool: $ curl 'http://localhost:4566/\u003cpool_id\u003e/.well-known/jwks.json' {\"keys\": [{\"kty\": \"RSA\", \"alg\": \"RS256\", \"use\": \"sig\", \"kid\": \"test-key\", \"n\": \"k6lrbEH...\"]}\nAdditionally, the global region-specific public keys for Cognito Identity Pools can be retrieved under this endpoint: $ curl http://localhost:4566/.well-known/jwks_uri {\"keys\": [{\"kty\": \"RSA\", \"alg\": \"RS512\", \"use\": \"sig\", \"kid\": \"ap-northeast-11\", \"n\": \"AI7mc1assO5...\"]}\nCognito Lambda Triggers Cognito provides a number of lifecycle hooks in the form of Cognito Lambda triggers. These triggers can be used to react to various lifecycle events and customize the behavior of user signup, confirmation, migration, etc.\nFor example, to define a user migration Lambda trigger, we can first create a Lambda function (say, named \"f1\") capable of performing the migration, and then define the corresponding --lambda-config on the user pool creation:\n$ awslocal cognito-idp create-user-pool --pool-name test2 --lambda-config '{\"UserMigration\":\"arn:aws:lambda:us-east-1:000000000000:function:f1\"}' Upon authentication of a non-registered user, Cognito will then automatically call the migration Lambda function and finally add the migrated user to the pool.\nMore details on Cognito Lambda triggers can be found in the AWS documentation.\nOAuth Flows via Cognito Login Form You can also access the local Cognito login form by entering the following URL in your browser:\nhttp://localhost:4566/login?response_type=code\u0026client_id=\u003cclient_id\u003e\u0026redirect_uri=\u003credirect_uri\u003e Please replace \u003cclient_id\u003e with the ID of an existing user pool client ID (in this case, example_user), and \u003credirect_uri\u003e with the redirect URI of your application (e.g., http://example.com).\nThe login form should look similar to the screenshot below:   After successful login, the page will redirect to the specified \u003credirect_uri\u003e, with a path parameter ?code=\u003ccode\u003e appended, e.g., http://example.com?code=test123. Obtain a token by submitting that code with grant_type=authorization_code the LocalStack‚Äôs implementation of the Cognito OAuth2 TOKEN Endpoint documented here. Note that the value of the redirect_uri parameter must match the value provided during login.\n% curl \\  --data-urlencode 'grant_type=authorization_code' \\  --data-urlencode 'redirect_uri=http://example.com' \\  --data-urlencode \"client_id=${client_id}\" \\  --data-urlencode 'code=test123' \\  'http://localhost:4566/oauth2/token' {\"access_token\": \"eyJ0eXAi‚Ä¶lKaHx44Q\", \"expires_in\": 86400, \"token_type\": \"Bearer\", \"refresh_token\": \"e3f08304\", \"id_token\": \"eyJ0eXAi‚Ä¶ADTXv5mA\"} Serverless and Cognito You can also use Cognito and LocalStack in conjunction with the Serverless framework.\nFor example, take this snippet of a serverless.yml configuration:\nservice:testplugins:- serverless-deployment-bucket- serverless-pseudo-parameters- serverless-localstackcustom:localstack:stages:[local]functions:http_request:handler:http.requestevents:- http:path:v1/requestauthorizer:arn:arn:aws:cognito-idp:us-east-1:#{AWS::AccountId}:userpool/ExampleUserPoolresources:Resources:UserPool:Type:AWS::Cognito::UserPoolProperties:...The serverless configuration can then be deployed using serverless deploy --stage local. The example contains a Lambda function http_request which is connected to an API Gateway endpoint. Once deployed, the v1/request API Gateway endpoint will be secured against the Cognito user pool ‚ÄúExampleUserPool‚Äù. You can then register users against that local pool, using the same API calls as for AWS.\nIn order to make requests against the secured API Gateway endpoint, use the local Cognito API to retrieve identity credentials which can be sent along as Authentication HTTP headers (where test-1234567 is the name of the access key ID generated by Cognito):\nAuthentication: AWS4-HMAC-SHA256 Credential=test-1234567/20190821/us-east-1/cognito-idp/aws4_request ... Further reading For a more detailed example, please check out our sample repository.\n","categories":["LocalStack Pro"],"description":"Cognito\n","excerpt":"Cognito\n","ref":"/aws/cognito/","tags":"","title":"Cognito"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/continuous-delivery/","tags":"","title":"continuous-delivery"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/continuous-integration/","tags":"","title":"continuous-integration"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/dns/","tags":"","title":"DNS"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/docker/","tags":"","title":"docker"},{"body":"","categories":"","description":"","excerpt":"","ref":"/","tags":"","title":"Documentation"},{"body":"Pro LocalStack Pro supports the Docker backend for running instances.\nThe Docker backend uses the Docker Engine to emulate EC2 instances. All limitations that apply to containers apply to EC2 instances backed by the Docker manager, including root access and networking. Access to the Docker socket is required which can be made available to LocalStack by mounting the socket file during launch.\nInstances have the Docker socket (/var/run/docker.sock) mounted inside them, making Docker-in-Docker use cases possible.\nBase Images LocalStack uses a naming scheme to recognise and manage the containers and images associated with it. Containers are named localstack-ec2.\u003cInstanceId\u003e, while images are tagged localstack-ec2/\u003cAmiName\u003e:\u003cAmiId\u003e.\nThe Docker backend treats Docker images with the above naming scheme as AMIs. For example, the following command can be used to associate the Ubuntu Focal image as ami-000001.\n$ docker tag ubuntu:focal localstack-ec2/ubuntu-focal-ami:ami-000001 These Docker-backed AMIs have the resource tag ec2_vm_manager:docker and can be listed with the following command:\n$ awslocal ec2 describe-images --filters Name=tag:ec2_vm_manager,Values=docker All other AMIs are ‚Äòmocked‚Äô and are based off the community edition of LocalStack. Attempting to launch Dockerised instances with these AMIs will return InvalidAMIID.NotFound error.\nNetworking LocalStack supports assignment of unique private IP addresses for Dockerised instances. To leverage this feature, it is necessary to run the LocalStack daemon process on the host which takes care of creating and managing networking on the host system.\n$ pip install localstack[runtime] $ export LOCALSTACK_API_KEY=... $ localstack daemons start The address for SSH access to the instance is printed in the logs when the instance is initialised.\n2022-03-21T14:46:49.540:INFO:localstack_ext.services.ec2.vmmanager.docker: Instance i-f6a80f48 will be accessible via SSH at: 192.168.123.25:22, 127.0.0.1:48805 If the LocalStack daemon is not running, the instance will be only accessible over SSH at 127.0.0.1 and the specified port.\nThe LocalStack daemon is supported on Linux and MacOS.\nSecurity Groups are not applied to Dockerised instances. Ports other than 22 (SSH) are currently not exposed.\nOperations The Docker backend supports following operations:\n   Operation Notes     CreateImage Uses Docker commit to take a snapshot of a running instance into a new AMI   DescribeImages Retrieve a list of Docker images available for use within LocalStack   DescribeInstances Describe ‚Äòmock‚Äô instances as well as Docker-backed instances. Docker-backed instances have the resource tag ec2_vm_manager:docker   RunInstances Launch an instance. Supports ImageId, MaxCount, KeyPair and UserData parameters   StopInstances Corresponds to pausing a container   StartInstances Corresponds to unpausing a container   TerminateInstances Corresponds to stopping a container    ","categories":["LocalStack Pro"],"description":"Amazon Elastic Compute Cloud (Amazon EC2)","excerpt":"Amazon Elastic Compute Cloud (Amazon EC2)","ref":"/aws/elastic-compute-cloud/","tags":"","title":"Elastic Compute Cloud (EC2)"},{"body":"A basic version of Elastic Container Registry (ECR) is available to store application images. ECR is often used in combination with other APIs that deploy containerized apps, like ECS or EKS.\n$ awslocal ecr create-repository --repository-name repo1 { \"repository\": { \"repositoryArn\": \"arn:aws:ecr:us-east-1:000000000000:repository/repo1\", \"registryId\": \"abc898c8\", \"repositoryName\": \"repo1\", \"repositoryUri\": \"localhost:4510/repo1\" } } You can then build and tag a new Docker image, and push it to the repository URL (localhost:4510/repo1 in the example above): $ cat Dockerfile FROM nginx ENV foo=bar\n$ docker build -t localhost:4510/repo1 . ... Successfully built e2cfb3cf012d Successfully tagged localhost:4510/repo1:latest $ docker push localhost:4510/repo1 The push refers to repository [localhost:4510/repo1] 318be7aea8fc: Pushed fe08d5d042ab: Pushed f2cb0ecef392: Pushed latest: digest: sha256:4dd893a43df24c8f779a5ab343b7ef172fb147c69ed5e1278d95b97fe0f584a5 size: 948 ... ","categories":["LocalStack Pro"],"description":"Elastic Container Registry (ECR)\n","excerpt":"Elastic Container Registry (ECR)\n","ref":"/aws/elastic-container-registry/","tags":"","title":"Elastic Container Registry (ECR)"},{"body":"LocalStack Pro version provides a basic support for creating and deploying containerized apps using Amazon ECS. LocalStack offers the basic APIs locally, including creation of ECS task definitions, services, and tasks.\nBy default, the ECS Fargate launch type is assumed, i.e., the local Docker engine is used for deployment of applications, and there is no need to create and manage EC2 virtual machines to run the containers.\nNote: More complex features like integration of application load balancers (ALBs) are currently not available. Nonetheless, they are being developed and will be available in the near future.  Task instances are started in a local Docker engine, which needs to be accessible to the LocalStack container. The name pattern for task containers is localstack_\u003cfamily\u003e_\u003crevision\u003e, where \u003cfamily\u003e refers to the task family and \u003crevision\u003e refers to a task revision (for example, localstack_nginx_1).\nYou can use the configuration option LAMBDA_DOCKER_NETWORK to specify the network the ECS containers are started in. If your ECS containers depend on LocalStack services, this should be the network the LocalStack container is located in. For more information regarding the configuration of LocalStack, please check the LocalStack configuration section.\nIf you are running LocalStack through a docker run command, do not forget to enable the communication from the container to the Docker Engine API. You can provide the access by adding the following option -v /var/run/docker.sock:/var/run/docker.sock.\n","categories":["LocalStack Pro"],"description":"Elastic Container Service (ECS)\n","excerpt":"Elastic Container Service (ECS)\n","ref":"/aws/elastic-container-service/","tags":"","title":"Elastic Container Service (ECS)"},{"body":"LocalStack Pro allows you to use the EKS API to create Kubernetes clusters and easily deploy containerized apps locally.\nThere are two modes for creating EKS clusters on LocalStack:\n spinning up an embedded kube cluster in your local Docker engine (preferred, simpler), or using an existing Kubernetes installation you can access from your local machine (defined in $HOME/.kube/config)  Auto-installing an embedded Kubernetes cluster The default method for creating Kubernetes clusters via the local EKS API is to spin up an embedded k3d kube cluster within Docker. LocalStack handles the download and installation transparently - on most systems the installation is performed automatically, and no customizations should be required.\nA new cluster can be created using the following command: $ awslocal eks create-cluster --name cluster1 --role-arn r1 --resources-vpc-config '{}'\nYou should then see some Docker containers getting started, e.g.: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b335f7f089e4 rancher/k3d-proxy:5.0.1-rc.1 \"/bin/sh -c nginx-pr‚Ä¶\" 1 minute ago Up 1 minute 0.0.0.0:8081-\u003e80/tcp, 0.0.0.0:44959-\u003e6443/tcp k3d-cluster1-serverlb f05770ec8523 rancher/k3s:v1.21.5-k3s2 \"/bin/k3s server --t‚Ä¶\" 1 minute ago Up 1 minute\nOnce the cluster has been created and initialized, we can determine the server endpoint: $ awslocal eks describe-cluster --name cluster1 { \"cluster\": { \"name\": \"cluster1\", \"status\": \"ACTIVE\", \"endpoint\": \"https://localhost.localstack.cloud:4513\", ... } }\nWe can then configure the kubectl command line to interact with the new cluster endpoint: $ awslocal eks update-kubeconfig --name cluster1 Updated context arn:aws:eks:us-east-1:000000000000:cluster/cluster1 in ~/.kube/config $ kubectl config use-context arn:aws:eks:us-east-1:000000000000:cluster/cluster1 Switched to context \"arn:aws:eks:us-east-1:000000000000:cluster/cluster1\". $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.43.0.1 \u003cnone\u003e 443/TCP 70s\nUse images pushed to ECR in EKS In this section we will, by the use of an example, explore the usage of ECR images inside EKS.\nInitial configuration You can use the configuration variable HOSTNAME_EXTERNAL to modify the return value of the resource URIs for most services, including ECR. By default, ECR will return a repositoryUri starting with localhost, like: localhost:\u003cport\u003e/\u003crepository-name\u003e. If we set the HOSTNAME_EXTERNAL to localhost.localstack.cloud, ECR will return a repositoryUri like localhost.localstack.cloud:\u003cport\u003e/\u003crepository_name\u003e.\nNotes In this section, we will assume localhost.localstack.cloud resolves in your environment and LocalStack is connected to a non-default bridge network. Check the article about DNS rebind protection to learn more. If this domain does not resolve on your host it is also possible not to set HOSTNAME_EXTERNAL, please nevertheless use localhost.localstack.cloud as registry in your pod configuration. LocalStack will take care of the DNS resolution of localhost.localstack.cloud within ECR itself, and you can use the localhost:\u003cport\u003e/\u003crepository_name\u003e Uri for tagging and pushing the image on your host.  If this configuration is correct, you can use your ECR image in EKS like expected.\nDeploying a sample application from an ECR image In order to demonstrate this behavior, take a look at the following small tutorial which leads to the point where the image is correctly pulled. For the sake of this tutorial, we will retag the nginx image to be pushed to ECR using another name, and use it for a pod configuration. First, we create a new repository with a chosen name: $ awslocal ecr create-repository --repository-name \"fancier-nginx\" { \"repository\": { \"repositoryArn\": \"arn:aws:ecr:us-east-1:000000000000:repository/fancier-nginx\", \"registryId\": \"c75fd0e2\", \"repositoryName\": \"fancier-nginx\", \"repositoryUri\": \"localhost.localstack.cloud:4510/fancier-nginx\", \"createdAt\": \"2022-04-13T14:22:47+02:00\", \"imageTagMutability\": \"MUTABLE\", \"imageScanningConfiguration\": { \"scanOnPush\": false }, \"encryptionConfiguration\": { \"encryptionType\": \"AES256\" } } }\nNote: When creating an ECR, a port from the the external service port range is dynamically selected.\nTherefore, the port can differ from 4510 used in the samples below. Make sure to use the correct URL / port by using the repositoryUrl of the create-repository request.  Now let us pull the nginx image: $ docker pull nginx ‚Ä¶ tag it to our repository name: $ docker tag nginx localhost.localstack.cloud:4510/fancier-nginx ‚Ä¶ and push it to ECR: $ docker push localhost.localstack.cloud:4510/fancier-nginx\nNow, let us set up the EKS cluster using the image pushed to local ECR. $ awslocal eks create-cluster --name fancier-cluster --role-arn \"r1\" --resources-vpc-config \"{}\" { \"cluster\": { \"name\": \"fancier-cluster\", \"arn\": \"arn:aws:eks:us-east-1:000000000000:cluster/fancier-cluster\", \"createdAt\": \"2022-04-13T16:38:24.850000+02:00\", \"roleArn\": \"r1\", \"resourcesVpcConfig\": {}, \"identity\": { \"oidc\": { \"issuer\": \"https://localhost.localstack.cloud/eks-oidc\" } }, \"status\": \"CREATING\", \"clientRequestToken\": \"cbdf2bb6-fd3b-42b1-afe0-3c70980b5959\" } }\nOnce the cluster status is ‚ÄúACTIVE‚Äù: awslocal eks describe-cluster --name \"fancier-cluster\" { \"cluster\": { \"name\": \"fancier-cluster\", \"arn\": \"arn:aws:eks:us-east-1:000000000000:cluster/fancier-cluster\", \"createdAt\": \"2022-04-13T17:12:39.738000+02:00\", \"endpoint\": \"https://localhost.localstack.cloud:4511\", \"roleArn\": \"r1\", \"resourcesVpcConfig\": {}, \"identity\": { \"oidc\": { \"issuer\": \"https://localhost.localstack.cloud/eks-oidc\" } }, \"status\": \"ACTIVE\", \"certificateAuthority\": { \"data\": \"...\" }, \"clientRequestToken\": \"d188f578-b353-416b-b309-5d8c76ecc4e2\" } }\n‚Ä¶ we will configure kubectl: $ awslocal eks update-kubeconfig --name fancier-cluster \u0026\u0026 kubectl config use-context arn:aws:eks:us-east-1:000000000000:cluster/fancier-cluster Added new context arn:aws:eks:us-east-1:000000000000:cluster/fancier-cluster to /home/localstack/.kube/config Switched to context \"arn:aws:eks:us-east-1:000000000000:cluster/fancier-cluster\".\n‚Ä¶ and add a deployment configuration: $ cat \u003c\u003cEOF | kubectl apply -f - apiVersion: apps/v1 kind: Deployment metadata: name: fancier-nginx labels: app: fancier-nginx spec: replicas: 1 selector: matchLabels: app: fancier-nginx template: metadata: labels: app: fancier-nginx spec: containers: - name: fancier-nginx image: localhost.localstack.cloud:4510/fancier-nginx:latest ports: - containerPort: 80 EOF\nNow, if we describe the pod: kubectl describe pod fancier-nginx ‚Ä¶ we can see, in the events, that the pull from ECR was successful:\n Normal Pulled 10s kubelet Successfully pulled image \"localhost.localstack.cloud:4510/fancier-nginx:latest\" in 2.412775896s Configuring an Ingress for your services In order to make an EKS service externally accessible, we need to create an Ingress configuration that exposes the service on a certain path to the load balancer.\nWe can create an nginx Kubernetes service for our sample deployment above by applying the following configuration: $ cat \u003c\u003cEOF | kubectl apply -f - apiVersion: v1 kind: Service metadata: name: nginx spec: selector: app: fancier-nginx ports: - name: http protocol: TCP port: 80 targetPort: 80 EOF\nNow use the following ingress configuration to expose the nginx service on path /test123:\n$ cat \u003c\u003cEOF | kubectl apply -f - apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: nginx annotations: ingress.kubernetes.io/ssl-redirect: \"false\" spec: rules: - http: paths: - path: /test123 pathType: Prefix backend: service: name: nginx port: number: 80 EOF We should then be able to send a request to nginx via the load balancer port 8081 from the host: $ curl http://localhost:8081/test123 \u003chtml\u003e ... \u003chr\u003e\u003ccenter\u003enginx/1.21.6\u003c/center\u003e ...\nNote You can customize the load balancer port by configuring EKS_LOADBALANCER_PORT in your environment.  Using an existing Kubernetes installation You can also use the EKS API using an existing local Kubernetes installation. This works by mounting the $HOME/.kube/config file into the LocalStack container - e.g., when using docker-compose.yml:\nvolumes:- \"${HOME}/.kube/config:/root/.kube/config\"In recent versions of Docker, you can simply enable Kubernetes as an embedded service running inside Docker. See below for a screenshot of the Docker settings for Kubernetes in MacOS (similar configurations apply for Linux/Windows). By default, it is asssumed that Kubernetes API runs on the local TCP port 6443.\nThe example below illustrates how to create an EKS cluster configuration (assuming you have awslocal installed): $ awslocal eks create-cluster --name cluster1 --role-arn r1 --resources-vpc-config '{}' { \"cluster\": { \"name\": \"cluster1\", \"arn\": \"arn:aws:eks:eu-central-1:000000000000:cluster/cluster1\", \"createdAt\": \"Sat, 05 Oct 2019 12:29:26 GMT\", \"endpoint\": \"https://172.17.0.1:6443\", \"status\": \"ACTIVE\", ... } } $ awslocal eks list-clusters { \"clusters\": [ \"cluster1\" ] }\nSimply configure your Kubernetes client (e.g., kubectl or other SDK) to point to the endpoint specified in the create-cluster output above. Depending on whether you‚Äôre calling the Kubernetes API from the local machine or from within a Lambda, you may have to use different endpoint URLs (https://localhost:6443 vs https://172.17.0.1:6443).\nMounting directories from host to pod If you have specific directories which you want to mount from your local dev machine into one of your pods you can do this with two simple steps:\nFirst, make sure to create your cluster with the special tag __k3d_volume_mount__, specifying how you want to mount a volume from your dev machine to the cluster nodes:\n$ awslocal eks create-cluster --name cluster1 --role-arn r1 --resources-vpc-config '{}' --tags '{\"__k3d_volume_mount__\":\"/path/on/host:/path/on/node\"}' { \"cluster\": { \"name\": \"cluster1\", \"arn\": \"arn:aws:eks:eu-central-1:000000000000:cluster/cluster1\", \"createdAt\": \"Sat, 05 Oct 2019 12:29:26 GMT\", \"endpoint\": \"https://172.17.0.1:6443\", \"status\": \"ACTIVE\", \"tags\": { \"__k3d_volume_mount__\" : \"/path/on/host:/path/on/node\" } ... } } Then, you can create your path with volume mounts as usual, with a configuration similar to this:\napiVersion:v1kind:Podmetadata:name:testspec:volumes:- name:example-volumehostPath:path:/path/on/nodecontainers:- image:alpine:3.12command:[\"/bin/sh\",\"-c\"]args:- echo \"Starting the update command\";apk update;echo \"Adding the openssh command\";apk add openssh;echo \"openssh completed\";sleep 240m;imagePullPolicy:IfNotPresentname:alpinevolumeMounts:- mountPath:\"/path/on/pod\"name:example-volumerestartPolicy:Always","categories":["LocalStack Pro"],"description":"Elastic Kubernetes Service (EKS)\n","excerpt":"Elastic Kubernetes Service (EKS)\n","ref":"/aws/elastic-kubernetes-service/","tags":"","title":"Elastic Kubernetes Service (EKS)"},{"body":"Pro LocalStack Pro supports Elastic Load Balancing operations for both version 1 and 2.\nApplication load balancers also support request forwarding to IP address and Lambda targets.\nIP Targets This example illustrates a load balancer configured for an IP target.\nStart an HTTP server which will serve as the target of our load balancer.\n$ docker run -itd -p 5678:5678 docker.io/hashicorp/http-echo:latest -text 'hello from the IP target' Create the load balancer, target group and register the target, which is the above Docker container in this case.\n$ awslocal ec2 describe-subnets --filters Name=availability-zone,Values=us-east-1f \\ | jq .Subnets[].SubnetId \"subnet-22d4f64a\" $ awslocal elbv2 create-load-balancer --name example-lb --subnets subnet-22d4f64a \\ | jq '.LoadBalancers[]|.LoadBalancerArn,.DNSName' \"arn:aws:elasticloadbalancing:us-east-1:112233445566:loadbalancer/app/example-lb/50dc6c495c0c9188\" \"example-lb.elb.localhost.localstack.cloud\" $ awslocal elbv2 create-target-group --name example-target-group --protocol HTTP --target-type ip \\ | jq .TargetGroups[].TargetGroupArn \"arn:aws:elasticloadbalancing:us-east-1:112233445566:targetgroup/example-target-group/50dc6c495c0c9188\" $ awslocal elbv2 register-targets \\ --targets Id=127.0.0.1,Port=5678,AvailabilityZone=all \\ --target-group-arn arn:aws:elasticloadbalancing:us-east-1:112233445566:targetgroup/example-target-group/50dc6c495c0c9188 Create a listener and a rule so that incoming requests are forwarded to the target.\n$ awslocal elbv2 create-listener \\ --default-actions '{\"Type\":\"forward\",\"TargetGroupArn\":\"arn:aws:elasticloadbalancing:us-east-1:112233445566:targetgroup/example-target-group/50dc6c495c0c9188\",\"ForwardConfig\":{\"TargetGroups\":[{\"TargetGroupArn\":\"arn:aws:elasticloadbalancing:us-east-1:112233445566:targetgroup/example-target-group/50dc6c495c0c9188\",\"Weight\":11}]}}' \\ --load-balancer-arn arn:aws:elasticloadbalancing:us-east-1:112233445566:loadbalancer/app/example-lb/50dc6c495c0c9188 \\ | jq '.Listeners[]|.ListenerArn,.Port' \"arn:aws:elasticloadbalancing:us-east-1:112233445566:listener/app/example/50dc6c495c0c9188/4566140160361637296\" 4566 $ awslocal elbv2 create-rule \\ --conditions Field=path-pattern,Values=/ \\ --priority 1 \\ --actions '{\"Type\":\"forward\",\"TargetGroupArn\":\"arn:aws:elasticloadbalancing:us-east-1:112233445566:targetgroup/example-target-group/50dc6c495c0c9188\",\"ForwardConfig\":{\"TargetGroups\":[{\"TargetGroupArn\":\"arn:aws:elasticloadbalancing:us-east-1:112233445566:targetgroup/example-target-group/50dc6c495c0c9188\",\"Weight\":11}]}}' \\ --listener-arn arn:aws:elasticloadbalancing:us-east-1:112233445566:listener/app/example/50dc6c495c0c9188/4566140160361637296 \\ | jq .Rules[].RuleArn \"arn:aws:elasticloadbalancing:us-east-1:112233445566:listener-rule/app/example/50dc6c495c0c9188/4566140160361637296/60d9790dd44c69e5\" Finally, issue HTTP request to the DNSName parameter of CreateLoadBalancer operation, and Port parameter of CreateListener command. In the above example, these parameter are filtered using jq.\n$ curl example-lb.elb.localhost.localstack.cloud:4566 hello from the IP target ","categories":["LocalStack Pro"],"description":"Elastic Load Balancing","excerpt":"Elastic Load Balancing","ref":"/aws/elastic-load-balancing/","tags":"","title":"Elastic Load Balancing"},{"body":"LocalStack Pro allows running data analytics workloads locally via the EMR API. EMR utilizes various tools in the Hadoop and Spark ecosystem, and your EMR instance is automatically configured to connect seamlessly to the LocalStack S3 API.\nTo create a virtual EMR cluster locally from the command line (assuming you have awslocal installed): $ awslocal emr create-cluster --release-label emr-5.9.0 --instance-groups InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m4.large InstanceGroupType=CORE,InstanceCount=1,InstanceType=m4.large { \"ClusterId\": \"j-A2KF3EKLAOWRI\" }\nThe commmand above will spin up one more more Docker containers on your local machine that can be used to run analytics workloads using Spark, Hadoop, Pig, and other tools.\nNote that you can also specify startup commands using the --steps=... command line argument to the create-cluster command. A simple demo project with more details can be found in this Github repository.\nNote: In order to use the EMR API, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.5GB which includes Presto, Hive and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you‚Äôre on a decent internet connection when pulling the dependencies for the first time.  ","categories":["LocalStack Pro"],"description":"Elastic MapReduce (EMR)\n","excerpt":"Elastic MapReduce (EMR)\n","ref":"/aws/elastic-mapreduce/","tags":"","title":"Elastic MapReduce (EMR)"},{"body":"A basic version of ElastiCache is provided. By default, the API is started on http://localhost:4598 and supports running a local Redis instance (Memcached support coming soon).\nAfter starting LocalStack Pro, you can test the following commands: $ awslocal elasticache create-cache-cluster --cache-cluster-id i1 { \"CacheCluster\": { \"CacheClusterId\": \"i1\", \"ConfigurationEndpoint\": { \"Address\": \"localhost\", \"Port\": 4510 } ... } }\nThen use the returned port number (4510) to connect to the Redis instance: $ redis-cli -p 4510 ping PONG $ redis-cli -p 4510 set foo bar OK $ redis-cli -p 4510 get foo \"bar\"\nWe also support the create-replication-group API which supports the replication groups in ElastiCache clusters. With the API, you can now have a Redis cluster, a Redis replication group with cluster mode disabled, and a Redis replication group with cluster mode enabled.\nNote: Redis requires at least 3+ nodes to form a Redis replication group with cluster mode enabled. Hence, if the user requests only 2 node groups, we transparently upgrade to 3 nodes behind the scenes, to avoid raising an error.  ","categories":["LocalStack Pro"],"description":"ElastiCache\n","excerpt":"ElastiCache\n","ref":"/aws/elasticache/","tags":"","title":"ElastiCache"},{"body":"The Elasticsearch Service in LocalStack lets you create one or more single-node Elasticsearch/OpenSearch cluster that behaves like the Amazon Elasticsearch Service. This service is, like its AWS counterpart, heavily linked with the OpenSearch Service. Any cluster created with the Elasticsearch Service will show up in the OpenSearch Service and vice versa.\nCreating an Elasticsearch cluster You can go ahead and use awslocal to create a new elasticsearch domain via the aws es create-elasticsearch-domain command.\nNote: Unless you use the Elasticsearch default version, the first time you create a cluster with a specific version, the Elasticsearch binary is downloaded, which may take a while to download.  Note: The default Elasticsearch version used is 7.10.0. This is a slight deviation from the default version used in AWS (Elasticsearch 1.5), which is not supported in LocalStack.  $ awslocal es create-elasticsearch-domain --domain-name my-domain { \"DomainStatus\": { \"DomainId\": \"000000000000/my-domain\", \"DomainName\": \"my-domain\", \"ARN\": \"arn:aws:es:us-east-1:000000000000:domain/my-domain\", \"Created\": true, \"Deleted\": false, \"Endpoint\": \"my-domain.us-east-1.es.localhost.localstack.cloud:4566\", \"Processing\": true, \"ElasticsearchVersion\": \"7.10.0\", \"ElasticsearchClusterConfig\": { \"InstanceType\": \"m3.medium.elasticsearch\", \"InstanceCount\": 1, \"DedicatedMasterEnabled\": true, \"ZoneAwarenessEnabled\": false, \"DedicatedMasterType\": \"m3.medium.elasticsearch\", \"DedicatedMasterCount\": 1 }, \"EBSOptions\": { \"EBSEnabled\": true, \"VolumeType\": \"gp2\", \"VolumeSize\": 10, \"Iops\": 0 }, \"CognitoOptions\": { \"Enabled\": false } } } In the LocalStack log you will see something like the following, where you can see the cluster starting up in the background.\n2021-11-08T16:29:28:INFO:localstack.services.es.cluster: starting elasticsearch: /opt/code/localstack/localstack/localstack/infra/elasticsearch/bin/elasticsearch -E http.port=57705 -E http.publish_port=57705 -E transport.port=0 -E network.host=127.0.0.1 -E http.compression=false -E path.data=\"/var/lib/localstack/lib//elasticsearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/data\" -E path.repo=\"/var/lib/localstack/lib//elasticsearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/backup\" -E xpack.ml.enabled=false with env {'ES_JAVA_OPTS': '-Xms200m -Xmx600m', 'ES_TMPDIR': '/var/lib/localstack/lib//elasticsearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/tmp'} 2021-11-08T16:29:28:INFO:localstack.services.es.cluster: registering an endpoint proxy for http://my-domain.us-east-1.es.localhost.localstack.cloud:4566 =\u003e http://127.0.0.1:57705 2021-11-08T16:29:30:INFO:localstack.services.es.cluster: OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. 2021-11-08T16:29:32:INFO:localstack.services.es.cluster: [2021-11-08T16:29:32,502][INFO ][o.e.n.Node ] [noctua] version[7.10.0], pid[22403], build[default/tar/51e9d6f22758d0374a0f3f5c6e8f3a7997850f96/2020-11-09T21:30:33.964949Z], OS[Linux/5.4.0-89-generic/amd64], JVM[Ubuntu/OpenJDK 64-Bit Server VM/11.0.11/11.0.11+9-Ubuntu-0ubuntu2.20.04] 2021-11-08T16:29:32:INFO:localstack.services.es.cluster: [2021-11-08T16:29:32,510][INFO ][o.e.n.Node ] [noctua] JVM home [/usr/lib/jvm/java-11-openjdk-amd64], using bundled JDK [false] 2021-11-08T16:29:32:INFO:localstack.services.es.cluster: [2021-11-08T16:29:32,511][INFO ][o.e.n.Node ] [noctua] JVM arguments [-Xshare:auto, -Des.networkaddress.cache.ttl=60, -Des.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.locale.providers=SPI,COMPAT, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -Djava.io.tmpdir=/var/lib/localstack/lib//elasticsearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms200m, -Xmx600m, -XX:MaxDirectMemorySize=314572800, -Des.path.home=/opt/code/localstack/localstack/localstack/infra/elasticsearch, -Des.path.conf=/opt/code/localstack/localstack/localstack/infra/elasticsearch/config, -Des.distribution.flavor=default, -Des.distribution.type=tar, -Des.bundled_jdk=true] 2021-11-08T16:29:36:INFO:localstack.services.es.cluster: [2021-11-08T16:29:36,258][INFO ][o.e.p.PluginsService ] [noctua] loaded module [aggs-matrix-stats] 2021-11-08T16:29:36:INFO:localstack.services.es.cluster: [2021-11-08T16:29:36,259][INFO ][o.e.p.PluginsService ] [noctua] loaded module [analysis-common] 2021-11-08T16:29:36:INFO:localstack.services.es.cluster: [2021-11-08T16:29:36,260][INFO ][o.e.p.PluginsService ] [noctua] loaded module [constant-keyword] ... and after some time, you should see that the Processing state of the domain is set to false:\n$ awslocal es describe-elasticsearch-domain --domain-name my-domain | jq \".DomainStatus.Processing\" false Interact with the cluster You can now interact with the cluster at the cluster API endpoint for the domain, in this case http://my-domain.us-east-1.es.localhost.localstack.cloud:4566.\nFor example:\n$ curl http://my-domain.us-east-1.es.localhost.localstack.cloud:4566 { \"name\" : \"localstack\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"IC7E9daNSiepRBB9Ksul7w\", \"version\" : { \"number\" : \"7.10.0\", \"build_flavor\" : \"default\", \"build_type\" : \"tar\", \"build_hash\" : \"51e9d6f22758d0374a0f3f5c6e8f3a7997850f96\", \"build_date\" : \"2020-11-09T21:30:33.964949Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.7.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"You Know, for Search\" } Or the health endpoint:\n$ curl -s http://my-domain.us-east-1.es.localhost.localstack.cloud:4566/_cluster/health | jq . { \"cluster_name\": \"elasticsearch\", \"status\": \"green\", \"timed_out\": false, \"number_of_nodes\": 1, \"number_of_data_nodes\": 1, \"active_primary_shards\": 0, \"active_shards\": 0, \"relocating_shards\": 0, \"initializing_shards\": 0, \"unassigned_shards\": 0, \"delayed_unassigned_shards\": 0, \"number_of_pending_tasks\": 0, \"number_of_in_flight_fetch\": 0, \"task_max_waiting_in_queue_millis\": 0, \"active_shards_percent_as_number\": 100 } Advanced topics Endpoints There are three configurable strategies that govern how domain endpoints are created, and can be configured via the OPENSEARCH_ENDPOINT_STRATEGY (previously ES_ENDPOINT_STRATEGY) environment variable.\n   Value Format Description     domain \u003cdomain-name\u003e.\u003cregion\u003e.es.localhost.localstack.cloud:4566 This is the default strategy that uses the localhost.localstack.cloud domain to route to your localhost   path localhost:4566/es/\u003cregion\u003e/\u003cdomain-name\u003e An alternative that can be useful if you cannot resolve LocalStack‚Äôs localhost domain   port localhost:\u003cport-from-range\u003e Exposes the cluster(s) directly with ports from the external service port range   off  Deprecated. This value now reverts to the port setting, using a port from the given range instead of 4571    Regardless of the service from which the clusters were created, the domain of the cluster always corresponds to the engine type (OpenSearch or Elasticsearch) of the cluster. OpenSearch cluster therefore have opensearch in their domain (e.g. my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566) and Elasticsearch clusters have es in their domain (e.g. my-domain.us-east-1.es.localhost.localstack.cloud:4566)\nCustom Endpoints LocalStack allows you to set arbitrary custom endpoints for your clusters in the domain endpoint options. This can be used to overwrite the behavior of the endpoint strategies described above. You can also choose custom domains, however it is important to add the edge port (80/443 or by default 4566).\n$ awslocal es create-elasticsearch-domain --domain-name my-domain \\ --elasticsearch-version 7.10 \\ --domain-endpoint-options '{ \"CustomEndpoint\": \"http://localhost:4566/my-custom-endpoint\", \"CustomEndpointEnabled\": true }' Once the domain processing is complete, you can access the cluster:\n$ curl http://localhost:4566/my-custom-endpoint/_cluster/health Re-using a single cluster instance In some cases, you may not want to create a new cluster instance for each domain, for example when you are only interested in testing API interactions instead of actual Elasticsearch functionality. In this case, you can set OPENSEARCH_MULTI_CLUSTER=0 (previously ES_MULTI_CLUSTER). This will multiplex all domains to the same cluster, or return the same port every time when using the port endpoint strategy. This can however lead to unexpected behavior when persisting data into Elasticsearch, or creating clusters with different versions, so we do not recommend it.\nStorage Layout Elasticsearch will be organized in your state directory as follows:\nlocalstack@machine % tree -L 4 volume/state . ‚îú‚îÄ‚îÄ elasticsearch ‚îÇ ‚îî‚îÄ‚îÄ arn:aws:es:us-east-1:000000000000:domain ‚îÇ ‚îú‚îÄ‚îÄ my-cluster-1 ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ backup ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ data ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ tmp ‚îÇ ‚îú‚îÄ‚îÄ my-cluster-2 ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ backup ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ data ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ tmp Custom Elasticsearch backends LocalStack downloads elasticsearch asynchronously the first time you run the aws es create-elasticsearch-domain, so you will get the response from localstack first and then (after download/install) you will have your elasticsearch cluster running locally. You may not want this, and instead use your already running elasticsearch cluster. This can also be useful when you want to run a cluster with a custom configuration that localstack does not support.\nTo customize the elasticsearch backend, you can your own elasticsearch cluster locally and point localstack to it using the OPENSEARCH_CUSTOM_BACKEND (previously ES_CUSTOM_BACKEND) environment variable. Note that only a single backend can be configured, meaning that you will get a similar behavior as when you re-use a single cluster instance.\nExample The following shows a sample docker-compose file that contains a single-noded elasticsearch cluster and a basic localstack setp.\nversion:\"3.9\"services:elasticsearch:container_name:elasticsearchimage:docker.elastic.co/elasticsearch/elasticsearch:7.10.2environment:- node.name=elasticsearch- cluster.name=es-docker-cluster- discovery.type=single-node- bootstrap.memory_lock=true- \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"ports:- \"9200:9200\"ulimits:memlock:soft:-1hard:-1volumes:- data01:/usr/share/elasticsearch/datalocalstack:container_name:\"${LOCALSTACK_DOCKER_NAME-localstack_main}\"image:localstack/localstackports:- \"4566:4566\"depends_on:- elasticsearchenvironment:- ES_CUSTOM_BACKEND=http://elasticsearch:9200- DEBUG=${DEBUG- }- PERSISTENCE=${PERSISTENCE- }- LAMBDA_EXECUTOR=${LAMBDA_EXECUTOR- }- DOCKER_HOST=unix:///var/run/docker.sockvolumes:- \"${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack\"- \"/var/run/docker.sock:/var/run/docker.sock\"volumes:data01:driver:local  Run docker compose: $ docker-compose up -d\n  Create the Elasticsearch domain: $ awslocal es create-elasticsearch-domain \\ --domain-name mylogs-2 \\ --elasticsearch-version 7.10 \\ --elasticsearch-cluster-config '{ \"InstanceType\": \"m3.xlarge.elasticsearch\", \"InstanceCount\": 4, \"DedicatedMasterEnabled\": true, \"ZoneAwarenessEnabled\": true, \"DedicatedMasterType\": \"m3.xlarge.elasticsearch\", \"DedicatedMasterCount\": 3}' { \"DomainStatus\": { \"DomainId\": \"000000000000/mylogs-2\", \"DomainName\": \"mylogs-2\", \"ARN\": \"arn:aws:es:us-east-1:000000000000:domain/mylogs-2\", \"Created\": true, \"Deleted\": false, \"Endpoint\": \"mylogs-2.us-east-1.es.localhost.localstack.cloud:4566\", \"Processing\": true, \"ElasticsearchVersion\": \"7.10\", \"ElasticsearchClusterConfig\": { \"InstanceType\": \"m3.xlarge.elasticsearch\", \"InstanceCount\": 4, \"DedicatedMasterEnabled\": true, \"ZoneAwarenessEnabled\": true, \"DedicatedMasterType\": \"m3.xlarge.elasticsearch\", \"DedicatedMasterCount\": 3 }, \"EBSOptions\": { \"EBSEnabled\": true, \"VolumeType\": \"gp2\", \"VolumeSize\": 10, \"Iops\": 0 }, \"CognitoOptions\": { \"Enabled\": false } } }\n  If the Processing status is true, it means that the cluster is not yet healthy. You can run describe-elasticsearch-domain to receive the status: $ awslocal es describe-elasticsearch-domain --domain-name mylogs-2\n  Check the cluster health endpoint and create indices: $ curl mylogs-2.us-east-1.es.localhost.localstack.cloud:4566/_cluster/health {\"cluster_name\":\"es-docker-cluster\",\"status\":\"green\",\"timed_out\":false,\"number_of_nodes\":1,\"number_of_data_nodes\":1,\"active_primary_shards\":0,\"active_shards\":0,\"relocating_shards\":0,\"initializing_shards\":0,\"unassigned_shards\":0,\"delayed_unassigned_shards\":0,\"number_of_pending_tasks\":0,\"number_of_in_flight_fetch\":0,\"task_max_waiting_in_queue_millis\":0,\"active_shards_percent_as_number\":100.0}[~]\n  Create an example index: $ curl -X PUT mylogs-2.us-east-1.es.localhost.localstack.cloud:4566/my-index {\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"my-index\"}\n  Differences to AWS  By default, AWS only sets the Endpoint attribute of the cluster status once the cluster is up. LocalStack will return the endpoint immediately, but keep Processing = \"true\" until the cluster has been started. The CustomEndpointOptions allows arbitrary endpoint URLs, which is not allowed in AWS  ","categories":["LocalStack Community"],"description":"Amazon Elasticsearch Service\n","excerpt":"Amazon Elasticsearch Service\n","ref":"/aws/elasticsearch/","tags":"","title":"Elasticsearch Service"},{"body":"The Glue API in LocalStack Pro allows you to run ETL (Extract-Transform-Load) jobs locally, maintaining table metadata in the local Glue data catalog, and using the Spark ecosystem (PySpark/Scala) to run data processing workflows.\nNote: In order to run Glue jobs, some additional dependencies have to be fetched from the network, including a Docker image of apprx. 1.5GB which includes Spark, Presto, Hive and other tools. These dependencies are automatically fetched when you start up the service, so please make sure you‚Äôre on a decent internet connection when pulling the dependencies for the first time.  Creating Databases and Table Metadata The commands below illustrate the creation of some very basic entries (databases, tables) in the Glue data catalog: $ awslocal glue create-database --database-input '{\"Name\":\"db1\"}' $ awslocal glue create-table --database db1 --table-input '{\"Name\":\"table1\"}' $ awslocal glue get-tables --database db1 { \"TableList\": [ { \"Name\": \"table1\", \"DatabaseName\": \"db1\" } ] }\nRunning Scripts with Scala and PySpark Assuming we would like to deploy a simple PySpark script job.py in the local folder, we can first copy the script to an S3 bucket: $ awslocal s3 mb s3://glue-test $ awslocal s3 cp job.py s3://glue-test/job.py\nNext, we can create a job definition: $ awslocal glue create-job --name job1 --role r1 \\ --command '{\"Name\": \"pythonshell\", \"ScriptLocation\": \"s3://glue-test/job.py\"}' ‚Ä¶ and finally start the job: $ awslocal glue start-job-run --job-name job1 { \"JobRunId\": \"733b76d0\" } The returned JobRunId can be used to query the status job the job execution, until it becomes SUCCEEDED: $ awslocal glue get-job-run --job-name job1 --run-id 733b76d0 { \"JobRun\": { \"Id\": \"733b76d0\", \"Attempt\": 1, \"JobRunState\": \"SUCCEEDED\" } }\nFor a more detailed example illustrating how to run a local Glue PySpark job, please refer to this sample repository.\nImporting Athena Tables into Glue Data Catalog The Glue data catalog is integrated with Athena, and the database/table definitions can be imported via the import-catalog-to-glue API.\nAssume you are running the following Athena queries to create databases and table definitions:\nCREATEDATABASEdb2CREATEEXTERNALTABLEdb2.table1(a1Date,a2STRING,a3INT)LOCATION's3://test/table1'CREATEEXTERNALTABLEdb2.table2(a1Date,a2STRING,a3INT)LOCATION's3://test/table2'Then this command will import these DB/table definitions into the Glue data catalog: $ awslocal glue import-catalog-to-glue\n‚Ä¶ and finally they will be available in Glue: $ awslocal glue get-databases { \"DatabaseList\": [ ... { \"Name\": \"db2\", \"Description\": \"Database db2 imported from Athena\", \"TargetDatabase\": { \"CatalogId\": \"000000000000\", \"DatabaseName\": \"db2\" } } ] } $ awslocal glue get-tables --database-name db2 { \"TableList\": [ { \"Name\": \"table1\", \"DatabaseName\": \"db2\", \"Description\": \"Table db2.table1 imported from Athena\", \"CreateTime\": ... }, { \"Name\": \"table2\", \"DatabaseName\": \"db2\", \"Description\": \"Table db2.table2 imported from Athena\", \"CreateTime\": ... } ] }\nCrawlers Glue crawlers allow extracting metadata from structured data sources. The example below illustrates crawling tables and partition metadata from S3 buckets.\nFirst, we create an S3 bucket with a couple of items: $ awslocal s3 mb s3://test $ printf \"1, 2, 3, 4\\n5, 6, 7, 8\" \u003e /tmp/file.csv $ awslocal s3 cp /tmp/file.csv s3://test/table1/year=2021/month=Jan/day=1/file.csv $ awslocal s3 cp /tmp/file.csv s3://test/table1/year=2021/month=Jan/day=2/file.csv $ awslocal s3 cp /tmp/file.csv s3://test/table1/year=2021/month=Feb/day=1/file.csv $ awslocal s3 cp /tmp/file.csv s3://test/table1/year=2021/month=Feb/day=2/file.csv\nThen we can create and trigger the crawler: $ awslocal glue create-database --database-input '{\"Name\":\"db1\"}' $ awslocal glue create-crawler --name c1 --database-name db1 --role r1 --targets '{\"S3Targets\": [{\"Path\": \"s3://test/table1\"}]}' $ awslocal glue start-crawler --name c1\nFinally, we can query the table and partitions metadata that has been created by the crawler: $ awslocal glue get-tables --database-name db1 { \"TableList\": [{ \"Name\": \"table1\", \"DatabaseName\": \"db1\", \"PartitionKeys\": [ ... ] ... $ awslocal glue get-partitions --database-name db1 --table-name table1 { \"Partitions\": [{ \"Values\": [\"2021\", \"Jan\", \"1\"], \"DatabaseName\": \"db1\", \"TableName\": \"table1\", ...\nSchema Registry The Glue Schema Registry allows you to centrally discover, control, and evolve data stream schemas. With the Schema Registry, you can manage and enforce schemas and schema compatibilities in your streaming applications. It integrates nicely with Managed Streaming for Kafka (MSK).\nNote: Currently, LocalStack supports the AVRO dataformat for the Glue Schema Registry. Support for other dataformats will be added in the future.  $ awslocal glue create-registry --registry-name demo-registry { \"RegistryArn\": \"arn:aws:glue:us-east-1:000000000000:file-registry/demo-registry\", \"RegistryName\": \"demo-registry\" } $ awslocal glue create-schema --schema-name demo-schema --registry-id RegistryName=demo-registry --data-format AVRO --compatibility FORWARD \\ --schema-definition '{\"type\":\"record\",\"namespace\":\"Demo\",\"name\":\"Person\",\"fields\":[{\"name\":\"Name\",\"type\":\"string\"}]}' { \"RegistryName\": \"demo-registry\", \"RegistryArn\": \"arn:aws:glue:us-east-1:000000000000:file-registry/demo-registry\", \"SchemaName\": \"demo-schema\", \"SchemaArn\": \"arn:aws:glue:us-east-1:000000000000:schema/demo-registry/demo-schema\", \"DataFormat\": \"AVRO\", \"Compatibility\": \"FORWARD\", \"SchemaCheckpoint\": 1, \"LatestSchemaVersion\": 1, \"NextSchemaVersion\": 2, \"SchemaStatus\": \"AVAILABLE\", \"SchemaVersionId\": \"546d3220-6ab8-452c-bb28-0f1f075f90dd\", \"SchemaVersionStatus\": \"AVAILABLE\" } $ awslocal glue register-schema-version --schema-id SchemaName=demo-schema,RegistryName=demo-registry \\ --schema-definition '{\"type\":\"record\",\"namespace\":\"Demo\",\"name\":\"Person\",\"fields\":[{\"name\":\"Name\",\"type\":\"string\"}, {\"name\":\"Address\",\"type\":\"string\"}]}' { \"SchemaVersionId\": \"ee38732b-b299-430d-a88b-4c429d9e1208\", \"VersionNumber\": 2, \"Status\": \"AVAILABLE\" } You can find a more advanced sample in our localstack-pro-samples repository on GitHub, which showcases the integration with AWS MSK and automatic schema registrations (including schema rejections based on the compatibilities).\nFurther Reading The AWS Glue API is a fairly comprehensive service - more details can be found in the official AWS Glue Developer Guide.\nCurrent Limitations Support for triggers is currently limited - the basic API endpoints are implemented, but triggers are currently still under development (more details coming soon).\n","categories":["LocalStack Pro"],"description":"Glue\n","excerpt":"Glue\n","ref":"/aws/glue/","tags":"","title":"Glue"},{"body":"Overview The AWS SDK for Go, like other AWS SDKs, lets you set the endpoint when creating resource clients, which is the preferred way of integrating the Go SDK with LocalStack.\nThe Go SDK has two major versions, each with their own way of specifying the LocalStack endpoint:\n aws-sdk-go aws-sdk-go-v2  Examples Here is an example of how to create an S3 Client from a Session with the endpoint set to LocalStack. Full examples for both SDK versions can be found in our samples repository.\naws-go-sdk  aws-go-sdk-v2   package main import ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/service/s3\" \"github.com/aws/aws-sdk-go/aws/credentials\" ) func main() { // Initialize a session  sess, _ := session.NewSession(\u0026aws.Config{ Region: aws.String(\"us-east-1\"), Credentials: credentials.NewStaticCredentials(\"test\", \"test\", \"\"), S3ForcePathStyle: aws.Bool(true), Endpoint: aws.String(\"http://localhost:4566\"), }) // Create S3 service client  client := s3.New(sess) // ... } package main import ( \"context\" \"log\" \"github.com/aws/aws-sdk-go-v2/aws\" \"github.com/aws/aws-sdk-go-v2/config\" \"github.com/aws/aws-sdk-go-v2/service/s3\" ) func main() { awsEndpoint = \"http://localhost:4566\" awsRegion = \"us-east-1\" customResolver := aws.EndpointResolverFunc(func(service, region string) (aws.Endpoint, error) { if awsEndpoint != \"\" { return aws.Endpoint{ PartitionID: \"aws\", URL: awsEndpoint, SigningRegion: awsRegion, }, nil } // returning EndpointNotFoundError will allow the service to fallback to its default resolution  return aws.Endpoint{}, \u0026aws.EndpointNotFoundError{} }) awsCfg, err := config.LoadDefaultConfig(context.TODO(), config.WithRegion(awsRegion), config.WithEndpointResolver(customResolver), ) if err != nil { log.Fatalf(\"Cannot load the AWS configs: %s\", err) } // Create the resource client  client = s3.NewFromConfig(awsCfg, func(o *s3.Options) { o.UsePathStyle = true }) // ... }  Resources  localstack-aws-sdk-examples for Go AWS SDK for Go Official repository of the AWS SDK for Go (v1) Official repository of the AWS SDK for Go (v2)  ","categories":"","description":"How to use the Go AWS SDK with LocalStack.\n","excerpt":"How to use the Go AWS SDK with LocalStack.\n","ref":"/integrations/sdks/go/","tags":["sdk"],"title":"Go"},{"body":"By default, LocalStack uses not enforce security policies for client requests. In LocalStack Pro, the IAM security enforcement feature can be used to test your security policies and create a more realistic environment that more closely resembles real AWS.\nNote: The environment configuration ENFORCE_IAM=1 is required to enable this feature. (By default, IAM enforcement is disabled, and all APIs can be accessed without authentication.)  Below is a simple example that illustrates the use of IAM policy enforcement. It first attempts to create an S3 bucket with the default user (which fails), then create a user and attempts to create a bucket with that user (which fails again), and then finally attaches a policy to the user to allow s3:CreateBucket, which allows the bucket to be created. $ awslocal s3 mb s3://test make_bucket failed: s3://test An error occurred (AccessDeniedException) when calling the CreateBucket operation: Access to the specified resource is denied $ awslocal iam create-user --user-name test ... $ awslocal iam create-access-key --user-name test ... \"AccessKeyId\": \"AKIA4HPFP0TZHP3Z5VI6\", \"SecretAccessKey\": \"mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua\", ... $ export AWS_ACCESS_KEY_ID=AKIA4HPFP0TZHP3Z5VI6 AWS_SECRET_ACCESS_KEY=mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua $ awslocal s3 mb s3://test make_bucket failed: s3://test An error occurred (AccessDeniedException) when calling the CreateBucket operation: Access to the specified resource is denied $ awslocal iam create-policy --policy-name p1 --policy-document '{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Allow\",\"Action\":\"s3:CreateBucket\",\"Resource\":\"*\"}]}' ... $ awslocal iam attach-user-policy --user-name test --policy-arn arn:aws:iam::000000000000:policy/p1 $ awslocal s3 mb s3://test make_bucket: test\nPlease notice that by default if you do not have valid credentials representing a user or assumed role, LocalStack will identify requests as coming from the root user.\nNote: Credentials are currently extracted in the request but signature is not validated - exceptions apply for s3 presigned URLs, for example.  For example:\n$ awslocal sts get-caller-identity { \"UserId\": \"AKIAIOSFODNN7EXAMPLE\", \"Account\": \"000000000000\", \"Arn\": \"arn:aws:iam::000000000000:root\" } $ awslocal iam create-user --user-name test ... $ awslocal iam create-access-key --user-name test ... \"AccessKeyId\": \"AKIA4HPFP0TZHP3Z5VI6\", \"SecretAccessKey\": \"mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua\", ... $ export AWS_ACCESS_KEY_ID=AKIA4HPFP0TZHP3Z5VI6 AWS_SECRET_ACCESS_KEY=mwi/8Zhg8ypkJQmkdBq87UA3MbSa3x0HWnkcC/Ua $ awslocal sts get-caller-identity { \"UserId\": \"b2yxf5g824zklfx5ry8o\", \"Account\": \"000000000000\", \"Arn\": \"arn:aws:iam::000000000000:user/test\" } Explainable IAM Since 1.0, our policy engine logs output related to failed policy evaluation to the LocalStack log. There, you can see which additional policies are necessary for your request to succeed. You need to enable DEBUG=1 to see these log messages.\nFor example, let us try to add a policy for creating Lambda functions, but only pass lambda:CreateFunction as allowed action - iam:PassRole (which is also required) is missing:\nOur policy document policy_1.json:\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"FirstStatement\", \"Effect\": \"Allow\", \"Action\": \"lambda:CreateFunction\", \"Resource\": \"*\" } ] } Let us create a new user, put the policies, create access keys, and try to create a function with the user:\n$ awslocal iam create-user --user-name test-user { \"User\": { \"Path\": \"/\", \"UserName\": \"test-user\", \"UserId\": \"x8a2eu4mc91yqtjazvhp\", \"Arn\": \"arn:aws:iam::000000000000:user/test-user\", \"CreateDate\": \"2022-07-05T16:08:25.741000+00:00\" } } $ awslocal iam put-user-policy --user-name test-user --policy-name policy1 --policy-document file://policy_1.json $ awslocal iam create-access-key --user-name test-user $ export AWS_ACCESS_KEY_ID=... $ export AWS_SECRET_ACCESS_KEY=... $ awslocal lambda create-function --function-name test-function --role arn:aws:iam::000000000000:role/lambda-role --runtime python3.8 --handler handler.handler --zip-file fileb://function.zip An error occurred (AccessDeniedException) when calling the CreateFunction operation: Access to the specified resource is denied When looking in the LocalStack logs, we can now see 5 log entries specific to that (denied) request:\nINFO:localstack_ext.services.iam.policy_engine.handler: Request for service lambda for operation CreateFunction denied. DEBUG:localstack_ext.services.iam.policy_engine.handler: Necessary permissions for this action: [\"Action 'lambda:CreateFunction' for 'arn:aws:lambda:us-east-1:000000000000:function:test-function'\", \"Action 'iam:PassRole' for 'arn:aws:iam::000000000000:role/lambda-role'\"] DEBUG:localstack_ext.services.iam.policy_engine.handler: 0 permissions have been explicitly denied: [] DEBUG:localstack_ext.services.iam.policy_engine.handler: 1 permissions have been explicitly allowed: [\"Action 'lambda:CreateFunction' for 'arn:aws:lambda:us-east-1:000000000000:function:test-function'\"] DEBUG:localstack_ext.services.iam.policy_engine.handler: 1 permissions have been implicitly denied: [\"Action 'iam:PassRole' for 'arn:aws:iam::000000000000:role/lambda-role'\"] So we can see the action iam:PassRole is not allowed but implicitely denied (meaning there is no explicit deny statement in the applicable policies, but now allow either) for your user for resouce arn:aws:iam::000000000000:role/lambda-role. If we now add this to our policy (since it is an example let‚Äôs do it very simple with the same wildcard resource):\n{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"FirstStatement\", \"Effect\": \"Allow\", \"Action\": [\"lambda:CreateFunction\", \"iam:PassRole\"], \"Resource\": \"*\" } ] } the call is correctly executed.\nSoft Mode If you enable IAM_SOFT_MODE=1, you can look at the logs whether your requests would have been denied or not, while still being able to execute your whole stack without interference. This is especially useful when trying to find missing permissions over a whole stack (with resources depending on each other) at a time without having to redeploy for every missing permission.\nNote: As of 1.0, resource based policies and conditions are not yet supported. Please try keeping to identity-based policies where possible. Inter-service communcation evaluation (for example for sts:AssumeRole) also is not supported, which currently reduces the impact of those missing features.  Supported APIs IAM security enforcement is available for all the AWS APIs of LocalStack - it has been tested, among others, for the following services: ACM, API Gateway, CloudFormation, CloudWatch (metrics/events/logs), DynamoDB, DynamoDB Streams, Elasticsearch Service, EventBus, Kinesis, KMS, Lambda, Redshift, S3, SecretsManager, SNS, SQS.\n","categories":["LocalStack Pro"],"description":"Identity and Access Management (IAM)\n","excerpt":"Identity and Access Management (IAM)\n","ref":"/aws/iam/","tags":"","title":"Identity and Access Management (IAM)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/infrastructure-as-code/","tags":"","title":"infrastructure-as-code"},{"body":"Basic support for IoT (including IoT Analytics, IoT Data, and related APIs) is provided in the Pro version. The main endpoints for creating and updating entities are currently implemented, as well as the CloudFormation integrations for creating them.\nThe IoT API ships with a built-in MQTT message broker. In order to get the MQTT endpoint, the describe-endpoint API can be used; for example, using awslocal: $ awslocal iot describe-endpoint { \"endpointAddress\": \"localhost:4510\" }\nThis endpoint can then be used with any MQTT client to send/receive messages (e.g., using the endpoint URL mqtt://localhost:4510).\nLocalStack Pro also supports advanced features like SQL queries for IoT topic rules. For example, you can use the CreateTopicRule API to define a topic rule with a SQL query SELECT * FROM 'my/topic' where attr=123 which will trigger a Lambda function whenever a message with attribute attr=123 is received on the MQTT topic my/topic.\n","categories":["LocalStack Pro"],"description":"AWS IoT\n","excerpt":"AWS IoT\n","ref":"/aws/iot/","tags":"","title":"IoT"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/kafka/","tags":"","title":"kafka"},{"body":"AWS Kinesis is a fully managed data streaming service, which enables your application to ingest, buffer, and process data in real-time. Kinesis is shipped with the LocalStack Community version and is extensively supported.\nQuickstart Trying to run the example applications from the official AWS developer guide against LocalStack is a great place to start. Assuming you have awslocal installed you can also try out the following commands:\n$ awslocal kinesis create-stream --stream-name samplestream --shard-count 1 $ awslocal kinesis list-streams { \"StreamNames\": [ \"samplestream\" ] } $ awslocal kinesis put-record --stream-name samplestream --data '{\"symbol\":\"TEST\",\"sampleno\":42}' --partition-key test1 { \"ShardId\": \"shardId-000000000001\", \"SequenceNumber\": \"49622467803485029265018102167378141645049970239670845458\", \"EncryptionType\": \"NONE\" } Kinesis backend providers LocalStack supports two third-party providers for Kinesis:\n kinesis-mock kinesalite  By default kinesis-mock is used. Your desired provider can be set with the environment variable KINESIS_PROVIDER. For instance, if you wish to use kinesalite you‚Äôd pass the environment variable as KINESIS_PROVIDER=kinesalite. While both providers are supported, we recommend working with kinesis-mock, as it is more actively maintained. Moreover, the Cloud Pods feature provides support only for kinesis-mock.\nConfiguration Regardless of which provider you‚Äôre working with, Kinesis can be further configured with the following environment variables:\n   Variable Description     KINESIS_ERROR_PROBABILITY Decimal value between 0.0 (default) and 1.0. Typically, it is difficult to know beforehand whether your application can handle the throughput and whether it can deal with backpressure. By setting this environment variable the application will randomly inject ProvisionedThroughputException. While this won‚Äôt tell you whether your application can handle sufficient throughput, it does help you to test whether your application can handle exceptions gracefully.   KINESIS_SHARD_LIMIT Integer value (default: 100) or Infinity (to disable). This variable can help you to test whether your application adheres to the allocated shard limit. This behavior can only be disabled by explicitly setting the environment variable as KINESIS_SHARD_LIMIT=Infinity   KINESIS_LATENCY Integer value of milliseconds (default: 500) or 0 (to disable). Especially important for testing latency-critical applications. Since latency cannot be tested with the local Kinesis service, you can use this variable to introduce artificial latency into your AWS calls. This behavior can only be disabled by explicitly setting the environment variable as KINESIS_LATENCY=0.   KINESIS_INITIALIZE_STREAMS A comma-delimited string of stream names, its corresponding shard count and an optional region to initialize during startup. If the region is not provided, the default region is used. For instance, KINESIS_INITIALIZE_STREAMS=my-first-stream:1,my-other-stream:2:us-west-2,my-last-stream:1 Important: Only supported by kinesis-mock    ","categories":["LocalStack Community"],"description":"Explaining the different Kinesis providers and how to configure the service.\n","excerpt":"Explaining the different Kinesis providers and how to configure the ‚Ä¶","ref":"/aws/kinesis/","tags":"","title":"Kinesis"},{"body":"The Kinesis Data Analytics API allows you to run continuous SQL queries directly over your Kinesis data streams. Basic support is included in LocalStack Pro - it allows you to create Kinesis Analytics applications, define input and output streams and schema types, and run continuous queries locally.\nA simple example has been added to this sample repository on Github. More details are following soon.\n","categories":["LocalStack Pro","Stub"],"description":"Kinesis Data Analytics\n","excerpt":"Kinesis Data Analytics\n","ref":"/aws/kinesis-analytics/","tags":"","title":"Kinesis Data Analytics"},{"body":"Kinesis Data Firehose is a service to extract, transform and load (ETL service) data to multiple destinations. LocalStack supports Firehose with Kinesis as source, and S3, Elasticsearch or HttpEndpoints as targets.\nExamples We will provide some examples to illustrate the possibilities of Firehose in LocalStack.\nUsing Firehose to load Kinesis data into Elasticsearch with S3 Backup As example, we want to deliver data sent to a Kinesis stream into Elasticsearch via Firehose, while making a full backup into a S3 bucket. We will assume LocalStack is already started correctly and we have awslocal installed.\nFirst we will create our Elasticsearch domain:\n$ awslocal es create-elasticsearch-domain --domain-name es-local { \"DomainStatus\": { \"DomainId\": \"000000000000/es-local\", \"DomainName\": \"es-local\", \"ARN\": \"arn:aws:es:us-east-1:000000000000:domain/es-local\", \"Created\": true, \"Deleted\": false, \"Endpoint\": \"es-local.us-east-1.es.localhost.localstack.cloud:443\", \"Processing\": true, \"ElasticsearchVersion\": \"7.10.0\", \"ElasticsearchClusterConfig\": { \"InstanceType\": \"m3.medium.elasticsearch\", \"InstanceCount\": 1, \"DedicatedMasterEnabled\": true, \"ZoneAwarenessEnabled\": false, \"DedicatedMasterType\": \"m3.medium.elasticsearch\", \"DedicatedMasterCount\": 1 }, \"EBSOptions\": { \"EBSEnabled\": true, \"VolumeType\": \"gp2\", \"VolumeSize\": 10, \"Iops\": 0 }, \"CognitoOptions\": { \"Enabled\": false } } } We need the Endpoint returned here later for the confirmation of our setup.\nNow let us create our target S3 bucket and our source Kinesis stream:\n$ awslocal s3 mb s3://kinesis-activity-backup-local make_bucket: kinesis-activity-backup-local $ awslocal kinesis create-stream --stream-name kinesis-es-local-stream --shard-count 2 Next, we will create our Firehose delivery stream with Elasticsearch as destination, and S3 as target for our AllDocuments backup. We set the ARN of our Kinesis stream in the kinesis-stream-source-configuration as well as the role we want to use for accessing the stream. In the elasticsearch-destination-configuration we set (again) the access role, the DomainARN of the Elasticsearch domain we want to publish to, as well as IndexName and TypeName for Elasticsearch. Since we want to backup all documents to S3, we also set S3BackupMode to AllDocuments and provide a S3Configuration pointing to our created bucket.\nNote: In LocalStack, per default, the IAM roles will not be verified, so you can provide any ARN here. In AWS, you need to check the access rights of the specified role for the task.  $ awslocal firehose create-delivery-stream --delivery-stream-name activity-to-elasticsearch-local --delivery-stream-type KinesisStreamAsSource --kinesis-stream-source-configuration \"KinesisStreamARN=arn:aws:kinesis:us-east-1:000000000000:stream/kinesis-es-local-stream,RoleARN=arn:aws:iam::000000000000:role/Firehose-Reader-Role\" --elasticsearch-destination-configuration \"RoleARN=arn:aws:iam::000000000000:role/Firehose-Reader-Role,DomainARN=arn:aws:es:us-east-1:000000000000:domain/es-local,IndexName=activity,TypeName=activity,S3BackupMode=AllDocuments,S3Configuration={RoleARN=arn:aws:iam::000000000000:role/Firehose-Reader-Role,BucketARN=arn:aws:s3:::kinesis-activity-backup-local}\" { \"DeliveryStreamARN\": \"arn:aws:firehose:us-east-1:000000000000:deliverystream/activity-to-elasticsearch-local\" } Before testing the integration, we should check whether the Elasticsearch cluster is already started up. We can do this using the following command (for more information about this, check out the docs page about Elasticsearch.\n$ awslocal es describe-elasticsearch-domain --domain-name es-local | jq \".DomainStatus.Processing\" false Once this command returns false, we are ready to proceed with ingesting our data. We can input our data into our source Kinesis stream, our put it directly into the Firehose delivery stream.\nTo put it into Kinesis, run:\n $ awslocal kinesis put-record --stream-name kinesis_es-local_stream --data '{ \"target\": \"barry\" }' --partition-key partition { \"ShardId\": \"shardId-000000000001\", \"SequenceNumber\": \"49625461294598302663271645332877318906244481566013128722\", \"EncryptionType\": \"NONE\" } Note: If you are using aws cli v2, you can add --cli-binary-format raw-in-base64-out to the above command  Or directly into the Firehose delivery stream:\n$ awslocal firehose put-record --delivery-stream-name activity-to-elasticsearch-local --record '{ \"Data\": \"eyJ0YXJnZXQiOiAiSGVsbG8gd29ybGQifQ==\" }' { \"RecordId\": \"00333086-7581-48a2-bc7c-8ac1ed97ed3d\" } If we now check the entries we made in Elasticsearch (we will use curl for simplicity). Note to replace the url with the ‚ÄúEndpoint‚Äù field of our create-elasticsearch-domain operation at the beginning.\n$ curl -s http://es-local.us-east-1.es.localhost.localstack.cloud:443/activity/_search | jq '.hits.hits' [ { \"_index\": \"activity\", \"_type\": \"activity\", \"_id\": \"f38e2c49-d101-46aa-9ce2-0d2ea8fcd133\", \"_score\": 1, \"_source\": { \"target\": \"Hello world\" } }, { \"_index\": \"activity\", \"_type\": \"activity\", \"_id\": \"d2f1c125-b3b0-4c7c-ba90-8acf4075a682\", \"_score\": 1, \"_source\": { \"target\": \"barry\" } } ] If you get a similar output, you have correctly set up a Firehose delivery stream! Also checkout the specified S3 bucket to check if your backup is working correctly.\n","categories":["LocalStack Community"],"description":"Kinesis Data Firehose\n","excerpt":"Kinesis Data Firehose\n","ref":"/aws/kinesis-firehose/","tags":"","title":"Kinesis Data Firehose"},{"body":"AWS Lambda is a Serverless Function as a Service (FaaS) system that allows you to write code in your favorite programming language and run it on the AWS ecosystem. Unlike deploying your code on a server, you can now break down your application into many independent functions and deploy them as a singular units. With the help of AWS Lambda, you can strive for more modular code that can be tested and debugged while integrated with the AWS infrastructure and your core system.\nLocalStack allows you to execute your Lambda functions locally, without the need to deploy them to AWS. This is a great way to test your code, and to learn more about how your Lambda functions work, before deploying them to AWS. LocalStack allows you to execute your Lambda functions, in various execution modes, which is detailed on our Lambda execution modes page.\nSpecial tooling for Lambdas We also provide tools to help you develop, debug and test your Lambda functions more efficiently:\n Hot swapping: Hot code swapping for Lambda functions using LocalStack‚Äôs code mounting feature. Remote debugging: Attaching a debugger to your Lambda function using your IDE.  Lambda sample applications LocalStack Pro samples contains a number of code examples that demonstrate how to use LocalStack to execute Lambda functions:\n Lambda XRay Tracing: Simple demo application illustrating Lambda XRay tracing using LocalStack, deployed via the Serverless framework. Lambda Container Images: Simple demo application illustrating Lambda container images in LocalStack. The Lambda image is built using Docker and pushed to a local ECR registry. Lambda Code Mounting and Debugging: Simple demo application to illustrate debugging Lambdas locally. Lambda Layers: Simple demo application illustrating Lambda layers using LocalStack, deployed via the Serverless framework.  Lambda Container Images LocalStack Pro supports Lambda functions defined as container images, so you can bundle your code and dependencies as one container image.\nPlease make sure bash and python 2/3 is installed inside your container image for the integration with LocalStack to work.  Lambda Layers Lambda layers are an AWS feature that allows to pull in additional code and content into your Lambda functions.\nLocalStack Pro provides support for deploying Lambda layers locally - for more details on general usage, please follow the documentation and examples in the AWS documentation on Lambda layers.\nCreating Lambda layers locally To create a Lambda layer locally, you can simply use the PublishLayerVersion API against LocalStack. Below is a simple example for creating a Lambda layer in Python with a util() function that prints some test output.\n$ mkdir -p /tmp/python/ $ echo 'def util():' \u003e /tmp/python/testlayer.py $ echo ' print(\"Output from Lambda layer util function\")' \u003e\u003e /tmp/python/testlayer.py $ (cd /tmp; zip -r testlayer.zip python) $ LAYER_ARN=$(awslocal lambda publish-layer-version --layer-name layer1 --zip-file fileb:///tmp/testlayer.zip | jq -r .LayerArn) We can then create a simple Lambda function which references and imports the Lambda layer: $ echo 'def handler(*args, **kwargs):' \u003e /tmp/testlambda.py $ echo ' import testlayer; testlayer.util()' \u003e\u003e /tmp/testlambda.py $ echo ' print(\"Debug output from Lambda function\")' \u003e\u003e /tmp/testlambda.py $ (cd /tmp; zip testlambda.zip testlambda.py) $ awslocal lambda create-function --function-name func1 --runtime python3.8 --role r1 --handler testlambda.handler --timeout 30 --zip-file fileb:///tmp/testlambda.zip --layers $LAYER_ARN:1\nOnce we invoke the Lambda function, we should see the following logs in the LocalStack container (with DEBUG=1 enabled), which includes the output from the layer util function:\n\u003e START RequestId: a8bc4ce6-e2e8-189e-cf58-c2eb72827c23 Version: $LATEST \u003e Output from Lambda layer util function \u003e Debug output from Lambda function \u003e END RequestId: a8bc4ce6-e2e8-189e-cf58-c2eb72827c23 Referencing Lambda layers from real AWS Alternatively, if your Lambda function references a layer in real AWS, there is also a mechanism to integrate such a remote layer into your local dev environment.\nIn order to achieve that, you‚Äôll need to make your Lambda layer accessible from the 886468871268 AWS account ID (this is an account managed by LocalStack on AWS). Assuming you‚Äôve created a layer named test-layer with version 1, you can use the following command to grant access to your layer:\n$ aws lambda add-layer-version-permission --layer-name test-layer --version-number 1 --statement-id layerAccessFromLocalStack --principal 886468871268 --action lambda:GetLayerVersion Next time you reference this layer (with the real AWS Lambda layer ARN) in one of your local Lambda functions, it will get automatically pulled down and integrated into your local dev environment.\n","categories":["LocalStack Community","LocalStack Pro"],"description":"Supporting local development and testing of AWS Lambdas on LocalStack\n","excerpt":"Supporting local development and testing of AWS Lambdas on LocalStack\n","ref":"/aws/lambda/","tags":"","title":"Lambda"},{"body":"","categories":"","description":"How to use your favorite cloud development SDK with LocalStack.\n","excerpt":"How to use your favorite cloud development SDK with LocalStack.\n","ref":"/integrations/sdks/","tags":"","title":"Language SDKs"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/localstack-cockpit/","tags":"","title":"LocalStack Cockpit"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/localstack-pro-enterprise/","tags":"","title":"LocalStack Pro \u0026 Enterprise"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/m1/","tags":"","title":"m1"},{"body":"LocalStack supports a basic version of Managed Streaming for Kafka (MSK) for testing. This allows you to spin up Kafka clusters on the local machine, create topics for exchanging messages, and define event source mappings that trigger Lambda functions when messages are received on a certain topic.\nCreate a local MSK Cluster Prerequisites  Java 8  To create a local MSK cluster, the following create-cluster example creates an MSK cluster named EventsCluster with three broker nodes. A JSON file named brokernodegroupinfo.json specifies the three subnets over which you want yout local Amazon MSK to distribute the broker nodes. This example doesn‚Äôt specify the monitoring level, so the cluster gets the DEFAULT level.\n$ awslocal kafka create-cluster \\ --cluster-name \"EventsCluster\" \\ --broker-node-group-info file://brokernodegroupinfo.json \\ --kafka-version \"2.2.1\" \\ --number-of-broker-nodes 3 The brokernodegroupinfo.json contains the following info: { \"InstanceType\": \"kafka.m5.xlarge\", \"BrokerAZDistribution\": \"DEFAULT\", \"ClientSubnets\": [ \"subnet-01\", \"subnet-02\", \"subnet-03\" ] } The output of the command looks similar to this: { \"ClusterArn\": \"arn:aws:kafka:us-east-1:000000000000:cluster/EventsCluster/b154d18a-8ecb-4691-96b2-50348357fc2f-25\", \"ClusterName\": \"EventsCluster\", \"State\": \"CREATING\" }\nDescribing the MSK cluster can be achieved by running the following command. Replace the ClusterArn with your own.\nawslocal kafka describe-cluster --cluster-arn \"arn:aws:kafka:us-east-1:000000000000:cluster/EventsCluster/b154d18a-8ecb-4691-96b2-50348357fc2f-25\" The expected output is something like the following\n{ \"ClusterInfo\": { \"BrokerNodeGroupInfo\": { \"BrokerAZDistribution\": \"DEFAULT\", \"ClientSubnets\": [ \"subnet-01\", \"subnet-02\", \"subnet-03\" ], \"InstanceType\": \"kafka.m5.xlarge\" }, \"ClusterArn\": \"arn:aws:kafka:us-east-1:000000000000:cluster/EventsCluster/b154d18a-8ecb-4691-96b2-50348357fc2f-25\", \"ClusterName\": \"EventsCluster\", \"CreationTime\": \"2022-06-29T02:45:16.848000Z\", \"CurrentBrokerSoftwareInfo\": { \"KafkaVersion\": \"2.5.0\" }, \"CurrentVersion\": \"K5OWSPKW0IK7LM\", \"NumberOfBrokerNodes\": 3, \"State\": \"ACTIVE\", \"ZookeeperConnectString\": \"localhost:4510\" } } Create a kafka topic In this step of using LocalStack MSK, we‚Äôll download and use the Kafka command line interface (CLI) to create a topic that produces and consumes data.\nRun the following command to download Apache Kafka.\nwget https://archive.apache.org/dist/kafka/2.2.1/kafka_2.12-2.2.1.tgz tar -xzf kafka_2.12-2.2.1.tgz Now, Go to the kafka_2.12-2.2.1 directory.\nThe cluster creation can take a few minutes. To find out whether the cluster you created is ready, run the following command, replacing ClusterArn with the Amazon Resource Name (ARN) that you obtained above when you created then Cluster.\nawslocal kafka describe-cluster --cluster-arn \"arn:aws:kafka:us-east-1:000000000000:cluster/EventsCluster\" Run the following command, replacing ZookeeperConnectString with the value that you saved after you ran the describe-cluster command.\nbin/kafka-topics.sh --create --zookeeper localhost:4510 --replication-factor 1 --partitions 1 --topic LocalMSKTopic Your output should be similar to this one\nCreated topic LocalMSKTopic. Interacting with the topic In this example we use the JVM truststore to talk to the MSK cluster. To do this, first create a folder named /tmp on the client machine. Then, go to the bin folder of the Apache Kafka installation and run the following command, replacing java_home with the path of your java_home. In this instance, the java_home is  /Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin/Contents/Home.\n Note: The following step is optional and may not be required, depending on the operating system environment being used.\n cp java_home/lib/security/cacerts /tmp/kafka.client.truststore.jks While still in the bin folder of the Apache Kafka installation on the client machine, create a text file named client.properties with the following contents.\nssl.truststore.location=/tmp/kafka.client.truststore.jks Run the following command, replacing ClusterArn with the Amazon Resource Name (ARN).\nawslocal kafka get-bootstrap-brokers --cluster-arn ClusterArn From the JSON result of the command, save the value associated with the string named ‚ÄúBootstrapBrokerStringTls‚Äù because you need it in the following commands.\n{ \"BootstrapBrokerString\": \"localhost:4511\" } Run the following command in the bin folder, replacing BootstrapBrokerStringTls with the value that you obtained when you ran the previous command.\n./kafka-console-producer.sh --broker-list BootstrapBrokerStringTls --producer.config client.properties --topic LocalMSKTopic Enter any message that you want, and press Enter. Repeat this step two or three times. Every time you enter a line and press Enter, that line is sent to your Apache Kafka cluster as a separate message.\nKeep the connection to the client machine open, and then open a second, separate connection to that machine in a new window.\nIn the following command, replace BootstrapBrokerStringTls with the value that you saved earlier. Then, go to the bin folder and run the command using your second connection to the client machine.\n./kafka-console-consumer.sh --bootstrap-server BootstrapBrokerStringTls --consumer.config client.properties --topic LocalMSKTopic --from-beginning You start seeing the messages you entered earlier when you used the console producer command. These messages are TLS encrypted in transit.\nEnter more messages in the producer window, and watch them appear in the consumer window.\nLocal MSK and Lambdas Adding a local MSK trigger The following example uses the Lambda Event Source Mapping API to map a Lambda function named my-kafka-function to a Kafka topic named LocalMSKTopic. The topic‚Äôs starting position is set to LATEST.\nawslocal lambda create-event-source-mapping \\ --event-source-arn arn:aws:kafka:us-east-1:000000000000:cluster/EventsCluster \\ --topics LocalMSKTopic \\ --starting-position LATEST \\ --function-name my-kafka-function The following response is to be expected\n{ \"UUID\": \"9c353a2b-bc1a-48b5-95a6-04baf67f01e4\", \"StartingPosition\": \"LATEST\", \"BatchSize\": 100, \"ParallelizationFactor\": 1, \"EventSourceArn\": \"arn:aws:kafka:us-east-1:000000000000:cluster/EventsCluster\", \"FunctionArn\": \"arn:aws:lambda:us-east-1:000000000000:function:my-kafka-function\", \"LastModified\": \"2021-11-21T20:55:49.438914+01:00\", \"LastProcessingResult\": \"OK\", \"State\": \"Enabled\", \"StateTransitionReason\": \"User action\", \"Topics\": [ \"LocalMSKTopic\" ] } Using this event source mapping, LocalStack will automatically spawn Lambda functions for each message that gets published to the target Kafka topic. You can use the kafka-console-producer.sh client script (see above) to publish messages to the topic, and then observe the LocalStack log output to see how Lambda function are executed (in Docker containers) as new messages arrive.\nDelete the local MSK cluster Run the following command to list your MSK clusters\nawslocal kafka list-clusters --region us-east-1 From the list of clusters, pick the ClusterARN of the cluster you want deleted and run the command\nawslocal kafka delete-cluster --cluster-arn ClusterArn ","categories":["LocalStack Pro"],"description":"Managed Streaming for Kafka (MSK)\n","excerpt":"Managed Streaming for Kafka (MSK)\n","ref":"/aws/managed-streaming-for-kafka/","tags":"","title":"Managed Streaming for Kafka (MSK)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/multi-account/","tags":"","title":"multi-account"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/multi-tenant/","tags":"","title":"multi-tenant"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/namespaces/","tags":"","title":"namespaces"},{"body":"The Neptune API provides a graph database to store nodes and edges that can be accessed via Apache TinkerPop and Gremlin queries.\nFor example, you can create a Neptune cluster like this:\nimport boto3 from gremlin_python.driver import client as gremlin_client client = boto3.client('neptune', endpoint_url='http://localhost:4566') cluster = client.create_db_cluster(DBClusterIdentifier='c1', Engine='neptune')['DBCluster'] cluster_url = 'ws://localhost:%s/gremlin' % cluster['Port'] graph_client = gremlin_client.Client(cluster_url, 'g') ‚Ä¶ and then submit and query values to the DB like this:\nvalues = '[1,2,3,4]' result_set = graph_client.submit(values) results = result_set.all().result() assert results == [1, 2, 3, 4] For a simple Neptune sample running on LocalStack, please refer to this Github repository.\n","categories":["LocalStack Pro"],"description":"Amazon Neptune\n","excerpt":"Amazon Neptune\n","ref":"/aws/neptune/","tags":"","title":"Neptune"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/observability/","tags":"","title":"observability"},{"body":"The OpenSearch Service in LocalStack lets you create one or more single-node OpenSearch clusters that behave like the Amazon OpenSearch Service. This service is, like its AWS counterpart, heavily linked with the Elasticsearch Service. Any cluster created with the OpenSearch Service will show up in the Elasticsearch Service and vice versa.\nCreating an OpenSearch cluster You can go ahead and use awslocal to create a new OpenSearch domain via the aws opensearch create-domain command.\nNote: Everytime when you create a cluster with a version of OpenSearch you haven‚Äôt used before, the OpenSearch binary for the respective version needs to be downloaded, which may take a while.  Note: The default OpenSearch version used is 1.1.0.  $ awslocal opensearch create-domain --domain-name my-domain { \"DomainStatus\": { \"DomainId\": \"000000000000/my-domain\", \"DomainName\": \"my-domain\", \"ARN\": \"arn:aws:es:us-east-1:000000000000:domain/my-domain\", \"Created\": true, \"Deleted\": false, \"Endpoint\": \"my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566\", \"Processing\": true, \"UpgradeProcessing\": false, \"EngineVersion\": \"OpenSearch_1.1\", \"ClusterConfig\": { \"InstanceType\": \"m3.medium.search\", \"InstanceCount\": 1, \"DedicatedMasterEnabled\": true, \"ZoneAwarenessEnabled\": false, \"DedicatedMasterType\": \"m3.medium.search\", \"DedicatedMasterCount\": 1, \"WarmEnabled\": false, \"ColdStorageOptions\": { \"Enabled\": false } }, \"EBSOptions\": { \"EBSEnabled\": true, \"VolumeType\": \"gp2\", \"VolumeSize\": 10, \"Iops\": 0 }, \"AccessPolicies\": \"\", \"SnapshotOptions\": { \"AutomatedSnapshotStartHour\": 0 }, \"CognitoOptions\": { \"Enabled\": false }, \"EncryptionAtRestOptions\": { \"Enabled\": false }, \"NodeToNodeEncryptionOptions\": { \"Enabled\": false }, \"AdvancedOptions\": { \"override_main_response_version\": \"false\", \"rest.action.multi.allow_explicit_index\": \"true\" }, \"ServiceSoftwareOptions\": { \"CurrentVersion\": \"\", \"NewVersion\": \"\", \"UpdateAvailable\": false, \"Cancellable\": false, \"UpdateStatus\": \"COMPLETED\", \"Description\": \"There is no software update available for this domain.\", \"AutomatedUpdateDate\": 0.0, \"OptionalDeployment\": true }, \"DomainEndpointOptions\": { \"EnforceHTTPS\": false, \"TLSSecurityPolicy\": \"Policy-Min-TLS-1-0-2019-07\", \"CustomEndpointEnabled\": false }, \"AdvancedSecurityOptions\": { \"Enabled\": false, \"InternalUserDatabaseEnabled\": false }, \"AutoTuneOptions\": { \"State\": \"ENABLE_IN_PROGRESS\" } } } In the LocalStack log you will see something like, where you can see the cluster starting up in the background.\n2022-01-13T10:36:29.436:INFO:localstack.services.opensearch.cluster: starting opensearch: /var/lib/localstack/libs/opensearch/1.1.0/bin/opensearch -E http.port=35403 -E http.publish_port=35403 -E transport.port=0 -E network.host=127.0.0.1 -E http.compression=false -E path.data=\"/var/lib/localstack/opensearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/data\" -E path.repo=\"/var/lib/localstack/opensearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/backup\" -E plugins.security.disabled=true with env {'OPENSEARCH_JAVA_OPTS': '-Xms200m -Xmx600m', 'OPENSEARCH_TMPDIR': '/var/lib/localstack/opensearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/tmp'} 2022-01-13T10:36:29.437:INFO:localstack.services.opensearch.cluster: registering an endpoint proxy for http://my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566 =\u003e http://127.0.0.1:35403 2022-01-13T10:36:32.803:INFO:localstack.services.opensearch.cluster: [2022-01-13T10:36:32,800][INFO ][o.o.n.Node ] [host-pc] version[1.1.0], pid[231895], build[tar/15e9f137622d878b79103df8f82d78d782b686a1/2021-10-04T21:29:03.079792Z], OS[Linux/5.11.0-46-generic/amd64], JVM[AdoptOpenJDK/OpenJDK 64-Bit Server VM/15.0.1/15.0.1+9] 2022-01-13T10:36:32.805:INFO:localstack.services.opensearch.cluster: [2022-01-13T10:36:32,805][INFO ][o.o.n.Node ] [host-pc] JVM home [/var/lib/localstack/libs/opensearch/1.1.0/jdk], using bundled JDK [true] 2022-01-13T10:36:32.806:INFO:localstack.services.opensearch.cluster: [2022-01-13T10:36:32,805][INFO ][o.o.n.Node ] [host-pc] JVM arguments [-Xshare:auto, -Dopensearch.networkaddress.cache.ttl=60, -Dopensearch.networkaddress.cache.negative.ttl=10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -XX:+ShowCodeDetailsInExceptionMessages, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dio.netty.allocator.numDirectArenas=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -Djava.locale.providers=SPI,COMPAT, -XX:+UseG1GC, -XX:G1ReservePercent=25, -XX:InitiatingHeapOccupancyPercent=30, -Djava.io.tmpdir=/var/lib/localstack/opensearch/arn:aws:es:us-east-1:000000000000:domain/my-domain/tmp, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath=data, -XX:ErrorFile=logs/hs_err_pid%p.log, -Xlog:gc*,gc+age=trace,safepoint:file=logs/gc.log:utctime,pid,tags:filecount=32,filesize=64m, -Xms200m, -Xmx600m, -XX:MaxDirectMemorySize=314572800, -Dopensearch.path.home=/var/lib/localstack/libs/opensearch/1.1.0, -Dopensearch.path.conf=/var/lib/localstack/libs/opensearch/1.1.0/config, -Dopensearch.distribution.type=tar, -Dopensearch.bundled_jdk=true] ... and after some time, you should see that the Processing state of the domain is set to false:\n$ awslocal opensearch describe-domain --domain-name my-domain | jq \".DomainStatus.Processing\" false Creating an Elasticsearch cluster Like in AWS, the OpenSearch service can create Elasticsearch clusters and manage them. To do so, you can use awslocal and select an Elasticsearch version with the --engine-version parameter of the awslocal opensearch create-domain command. For an overview of existing Elasticsearch versions you can use awslocal opensearch list-versions.\nInteract with the cluster You can now interact with the cluster at the cluster API endpoint for the domain, in this case http://my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566.\nFor example:\n$ curl http://my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566 { \"name\" : \"host-pc\", \"cluster_name\" : \"opensearch\", \"cluster_uuid\" : \"DMN-2TlwRkuhMH4aRRqrkA\", \"version\" : { \"distribution\" : \"opensearch\", \"number\" : \"1.1.0\", \"build_type\" : \"tar\", \"build_hash\" : \"15e9f137622d878b79103df8f82d78d782b686a1\", \"build_date\" : \"2021-10-04T21:29:03.079792Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.9.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" }, \"tagline\" : \"The OpenSearch Project: https://opensearch.org/\" } Or the health endpoint:\n$ curl -s http://my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566/_cluster/health | jq . { \"cluster_name\": \"opensearch\", \"status\": \"green\", \"timed_out\": false, \"number_of_nodes\": 1, \"number_of_data_nodes\": 1, \"discovered_master\": true, \"active_primary_shards\": 0, \"active_shards\": 0, \"relocating_shards\": 0, \"initializing_shards\": 0, \"unassigned_shards\": 0, \"delayed_unassigned_shards\": 0, \"number_of_pending_tasks\": 0, \"number_of_in_flight_fetch\": 0, \"task_max_waiting_in_queue_millis\": 0, \"active_shards_percent_as_number\": 100 } Advanced topics Endpoints There are two configurable strategies that govern how domain endpoints are created. The strategy can be configured via the OPENSEARCH_ENDPOINT_STRATEGY environment variable.\n   Value Format Description     domain \u003cdomain-name\u003e.\u003cregion\u003e.\u003cengine-type\u003e.localhost.localstack.cloud:4566 This is the default strategy that uses the localhost.localstack.cloud domain to route to your localhost   path localhost:4566/\u003cengine-type\u003e/\u003cregion\u003e/\u003cdomain-name\u003e An alternative that can be useful if you cannot resolve LocalStack‚Äôs localhost domain   port localhost:\u003cport-from-range\u003e Exposes the cluster(s) directly with ports from the external service port range    Regardless of the service from which the clusters were created, the domain of the cluster always corresponds to the engine type (OpenSearch or Elasticsearch) of the cluster. OpenSearch cluster therefore have opensearch in their domain (e.g. my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566) and Elasticsearch clusters have es in their domain (e.g. my-domain.us-east-1.es.localhost.localstack.cloud:4566)\nCustom Endpoints LocalStack allows you to set arbitrary custom endpoints for your clusters in the domain endpoint options. This can be used to overwrite the behavior of the endpoint strategies described above. You can also choose custom domains, however it is important to add the edge port (80/443 or by default 4566).\n$ awslocal opensearch create-domain --domain-name my-domain \\ --domain-endpoint-options '{ \"CustomEndpoint\": \"http://localhost:4566/my-custom-endpoint\", \"CustomEndpointEnabled\": true }' Once the domain processing is complete, you can access the cluster:\n$ curl http://localhost:4566/my-custom-endpoint/_cluster/health Re-using a single cluster instance In some cases, you may not want to create a new cluster instance for each domain, for example when you are only interested in testing API interactions instead of actual OpenSearch functionality. In this case, you can set OPENSEARCH_MULTI_CLUSTER=0, which will multiplex all domains to the same cluster. This can however lead to unexpected behavior when persisting data into OpenSearch, or creating clusters with different versions, so we do not recommend it.\nStorage Layout OpenSearch will be organized in your state directory as follows:\nlocalstack@machine % tree -L 4 ./volume/state ./volume/state ‚îú‚îÄ‚îÄ opensearch ‚îÇ ‚îî‚îÄ‚îÄ arn:aws:es:us-east-1:000000000000:domain ‚îÇ ‚îú‚îÄ‚îÄ my-cluster-1 ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ backup ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ data ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ tmp ‚îÇ ‚îú‚îÄ‚îÄ my-cluster-2 ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ backup ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ data ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ tmp Custom OpenSearch backends LocalStack downloads OpenSearch asynchronously the first time you run the aws opensearch create-domain, so you will get the response from LocalStack first and then (after download/install) you will have your OpenSearch cluster running locally. You may not want this, and instead use your already running OpenSearch cluster. This can also be useful when you want to run a cluster with a custom configuration that LocalStack does not support.\nTo customize the OpenSearch backend, you can start your own OpenSearch cluster locally and point LocalStack to it using the OPENSEARCH_CUSTOM_BACKEND environment variable. Note that only a single backend can be configured, meaning that you will get a similar behavior as when you re-use a single cluster instance.\nExample The following shows a sample docker-compose.yaml file that contains a single-node OpenSearch cluster and a basic LocalStack setup.\nversion:\"3.9\"services:opensearch:container_name:opensearchimage:opensearchproject/opensearch:1.1.0environment:- node.name=opensearch- cluster.name=opensearch-docker-cluster- discovery.type=single-node- bootstrap.memory_lock=true- \"OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m\"- \"DISABLE_SECURITY_PLUGIN=true\"ports:- \"9200:9200\"ulimits:memlock:soft:-1hard:-1volumes:- data01:/usr/share/opensearch/datalocalstack:container_name:\"${LOCALSTACK_DOCKER_NAME-localstack_main}\"image:localstack/localstackports:- \"4566:4566\"depends_on:- opensearchenvironment:- OPENSEARCH_CUSTOM_BACKEND=http://opensearch:9200- DEBUG=${DEBUG- }- PERSISTENCE=${PERSISTENCE- }- DOCKER_HOST=unix:///var/run/docker.sockvolumes:- \"${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack\"- \"/var/run/docker.sock:/var/run/docker.sock\"volumes:data01:driver:local  Run docker compose: $ docker-compose up -d\n  Create the OpenSearch domain: $ awslocal opensearch create-domain --domain-name my-domain { \"DomainStatus\": { \"DomainId\": \"000000000000/my-domain\", \"DomainName\": \"my-domain\", \"ARN\": \"arn:aws:es:us-east-1:000000000000:domain/my-domain\", \"Created\": true, \"Deleted\": false, \"Endpoint\": \"my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566\", \"Processing\": false, \"UpgradeProcessing\": false, \"EngineVersion\": \"OpenSearch_1.1\", \"ClusterConfig\": { \"InstanceType\": \"m3.medium.search\", \"InstanceCount\": 1, \"DedicatedMasterEnabled\": true, \"ZoneAwarenessEnabled\": false, \"DedicatedMasterType\": \"m3.medium.search\", \"DedicatedMasterCount\": 1, \"WarmEnabled\": false, \"ColdStorageOptions\": { \"Enabled\": false } }, \"EBSOptions\": { \"EBSEnabled\": true, \"VolumeType\": \"gp2\", \"VolumeSize\": 10, \"Iops\": 0 }, \"AccessPolicies\": \"\", \"SnapshotOptions\": { \"AutomatedSnapshotStartHour\": 0 }, \"CognitoOptions\": { \"Enabled\": false }, \"EncryptionAtRestOptions\": { \"Enabled\": false }, \"NodeToNodeEncryptionOptions\": { \"Enabled\": false }, \"AdvancedOptions\": { \"override_main_response_version\": \"false\", \"rest.action.multi.allow_explicit_index\": \"true\" }, \"ServiceSoftwareOptions\": { \"CurrentVersion\": \"\", \"NewVersion\": \"\", \"UpdateAvailable\": false, \"Cancellable\": false, \"UpdateStatus\": \"COMPLETED\", \"Description\": \"There is no software update available for this domain.\", \"AutomatedUpdateDate\": 0.0, \"OptionalDeployment\": true }, \"DomainEndpointOptions\": { \"EnforceHTTPS\": false, \"TLSSecurityPolicy\": \"Policy-Min-TLS-1-0-2019-07\", \"CustomEndpointEnabled\": false }, \"AdvancedSecurityOptions\": { \"Enabled\": false, \"InternalUserDatabaseEnabled\": false }, \"AutoTuneOptions\": { \"State\": \"ENABLE_IN_PROGRESS\" } } }\n  If the Processing status is true, it means that the cluster is not yet healthy. You can run decribe-domain to receive the status: $ awslocal opensearch describe-domain --domain-name my-domain\n  Check the cluster health endpoint and create indices: $ curl my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566/_cluster/health | jq { \"name\": \"host-pc\", \"cluster_name\": \"opensearch\", \"cluster_uuid\": \"DMN-2TlwRkuhMH4aRRqrkA\", \"version\": { \"distribution\": \"opensearch\", \"number\": \"1.1.0\", \"build_type\": \"tar\", \"build_hash\": \"15e9f137622d878b79103df8f82d78d782b686a1\", \"build_date\": \"2021-10-04T21:29:03.079792Z\", \"build_snapshot\": false, \"lucene_version\": \"8.9.0\", \"minimum_wire_compatibility_version\": \"6.8.0\", \"minimum_index_compatibility_version\": \"6.0.0-beta1\" }, \"tagline\": \"The OpenSearch Project: https://opensearch.org/\" }\n  Create an example index: $ curl -X PUT my-domain.us-east-1.opensearch.localhost.localstack.cloud:4566/my-index {\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"my-index\"}\n  Differences to AWS  By default, AWS only sets the Endpoint attribute of the cluster status once the cluster is up. LocalStack will return the endpoint immediately, but keep Processing = \"true\" until the cluster has been started. The CustomEndpointOptions allows arbitrary endpoint URLs, which is not allowed in AWS.  Troubleshooting If you are using the OPENSEARCH_ENDPOINT_STRATEGY=domain (which is the default) and are having issues with resolving the subdomains, please check if your DNS blocks rebind queries.\n","categories":["LocalStack Community"],"description":"Amazon OpenSearch Service (successor to Amazon Elasticsearch Service)\n","excerpt":"Amazon OpenSearch Service (successor to Amazon Elasticsearch Service)\n","ref":"/aws/opensearch/","tags":"","title":"OpenSearch Service"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/persistence/","tags":"","title":"Persistence"},{"body":"Overview The AWS SDK for PHP, like other AWS SDKs, lets you set the endpoint when creating resource clients, which is the preferred way of integrating the PHP SDK with LocalStack.\nExample Here is an example of how to create an S3Client with the endpoint set to LocalStack.\nuse Aws\\S3\\S3Client; use Aws\\Exception\\AwsException; // Configuring S3 Client $s3 = new Aws\\S3\\S3Client([ 'version' =\u003e '2006-03-01', 'region' =\u003e 'us-east-1', // Enable 'use_path_style_endpoint' =\u003e true, if bucket name is non DNS compliant  'use_path_style_endpoint' =\u003e true, 'endpoint' =\u003e 'http://s3.localhost.localstack.cloud:4566', ]); A full example can be found in our samples repository.\nResources  localstack-aws-sdk-examples for PHP AWS SDK for PHP Official repository of the AWS SDK for PHP  ","categories":"","description":"How to use the PHP AWS SDK with LocalStack.\n","excerpt":"How to use the PHP AWS SDK with LocalStack.\n","ref":"/integrations/sdks/php/","tags":["sdk"],"title":"PHP"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/podman/","tags":"","title":"podman"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/pulumi/","tags":"","title":"pulumi"},{"body":"Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of AWS services.\nYou can easily create a boto3 client that interacts with your LocalStack instance. The example below creates a boto3 client that lists all available Lambda functions:\nimport boto3 endpoint_url = \"http://localhost.localstack.cloud:4566\" # alternatively, to use HTTPS endpoint on port 443: # endpoint_url = \"https://localhost.localstack.cloud\" def main(): client = boto3.client(\"lambda\", endpoint_url=endpoint_url) result = client.list_functions() print(result) if __name__ == \"__main__\": main() Note: If you‚Äôre connecting from within a Python Lambda function handler in LocalStack, you can create a default client without configuring the endpoint_url - LocalStack will automatically forward the invocations to the local API endpoints (available in Pro, see here for more details).\nclient = boto3.client(\"lambda\") ... Alternatively, if you prefer to (or need to) set the endpoints directly, you can use the $LOCALSTACK_HOSTNAME environment variable which is available when executing user code (e.g., Lambda functions, ECS containers) in LocalStack:\nimport os endpoint_url = f\"http://{os.getenv(\"LOCALSTACK_HOSTNAME\")}:{os.getenv(\"EDGE_PORT\")}\" client = boto3.client(\"lambda\", endpoint_url=endpoint_url) ... Further Material:  localstack-python-client: small Python library with additional utils for interacting with LocalStack  ","categories":"","description":"How to use the Boto3 Python AWS SDK with LocalStack.\n","excerpt":"How to use the Boto3 Python AWS SDK with LocalStack.\n","ref":"/integrations/sdks/python/","tags":["sdk"],"title":"Python Boto3"},{"body":"The Quantum Ledger Database (QLDB) API supports queries over cryptographically verifiable data, stored in a journal of immutable transaction events. LocalStack allows to create local ledgers and journals, to perform CREATE TABLE statements, to insert data via INSERT statements, and to query data via SELECT statements.\nQLDB uses the Amazon ION data format, a data serialization format that represents a superset of JSON, with a number of additional features.\nA simple QLDB example running on LocalStack is provided in this Github repository. The sample consists of two simple scenarios: (1) to create and list tables via the pyqldb Python library, and (2) to insert data into two tables and perform a JOIN query that combines data from the two tables. The sample output is posted below:\nScenario 1: create and list tables in ledger ----------- Creating new test ledger in QLDB API: ledger-test-1 Creating two test tables in ledger Retrieved list of tables in ledger ledger-test-1: ['foobar1', 'foobar2'] ----------- Scenario 2: create ledger tables and run join query ----------- Creating two test tables in ledger - \"Vehicle\" and \"VehicleRegistration\" Running a query that joins data from the two tables Query result: [{'Vehicle': {'id': 'v1'}}, {'Vehicle': {'id': 'v2'}}, {'Vehicle': {'id': 'v3'}}] ","categories":["LocalStack Pro"],"description":"Quantum Ledger Database (QLDB)\n","excerpt":"Quantum Ledger Database (QLDB)\n","ref":"/aws/qldb/","tags":"","title":"Quantum Ledger Database (QLDB)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/raspberry-pi/","tags":"","title":"raspberry pi"},{"body":"LocalStack supports a basic version of the Relational Database Service (RDS) for testing.\nSupported DB engines Currently, it is possible to spin up PostgreSQL, MySQL, and MSSQL (SQL Server) databases on the local machine.\nNote In order to use MSSQL databases, you need to explicitly accept the Microsoft SQL Server End-User Licensing Agreement (EULA) by setting MSSQL_ACCEPT_EULA=Y in the LocalStack container environment.  Postgres versions When creating an RDS DB cluster or instance with postgres/aurora-postgresql DB engine, by default Postgres version 11 is used. In order to use custom versions, make sure to configure the environment variable RDS_PG_CUSTOM_VERSIONS=1, which then causes LocalStack to install and start up the respective Postgres version on demand. Currently, versions 11/12/13 can be installed - when selecting a major version outside of this range, the default version 11 is used as fallback.\nEnd-to-end example (Postgres) The local RDS service also supports the RDS Data API, which allows executing data queries against RDS clusters over a JSON/REST interface. Below is a simple example that illustrates (1) creation of an RDS cluster, (2) creation of a SecretsManager secret with the DB password, and (3) running a simple SELECT 123 query via the RDS Data API. $ awslocal rds create-db-cluster --db-cluster-identifier db1 --engine aurora-postgresql --database-name test { \"DBCluster\": { ... \"Endpoint\": \"localhost:4510\", \"Port\": 4510, # may vary \"DBClusterArn\": \"arn:aws:rds:us-east-1:000000000000:cluster:db1\", ... } } $ awslocal secretsmanager create-secret --name dbpass --secret-string test { \"ARN\": \"arn:aws:secretsmanager:eu-central-1:1234567890:secret:dbpass-cfnAX\", \"Name\": \"dbpass\", \"VersionId\": \"fffa1f4a-2381-4a2b-a977-4869d59a16c0\" } $ awslocal rds-data execute-statement --database test --resource-arn arn:aws:rds:us-east-1:000000000000:cluster:db1 --secret-arn arn:aws:secretsmanager:eu-central-1:1234567890:secret:dbpass-cfnAX --include-result-metadata --sql 'SELECT 123' { \"columnMetadata\": [ { \"arrayBaseColumnType\": 0, \"isAutoIncrement\": false, \"isCaseSensitive\": false, \"isCurrency\": false, \"isSigned\": true, \"label\": \"?column?\", \"name\": \"?column?\", \"nullable\": 0, \"precision\": 10, \"scale\": 0, \"schemaName\": \"\", \"tableName\": \"\", \"type\": 4, \"typeName\": \"int4\" } ], \"numberOfRecordsUpdated\": 0, \"records\": [ [ { \"longValue\": 123 } ] ] }\nYou can also use other clients like psql to interact with the database. The hostname and port of your created instance can be found in the output from above or by running awslocal rds describe-db-instances.\n$ psql -d test -U test -p 4513 -h localhost -W Password: \u003center \"test\"\u003e Default usernames and passwords Please consider the following notes regarding default usernames/passwords and database names:\n The default for master-username and db-name is ‚Äútest‚Äù. The default master-user-password is ‚Äútest‚Äù - except for MSSQL DBs, which uses ‚ÄúTest123!‚Äù as the default master password. You can use any master-username, except ‚Äúpostgres‚Äù, for creating a new RDS instance. The user will automatically be created. The user ‚Äúpostgres‚Äù is special, and it is not possible to create a new RDS instance with this user name. Do not use db-name ‚Äúpostgres‚Äù as it is already in use by LocalStack.  ","categories":["LocalStack Pro"],"description":"Relational Database Service (RDS)\n","excerpt":"Relational Database Service (RDS)\n","ref":"/aws/rds/","tags":"","title":"Relational Database Service (RDS)"},{"body":"The Route53 API in LocalStack Pro allows you to create hosted zones and to manage DNS entries (e.g., A records) which can then be queried via the built-in DNS server.\nThe example below illustrates the creation of a hosted zone example.com, registration of an A record named test.example.com that points to 1.2.3.4, and finally querying the DNS record by using the dig command against the DNS server running on localhost (inside the LocalStack container, on port 53): $ zone_id=$(awslocal route53 create-hosted-zone --name example.com --caller-reference r1 | jq -r '.HostedZone.Id') $ awslocal route53 change-resource-record-sets --hosted-zone-id $zone_id --change-batch 'Changes=[{Action=CREATE,ResourceRecordSet={Name=test.example.com,Type=A,ResourceRecords=[{Value=1.2.3.4}]}}]' $ dig @localhost test.example.com ... ;; ANSWER SECTION: test.example.com.\t300\tIN\tA\t1.2.3.4\nNote: Using the built-in DNS capabilities requires privileged access for the LocalStack container (please also refer to the DNS_ADDRESS configuration variable).  Customizing internal endpoint resolution The DNS name localhost.localstack.cloud (and any subdomains like mybucket.s3.localhost.localstack.cloud) is used internally in LocalStack to route requests, e.g., between a Lambda container and the LocalStack APIs.\nCustomizing the internal LocalStack DNS name is not a common requirement - it should work out of the box for most use cases. However, in some cases you may want to customize the external resolution of this DNS name, for example if your LocalStack instance is running on a separate Docker network than your application code, or even on a different machine.\nAssume we‚Äôd like to have all *.localhost.localstack.cloud subdomains resolve to the address 5.6.7.8 (i.e., if this is the IP where your LocalStack instance is accessible) when querying the built-in DNS server. We can utilize Route53 to that effect: $ zone_id=$(awslocal route53 create-hosted-zone --name localhost.localstack.cloud --caller-reference r1 | jq -r .HostedZone.Id) $ awslocal route53 change-resource-record-sets --hosted-zone-id $zone_id --change-batch '{\"Changes\":[{\"Action\":\"CREATE\",\"ResourceRecordSet\":{\"Name\":\"localhost.localstack.cloud\",\"Type\":\"A\",\"ResourceRecords\":[{\"Value\":\"5.6.7.8\"}]}},{\"Action\":\"CREATE\",\"ResourceRecordSet\":{\"Name\":\"*.localhost.localstack.cloud\",\"Type\":\"A\",\"ResourceRecords\":[{\"Value\":\"5.6.7.8\"}]}}]}' $ dig @127.0.0.1 bucket1.s3.localhost.localstack.cloud ... ;; ANSWER SECTION: localhost.localstack.cloud. 300\tIN\tA\t5.6.7.8 $ dig @127.0.0.1 localhost.localstack.cloud ... ;; ANSWER SECTION: localhost.localstack.cloud. 300\tIN\tA\t5.6.7.8\n","categories":["LocalStack Pro","DNS"],"description":"Route 53\n","excerpt":"Route 53\n","ref":"/aws/route53/","tags":"","title":"Route 53"},{"body":"AWS S3 is a managed scalable object storage service that can be used to store any amount of data for a wide range of use cases.\nS3 is shipped with the LocalStack Community version and is extensively supported. Trying to run the examples in the official AWS developer guide against LocalStack is a great place to start.\nAssuming you have awslocal installed you can also try the following commands. Make sure the file you put into the bucket exists:\n$ awslocal s3api create-bucket --bucket sample-bucket { \"Location\": \"/sample-bucket\" } $ awslocal s3api list-buckets { \"Buckets\": [ { \"Name\": \"sample-bucket\", \"CreationDate\": \"2021-10-05T10:48:38+00:00\" } ], \"Owner\": { \"DisplayName\": \"webfile\", \"ID\": \"bcaf1ffd86f41161ca5fb16fd081034f\" } } $ awslocal s3api put-object --bucket sample-bucket --key index.html --body index.html { \"ETag\": \"\\\"d41d8cd98f00b204e9800998ecf8427e\\\"\" } Path-Style Requests versus Virtual Hosted-Style Requests  Just like AWS, LocalStack differentiates between Path-Style and Virtual Hosted-Style Requests depending on your Host header for a request.\nExample:\n\u003cbucket-name\u003e.s3.\u003cregion\u003e.localhost.localstack.cloud # host-style request \u003cbucket-name\u003e.s3.\u003cregion\u003e.amazonaws.com # host-style request As a special case in LocalStack, leaving out .s3.\u003cregion\u003e also works for the localhost.localstack.cloud domain:\n\u003cbucket-name\u003e.localhost.localstack.cloud is also a host-style request.\nAll other requests will be considered path-style requests.\n ","categories":["LocalStack Community"],"description":"S3\n","excerpt":"S3\n","ref":"/aws/s3/","tags":"","title":"S3"},{"body":"LocalStack Pro provides a local version of the SageMaker API, which allows running jobs to create machine learning models (e.g., using TensorFlow).\nA basic example using the sagemaker.tensorflow.TensorFlow class is provided in this Github repository. Essentially, the code boils down to these core lines:\ninputs = ... # load training data files mnist_estimator = TensorFlow(entry_point='mnist.py', role='arn:aws:...', framework_version='1.12.0', sagemaker_session=sagemaker_session, train_instance_count=1, training_steps=10, evaluation_steps=10) mnist_estimator.fit(inputs, logs=False) The code snippet above uploads the model training code to local S3, submits a new training job to the local SageMaker API, and finally puts the trained model back to an output S3 bucket. Please refer to the sample repo for more details.\nNote: SageMaker is a fairly comprehensive API - for now, only a subset of the functionality is provided locally, but new features are being added on a regular basis.  ","categories":["LocalStack Pro"],"description":"SageMaker\n","excerpt":"SageMaker\n","ref":"/aws/sagemaker/","tags":"","title":"SageMaker"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/sam/","tags":"","title":"sam"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/sdk/","tags":"","title":"sdk"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/self-managed/","tags":"","title":"self-managed"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/silicon/","tags":"","title":"silicon"},{"body":"Community LocalStack keeps track of all sent emails for retrospection.\nThe sent messages can be retrieved via a service API endpoint (GET /_localstack/ses) or from the filesystem.\nMessages are also saved to the state directory (see filesystem layout). The files are saved as JSON in the ses/ subdirectory and organised by message ID.\nPro LocalStack Pro ships with extended support including a simple user interface to inspect email accounts and sent messages, as well as support for sending SES messages through an actual SMTP email server.\nPlease refer to the Configuration guide for instructions on how to configure the connection parameters of your SMTP server (SMTP_HOST/SMTP_USER/SMTP_PASS).\nOnce the SMTP server has been configured, the SES user interface in the Web app can be used to create a new email account (e.g., user1@yourdomain.com). Emails can be sent via the command line (or SES client SDK): $ awslocal ses send-email \\ --from user1@yourdomain.com \\ --message 'Body={Text={Data=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit, ...\"}},Subject={Data=Test Email}' \\ --destination 'ToAddresses=recipient1@example.com' Note: If you receive a ‚ÄúEmail address not verified message‚Äù, simply call awslocal ses verify-email-identity --email-address user1@yourdomain.com  The Web user interface can be used to view the sent email messages, as illustrated in the screenshot below:\n","categories":["LocalStack Community","LocalStack Pro"],"description":"Amazon Simple Email Service (Amazon SES)","excerpt":"Amazon Simple Email Service (Amazon SES)","ref":"/aws/ses/","tags":"","title":"Simple Email Service (SES)"},{"body":"AWS SQS is a fully managed distributed message queuing service. SQS is shipped with the LocalStack Community version and is extensively supported and tested.\nGetting started Trying to run the examples in the official AWS developer guide against LocalStack is a great place to start. Assuming you have awslocal installed you can also try the following commands:\n$ awslocal sqs create-queue --queue-name sample-queue { \"QueueUrl\": \"http://localhost:4566/000000000000/sample-queue\" } $ awslocal sqs list-queues { \"QueueUrls\": [ \"http://localhost:4566/000000000000/sample-queue\" ] } $ awslocal sqs send-message --queue-url http://localhost:4566/00000000000/sample-queue --message-body test { \"MD5OfMessageBody\": \"098f6bcd4621d373cade4e832627b4f6\", \"MessageId\": \"74861aab-05f8-0a75-ae20-74d109b7a76e\" } SQS Query API The SQS Query API exposes SQS Queue URLs as endpoints and allows you to make HTTP requests directly against the Queue. LocalStack also supports the Query API.\nLocalStack makes it easy to test SQS Query API calls without having to sign or add AUTHPARAMS to your HTTP requests. For example, you could send a SendMessage command using a MessageBody attribute with a simple curl command: $ curl \"http://localhost:4566/000000000000/sample-queue?Action=SendMessage\u0026MessageBody=hello%2Fworld\" \u003c?xml version='1.0' encoding='utf-8'?\u003e \u003cSendMessageResponse xmlns=\"http://queue.amazonaws.com/doc/2012-11-05/\"\u003e\u003cSendMessageResult\u003e\u003cMD5OfMessageBody\u003ec6be4e95a26409675447367b3e79f663\u003c/MD5OfMessageBody\u003e\u003cMessageId\u003e466144ab-1d03-4ec5-8d70-97535b2957fb\u003c/MessageId\u003e\u003c/SendMessageResult\u003e\u003cResponseMetadata\u003e\u003cRequestId\u003eJU40AF5GORK0WSR75MOY3VNQ1KZ3TAI7S5KAJYGK9C5P4W4XKMGF\u003c/RequestId\u003e\u003c/ResponseMetadata\u003e\u003c/SendMessageResponse\u003e\nJSON output format When the client sets the Accept: application/json header, AWS responds with a JSON response instead of XML. This is currently not supported by LocalStack.  Behavior changes in 0.14.2 In previous releases, an empty HTTP request to a queue would return a \u003cGetQueueUrlResponse\u003e. This has since been aligned to the behavior of AWS, which returns a \u003cUnknownOperationException/\u003e. To run a GetQueueUrl request, add the ?Action=GetQueueUrl\u0026QueueName=\u003cQueueName\u003e\" query string to the URL.  Configuration Queue URLs You can control the format of the generated Queue URLs by setting the environment variable SQS_ENDPOINT_STRATEGY when starting LocalStack to one of the following values.\n   Value URL format Description     domain \u003cregion\u003e.queue.localhost.localstack.cloud:4566/\u003caccount_id\u003e/\u003cqueue_name\u003e This strategy behaves like the SQS legacy service endpoints, and uses localhost.localstack.cloud to resolve to localhost. When using us-east-1, the \u003cregion\u003e. prefix is omitted.   path localhost:4566/queue/\u003cregion\u003e/\u003caccount_id\u003e/\u003cqueue_name\u003e An alternative that can be useful if you cannot resolve LocalStack‚Äôs localhost domain   off localhost:4566/\u003caccount_id\u003e/\u003cqueue_name\u003e Currently the default for backwards compatibility. Since this format does not encode the region, you cannot query queues that exist in different regions with the same name.    Enabling QueueDeletedRecently errors AWS does not allow creating a queue with the same name for 60 seconds after it was deleted. See the DeleteQueue API Reference. LocalStack disables this behavior by default, but it can be enabled by starting LocalStack with SQS_DELAY_RECENTLY_DELETED=1.\nDeprecated providers LocalStack has two other third-party providers for SQS that have since been deprecated: moto and elasticmq. To activate the moto provider, start localstack with PROVIDER_OVERRIDE_SQS=legacy. If you want to activate elasticmq, you need to set both PROVIDER_OVERRIDE_SQS=legacy SQS_PROVIDER=elasticmq. The two providers are no longer tested or supported.\nPersistence Support As of now the LocalStack Pro persistence mechanism is only supported for the default SQS provider.  ","categories":["LocalStack Community"],"description":"Explaining the different SQS providers and how to configure the service.\n","excerpt":"Explaining the different SQS providers and how to configure the ‚Ä¶","ref":"/aws/sqs/","tags":"","title":"Simple Queue Service (SQS)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/stub/","tags":"","title":"Stub"},{"body":"Systems Manager can be used in conjunction with the EC2 Docker backend to run operational tasks on the Dockerised instances.\nThe following table highlights some differences between LocalStack SSM and AWS SSM.\n   LocalStack AWS     Instances are automatically registered with SSM Instances are manually registered using CreateActivation   Uses Docker exec to perform operations Uses Amazon SSM Agent   Instance IDs are prefixed with i- Instance IDs are prefixed with mi-    Following operations are currently supported:\n   Operation Notes     DescribeInstanceInformation List all registered instances   SendCommand Currently only AWS-RunShellScript document is supported   ListCommandInvocations List all invocations   GetCommandInvocation Details of an invocation including standard output and standard error contents    Examples $ awslocal ssm send-command --document-name \"AWS-RunShellScript\" \\ --document-version \"1\" \\ --instance-ids i-04df0c15 \\ --parameters \"commands='cat ./uptime',workingDirectory=/proc\" { \"Command\": { \"CommandId\": \"e53e67c3-a8f2-419e-87e4-e596880797e8\", \"DocumentName\": \"AWS-RunShellScript\", \"DocumentVersion\": \"1\", \"InstanceIds\": [ \"i-04df0c15\" ], \"Status\": \"InProgress\" } } $ awslocal ssm get-command-invocation \\ --command-id a0105ed1-0a4d-423b-9a64-9a49828f5391 \\ --instance-id i-04df0c15 { \"CommandId\": \"a0105ed1-0a4d-423b-9a64-9a49828f5391\", \"InstanceId\": \"i-04df0c15\", \"DocumentName\": \"AWS-RunShellScript\", \"DocumentVersion\": \"1\", \"Status\": \"Success\", \"StandardOutputContent\": \"1066081.29 510156.74\\n\", \"StandardErrorContent\": \"\" } Limitations  Only AWS-RunShellScript is supported for Dockerised instances. If the command returns a non-zero code, the standard output and standard error streams are not captured and will be empty. Shell constructs like job controls (\u0026\u0026, ||), redirection (\u003e) etc. are not supported.  ","categories":["LocalStack Pro"],"description":"AWS Systems Manager (SSM)","excerpt":"AWS Systems Manager (SSM)","ref":"/aws/systems-manager/","tags":"","title":"Systems Manager (SSM)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/terraform/","tags":"","title":"terraform"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/testing/","tags":"","title":"testing"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/thundra/","tags":"","title":"thundra"},{"body":"LocalStack Pro contains basic support for Timestream time series databases, including these operations:\n Creating databases Creating tables Writing records to tables Querying timeseries data from tables  Simple Usage Example The following example illustrates the basic operations, using the awslocal command line.\nFirst, we create a test database and table:\n$ awslocal timestream-write create-database --database-name testDB $ awslocal timestream-write create-table --database-name testDB --table-name testTable We can then add a few records with a timestamp, measure name, and value to the table:\n$ awslocal timestream-write write-records --database-name testDB --table-name testTable --records '[{\"MeasureName\":\"cpu\",\"MeasureValue\":\"60\",\"TimeUnit\":\"SECONDS\",\"Time\":\"1636986409\"}]' $ awslocal timestream-write write-records --database-name testDB --table-name testTable --records '[{\"MeasureName\":\"cpu\",\"MeasureValue\":\"80\",\"TimeUnit\":\"SECONDS\",\"Time\":\"1636986412\"}]' $ awslocal timestream-write write-records --database-name testDB --table-name testTable --records '[{\"MeasureName\":\"cpu\",\"MeasureValue\":\"70\",\"TimeUnit\":\"SECONDS\",\"Time\":\"1636986414\"}]' Finally, we can run a query to retrieve the timeseries data (or aggregate values) from the table: $ awslocal timestream-query query --query-string \"SELECT CREATE_TIME_SERIES(time, measure_value::double) as cpu FROM testDB.timeStreamTable WHERE measure_name='cpu'\" { \"Rows\": [{ \"Data\": [{ \"TimeSeriesValue\": [{ \"Time\": \"2021-11-15T14:26:49\", \"Value\": { \"ScalarValue\": 60 } }, ...\nDate / Time Functions LocalStack supports the following functions for querying Timestream data:\n   Function Description Data type     ago (interval) Returns the value corresponding to current_timestamp interval. timestamp   bin (timestamp, interval) Returns a rounded value down to a multiple of given bin interval. timestamp   parse_duration (string) Returns an interval equivalent parsed out of the input string. interval   from_iso8601_date (string) Parses the ISO 8601 date string into internal Timestamp format for UTC 00:00:00 of the specified date. timestamp   from_iso8601_timestamp (string) Parses the ISO 8601 timestamp into internal timestamp format. timestamp    ","categories":["LocalStack Pro"],"description":"Timestream\n","excerpt":"Timestream\n","ref":"/aws/timestream/","tags":"","title":"Timestream"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/tools/","tags":"","title":"Tools"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/tracing/","tags":"","title":"tracing"},{"body":"The AWS Transfer API provides the ability to create FTP(S) servers to make files in S3 buckets accessible directly via FTP.\nA simple example using AWS Transfer is included in this Github repository. The sample creates an FTP server via the Transfer API locally, uploads two files via FTP to S3, and then finally downloads the files from the target S3 bucket.\nNote: The Transfer API does not provide a way to return the endpoint URL of created FTP servers. Hence, in order to determine the server endpoint, the local port is encoded as a suffix in the ServerId attribute, using the pattern s-\u003cid\u003e:\u003cport\u003e. For example, assume the following is the response from the CreateServer API call, then the FTP server is accessible on port 4511 (i.e., ftp://localhost:4511):\n{ \"ServerId\": \"s-73c53daf86da4:4511\" }   ","categories":["LocalStack Pro"],"description":"Transfer\n","excerpt":"Transfer\n","ref":"/aws/transfer/","tags":"","title":"Transfer"},{"body":"LocalStack Pro allows to instrument your applications using XRay tracing. This helps in optimizing the interactions between service calls, and facilitates debugging of performance bottlenecks.\nFor example, a Python Lambda function can be instrumented as follows (based on the example here):\nimport boto3 from aws_xray_sdk.core import xray_recorder from aws_xray_sdk.core import patch patch(['boto3']) s3_client = boto3.client('s3') def lambda_handler(event, context): s3_client.create_bucket(Bucket='mybucket') xray_recorder.begin_subsegment('my_code') # your function code goes here... xray_recorder.end_subsegment() Running this code in Lambda on LocalStack will result in two trace segments being created in XRay - one from the instrumented boto3 client when running create_bucket(..), and one for the custom subsegment denoted 'my_code'. You can use the regular XRay API calls (e.g., GetTraceSummaries, BatchGetTraces) to retrieve the details (timestamps, IDs, etc) of these segments.\nYou can also checkout another of our examples with Xray and Lambda, deployed via the Serverless framework, here\nNote: To use XRay in Lambdas, please note that you‚Äôll need to configure LAMBDA_XRAY_INIT=1 - this will ensure that the XRay daemon process is fully initialized when spawning Lambda containers (may slightly increase startup times).  ","categories":["LocalStack Pro"],"description":"XRay Tracing\n","excerpt":"XRay Tracing\n","ref":"/aws/xray-tracing/","tags":"","title":"XRay Tracing"}]